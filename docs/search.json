[
  {
    "objectID": "intro-how-to-navigate-this-course.html",
    "href": "intro-how-to-navigate-this-course.html",
    "title": "3  How to Navigate this Course",
    "section": "",
    "text": "This video goes over a couple of items not covered in Chapter 2 such as:\n\nHow to know what to do each week\nIntroduce Yourself Discussion Post and Course Overview Quiz\nUnderstanding the Reading Assignments\nContent videos and how to follow along (including the additional exercises)\nWhere to post questions\n\n\nASSIGNMENT: Be sure to complete the ‘Course Overview Quiz’ on Canvas.",
    "crumbs": [
      "Intro",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>How to Navigate this Course</span>"
    ]
  },
  {
    "objectID": "intro-syllabus.html",
    "href": "intro-syllabus.html",
    "title": "2  Syllabus",
    "section": "",
    "text": "Watch the following video to hear more detail about our course!\n\nFILE: dana-320-syllabus-fa23.docx",
    "crumbs": [
      "Intro",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Syllabus</span>"
    ]
  },
  {
    "objectID": "module-intro.html",
    "href": "module-intro.html",
    "title": "Intro",
    "section": "",
    "text": "Here is an overview of the content and corresponding assignments.",
    "crumbs": [
      "Intro"
    ]
  },
  {
    "objectID": "intro-meet-your-instructor.html",
    "href": "intro-meet-your-instructor.html",
    "title": "1  Meet Your Instructor",
    "section": "",
    "text": "Check out the video below to find out a little more about me!\n\nSLIDES: meet-your-instructor.pptx",
    "crumbs": [
      "Intro",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Meet Your Instructor</span>"
    ]
  },
  {
    "objectID": "intro-to-data-viz.html",
    "href": "intro-to-data-viz.html",
    "title": "3  Introduction to Data Visualization",
    "section": "",
    "text": "Watch the video below to find out more about what Data Visualization is and big picture how we will be learning it!\n\nSLIDES: intro-to-data-viz.pptx\nASSIGNMENT: Be sure to complete the ‘Introduce Yourself Discussion Post’ on Canvas.",
    "crumbs": [
      "Intro",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introduction to Data Visualization</span>"
    ]
  },
  {
    "objectID": "module-readings.html#overview",
    "href": "module-readings.html#overview",
    "title": "Readings",
    "section": "Overview",
    "text": "Overview\n\nWeekly readings and corresponding quizzes will be assigned continuously throughout the semester.\nThese will correspond to the following texts:\n\nSWD = Storytelling with data (Note that this is available as an audiobook on Audible as well)\nR4DS = R for Data Science (2e)\n\nFurther along in the semester, there may be discussion posts related to ideas from these.",
    "crumbs": [
      "Readings"
    ]
  },
  {
    "objectID": "module-readings.html#purpose-of-readings",
    "href": "module-readings.html#purpose-of-readings",
    "title": "Readings",
    "section": "Purpose of Readings",
    "text": "Purpose of Readings\n\nRegular content in the course will focus on the tools used to carry out data visualizations, specifically the methods and techniques to manipulate data and create visuals in Excel, Tableau and R.\nTo guide the design and creation of these visuals, the readings are where we will explore the principles of data visualization.\nIncluded in these principles are:\n\nThe science of visual perception (how our brains process visual information);\nHow creators can optimize a data display (methods for more effective visuals);\nHow to create accurate, non-misleading displays (from a statistical and visual perspective).",
    "crumbs": [
      "Readings"
    ]
  },
  {
    "objectID": "module-readings.html#schedule",
    "href": "module-readings.html#schedule",
    "title": "Readings",
    "section": "Schedule",
    "text": "Schedule\n\nBelow is an outline of the assigned readings and the content they cover.",
    "crumbs": [
      "Readings"
    ]
  },
  {
    "objectID": "module-readings.html#additional-resources",
    "href": "module-readings.html#additional-resources",
    "title": "Readings",
    "section": "Additional Resources",
    "text": "Additional Resources\n\nOnce we get further in the semester, I encourage you to check out the following online platforms for discussing and sharing data visualizations. Can you see how the visuals apply the principles of data visualization?\n\nflowingdata.com, visualcomplexity.com, reddit.com/r/dataisbeautiful\n\nIf you want to read more about data visualization, you can try these data visualization books:\n\nVisualize This (Nathan Yau), Data Visualization Made Simple (Kristen Sosulski)",
    "crumbs": [
      "Readings"
    ]
  },
  {
    "objectID": "quizzes-readings.html",
    "href": "quizzes-readings.html",
    "title": "4  Reading Check Quizzes",
    "section": "",
    "text": "Check Canvas for the weekly Reading Check Quizzes (RCQs) and discussion posts.",
    "crumbs": [
      "Readings",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Reading Check Quizzes</span>"
    ]
  },
  {
    "objectID": "module-excel.html",
    "href": "module-excel.html",
    "title": "Excel",
    "section": "",
    "text": "Here is an overview of the content and corresponding assignments.",
    "crumbs": [
      "Excel"
    ]
  },
  {
    "objectID": "install-excel.html#how-to-install-excel",
    "href": "install-excel.html#how-to-install-excel",
    "title": "5  Install Excel",
    "section": "5.1 How to Install Excel",
    "text": "5.1 How to Install Excel\n\nExcel and all of Microsoft Office 365 Pro Plus is available free to BSU students.\nFollow these instructions to download Excel if you do not already have it on your personal computer. It is also available for free on campus computers.\nIF YOU HAVE A MAC, using Numbers (Apple’s version of Excel) is not an adequate replacement. You will need Microsoft Excel.",
    "crumbs": [
      "Excel",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Install Excel</span>"
    ]
  },
  {
    "objectID": "install-excel.html#having-trouble",
    "href": "install-excel.html#having-trouble",
    "title": "5  Install Excel",
    "section": "5.2 Having Trouble?",
    "text": "5.2 Having Trouble?\n\nPlease reach out to me or the BSU Technology Help Desk as soon as possible.",
    "crumbs": [
      "Excel",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Install Excel</span>"
    ]
  },
  {
    "objectID": "intro-to-excel.html#overview",
    "href": "intro-to-excel.html#overview",
    "title": "6  Introduction to Excel",
    "section": "6.1 Overview",
    "text": "6.1 Overview\n\nTo start the Excel module, I have assigned a DataCamp course.\nIf you have not used DataCamp before, it is an online learning platform that focuses on teaching students the comprehensive skills they need to become successful data scientists. Courses contain videos taught by industry experts to follow along with as well as various built-in learning checks (exercises).",
    "crumbs": [
      "Excel",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Introduction to Excel</span>"
    ]
  },
  {
    "objectID": "intro-to-excel.html#access-course-steps",
    "href": "intro-to-excel.html#access-course-steps",
    "title": "6  Introduction to Excel",
    "section": "6.2 Access Course – Steps",
    "text": "6.2 Access Course – Steps\n\nJoin our DataCamp classroom by clicking the this invite link.\nIf you do not have a DataCamp account, it will prompt you to make one. You MUST USE your @bsu.edu email.\n\n\n\n\n\n\n\n\n\nOnce you do this, navigate to the ‘Learn’ tab at the top and then to ‘Assignments’ on the sidebar. This is where you will find this and future assignments.",
    "crumbs": [
      "Excel",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Introduction to Excel</span>"
    ]
  },
  {
    "objectID": "intro-to-excel.html#course-introduction-to-excel",
    "href": "intro-to-excel.html#course-introduction-to-excel",
    "title": "6  Introduction to Excel",
    "section": "6.3 Course: Introduction to Excel",
    "text": "6.3 Course: Introduction to Excel\n\nThis course covers the basics of Excel and will give you the foundation needed for the rest of the module. Even if you are familiar with Excel, this will be a very useful course where you will learn features that you are probably not aware of.\nThis will serve as both content and an assignment to start the module.\nIt has 3 chapters that you will need to complete (you must finish Chapter 1 in order to unlock Chapter 2, and so forth):\n\nGetting Started with Excel\nManaging data and applying aggregate functions\nOther functions and visualizing data\n\nHOW TO WORK THROUGH THIS COURSE\n\nCompleting the course requires you earn enough XP by watching the videos and complete the exercises correctly.\nThese will be the most effective if you follow along with the videos and do them at the same time and take the time to actually do the exercises. Guessing just to get it done is not an effective learning strategy.\n\nHere is a link to DOWNLOAD the workbooks / datasets used in the videos and exercises.",
    "crumbs": [
      "Excel",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Introduction to Excel</span>"
    ]
  },
  {
    "objectID": "intro-to-excel.html#learn-more",
    "href": "intro-to-excel.html#learn-more",
    "title": "6  Introduction to Excel",
    "section": "6.4 Learn more!",
    "text": "6.4 Learn more!\n\nBy joining our course, you have unlimited access to ANY DataCamp course until January 6, 2024.\nFeel free to explore and complete any other course you wish, related to our class or not.",
    "crumbs": [
      "Excel",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Introduction to Excel</span>"
    ]
  },
  {
    "objectID": "intro-to-excel.html#submission",
    "href": "intro-to-excel.html#submission",
    "title": "6  Introduction to Excel",
    "section": "6.5 Submission",
    "text": "6.5 Submission\n\nUpon completion of the entire course, you will receive a certificate called a ‘Statement of Accomplishment’ like below.\nPlease upload this certificate for this assignment (a picture of it, or a word doc with the certificate in it, etc.). IT MUST INCLUDE YOUR NAME IN THE CERTIFICATE, or no credit will be given.",
    "crumbs": [
      "Excel",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Introduction to Excel</span>"
    ]
  },
  {
    "objectID": "notes-excel-basic-charts-in-excel.html#preface",
    "href": "notes-excel-basic-charts-in-excel.html#preface",
    "title": "7  Notes – Basic Charts in Excel",
    "section": "7.1 Preface",
    "text": "7.1 Preface\n\nBelow is all of the content for this section along with the corresponding assignments (in the recommended order).\nBe sure to follow along with all of the videos using the provided Excel files AND complete the additional Exercises.\nPost any questions related to content or assignments in the corresponding discussion board.",
    "crumbs": [
      "Excel",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Notes -- Basic Charts in Excel</span>"
    ]
  },
  {
    "objectID": "notes-excel-basic-charts-in-excel.html#sec-notes-basic-charts-in-excel",
    "href": "notes-excel-basic-charts-in-excel.html#sec-notes-basic-charts-in-excel",
    "title": "7  Notes – Basic Charts in Excel",
    "section": "7.2 Basic Charts in Excel",
    "text": "7.2 Basic Charts in Excel\n\nThis video introduces the basics of creating a variety of different charts in Excel and is our first exposure to redesigning plots to be more effective, which is a main goal of this course: Learn the features of different technologies so we can utilize them to create thoughtful data visualizations.\nFILES: basic-charts-in-excel-STARTER.xlsx and basic-charts-in-excel-COMPLETED.xlsx",
    "crumbs": [
      "Excel",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Notes -- Basic Charts in Excel</span>"
    ]
  },
  {
    "objectID": "notes-excel-basic-charts-in-excel.html#lab",
    "href": "notes-excel-basic-charts-in-excel.html#lab",
    "title": "7  Notes – Basic Charts in Excel",
    "section": "7.3 Lab",
    "text": "7.3 Lab\nASSIGNMENT LINK: Chapter 8",
    "crumbs": [
      "Excel",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Notes -- Basic Charts in Excel</span>"
    ]
  },
  {
    "objectID": "notes-excel-basic-charts-in-excel.html#homework",
    "href": "notes-excel-basic-charts-in-excel.html#homework",
    "title": "7  Notes – Basic Charts in Excel",
    "section": "7.4 Homework",
    "text": "7.4 Homework\nASSIGNMENT LINK: Chapter 9",
    "crumbs": [
      "Excel",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Notes -- Basic Charts in Excel</span>"
    ]
  },
  {
    "objectID": "lab-excel-more-charts-in-excel.html#submission",
    "href": "lab-excel-more-charts-in-excel.html#submission",
    "title": "9  Lab – More Charts in Excel",
    "section": "9.1 Submission",
    "text": "9.1 Submission\nSubmission\n\nPlease upload a completed workbook for this assignment to Canvas.\nPart of the grading will be the organization / cleanliness of the workbook.\n\nMake sure the final product looks professional and presentable, e.g. no extraneous work scattered about and data, plots and reports placed well.\n\n\nFILES\n\nlab-more-charts-in-excel.docx and lab-more-charts-in-excel-STARTER.xlsx\nNOTE: Instructors can contact me for solutions :)",
    "crumbs": [
      "Excel",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Lab -- More Charts in Excel</span>"
    ]
  },
  {
    "objectID": "lab-excel-more-charts-in-excel.html#part-1-multiple-variable-charts",
    "href": "lab-excel-more-charts-in-excel.html#part-1-multiple-variable-charts",
    "title": "9  Lab – More Charts in Excel",
    "section": "9.2 Part 1 – Multiple Variable Charts",
    "text": "9.2 Part 1 – Multiple Variable Charts\n\n9.2.1 Overview\n\nThis problem furthers the ideas from the notes in Section 7.2, where we learned how to create and format many simple charts in Excel.\nThe first tab of the accompanying workbook contains a dataset of physical measurements of a sample several different fish species caught from the same lake; a subset is shown below:\n\n\n\n\n\n\n\n\n\n\n9.2.2 Assignment\n\nThe goal is to create several plots that visualize more than one variable at the same time.\nHere are some questions to investigate about the fish species and the plots we will use to help. After each plot, add a text box with a quick write-up answering the directed questions.\n\n\nDo different species have different lengths? Comparative Boxplot of length by species\n\nThis type of plot visualizes boxplots for each species.\nTo create this: Highlight the Species column and Length column at the same time -&gt; Insert Box and Whisker Plot.\nIn the write-up: Compare the distributions of length between the different species.\n\nHow do the distributions of weights compare for species of different lengths? Comparative Histograms\n\nThere is no good way to plot two histograms in the same panel; so, the best way to do this is to create two separate histograms and organize next to each other, specifically one for shorter length species and one for longer length.\nTo create this:\n\n\nBased on the plot from (a), identify the 3 shortest species.\nTo make two histograms, you need two separate tables. Copy the entire dataset and paste off to the side; this will be used to help make the two needed tables.\nFilter the copied data to the 3 shortest species; then copy only those rows and paste in their own table. Repeat for the remaining species. Now the full copied data can be deleted.\nInsert histograms for each new table. Be sure color each histogram different and give them informative titles based on which subset of data it is based on (shorter fish or longer fish).\n\n\nIn the write up: Compare the distributions of weight for the two groups of fish.\n\nIs weight a good predictor of length? Scatterplot\n\nScatterplots visualize two numeric variables by plotting each pair of numbers.\nTo create this: Highlight the Weight and Length columns at the same time -&gt; Insert Scatterplot.\nBe sure to give the chart a title and axis labels.\nIn the write-up: Does there appear to be a relationship between weight and length of fish? If so, describe the trend.\n\n\nWhat will be looked at for grading\n\nCorrect plots and sufficient write-ups.",
    "crumbs": [
      "Excel",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Lab -- More Charts in Excel</span>"
    ]
  },
  {
    "objectID": "lab-excel-more-charts-in-excel.html#part-2-waterfall-chart",
    "href": "lab-excel-more-charts-in-excel.html#part-2-waterfall-chart",
    "title": "9  Lab – More Charts in Excel",
    "section": "9.3 Part 2 – Waterfall Chart",
    "text": "9.3 Part 2 – Waterfall Chart\n\n9.3.1 Overview\n\nThis problem extends Part 1 of this Lab, where we continued introducing more types of Charts that can be made in Excel.\nThe second tab of the accompanying workbook contains a dataset for interest rates of a 30-year mortgage; a subset of which is shown below:\n\n\n\n\n\n\n\n\n\n\n9.3.2 Assignment\n\nThe goal is to create a Waterfall Chart, including performing the necessary data transformations needed for the plot.\nA Waterfall Chart shows a running total as values are added or subtracted. It’s useful for understanding how an initial value is affected by a series of positive and negative values. An example is shown below:\n\n\n\n\n\n\n\n\n\nIt is commonly used in a business context to show the incoming and outgoing money (revenue, expenses, net income, etc.). It can also be used to show values across time as in the example.\nHere’s how to create it:\n\n\nCreate a new column named ‘Change in interest rate (%)’ with the following specifications:\n\nThe first value (corresponding to the earliest year) should be equal to the interest rate that year. This represents the starting ‘base’ total.\nAfter the base, a Waterfall Chart plots the change from the previous item (i.e. year to year in this case). Write a formula to calculate the change in rate from the previous year and fill it down. For example, if 2010 rate was 5.5% and 2011 rate was 5%, the value in the row for 2011 is -0.5%.\nAfter the final year, add an extra row that is the cumulative value of the interest rate after all of the changes. It should equal the rate in the last year. This row (without a year label) represents the ending ‘base’ total.\n\nWith the data setup, now you can highlight the change column -&gt; Insert Waterfall Chart.\n\nTo correctly format the starting and ending ‘base’, double click the bars and click ‘Set as Total’.\nSet the horizontal axis labels to the Year.\nChoose appropriate colors for the Increase, Decrease, and Totals. Be sure to give the chart an informative title as well.\n\n\nWhat will be looked at for grading\n\nCorrect data setup, well-formatted Waterfall Chart.",
    "crumbs": [
      "Excel",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Lab -- More Charts in Excel</span>"
    ]
  },
  {
    "objectID": "hw-excel-plots-for-analyses.html#submission",
    "href": "hw-excel-plots-for-analyses.html#submission",
    "title": "9  HW – Plots for Analyses",
    "section": "9.1 Submission",
    "text": "9.1 Submission\nSubmission\n\nPlease upload a completed workbook for this assignment to Canvas.\nPart of the grading will be the organization / cleanliness of the workbook.\n\nMake sure the final product looks professional and presentable, e.g. no extraneous work scattered about and data, plots and reports placed well.\n\n\nFILES\n\nhw-plots-for-analyses.docx and hw-plots-for-analyses-STARTER.xlsx\nNOTE: Instructors can contact me for solutions :)",
    "crumbs": [
      "Excel",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>HW -- Plots for Analyses</span>"
    ]
  },
  {
    "objectID": "hw-excel-plots-for-analyses.html#part-1-linear-regression",
    "href": "hw-excel-plots-for-analyses.html#part-1-linear-regression",
    "title": "9  HW – Plots for Analyses",
    "section": "9.2 Part 1 – Linear Regression",
    "text": "9.2 Part 1 – Linear Regression\n\n9.2.1 Overview\n\nThis problem extends the ideas from the notes in Section 7.2, where we learned how to create summary tables, and from @lab-more-charts-in-excel, where we created scatterplots.\nThe first tab of the accompanying workbook contains a dataset of public transformation information related to the metro for a sample of hypothetical cities; a subset is shown below:\n\n\n\n\n\n\n\n\n\nThe response variable Y is ‘Number of weekly riders’ and the other numeric variables are the explanatory X variables.\n\n\n\n9.2.2 Assignment\n\nThe goal is to analyze the number of weekly riders by creating a summary statistics table for each state and determining the best predictor via simple linear regression.\n\n\nComplete the summary statistics table for each City and Overall.\n\nFind the correct formulas to use and set them up so that they can be autofilled down easily.\n\nNow we want to determine which X variable has the most impact on Y, the number of weekly riders. Repeat the following steps for each of the three numeric X variables.\n\nCreate a scatterplot with the correct selection of the axes / variables.\nAdd informative chart title and axes labels so it is clear which variables are being plotted.\nTo add the line of best fit (regression line): Chart Design -&gt; Add Chart Element -&gt; Trendline -&gt; Linear.\nTo add the regression information: Right click on the trend line -&gt; Format Trendline -&gt; check the boxes for ‘Display Equation on chart’ and ‘Display R-squared value on chart’.\nFormat the points to be a neutral color and the line a brighter color so that the regression line has more emphasis. Change the font color of the summary info to visually ‘link’ it to the regression line.\nAfter finishing all plots, add a text box to your workbook and include a quick write-up discussing which X variable is the best predictor of Y the number of weekly riders. How do you know? Describe the relationship (either visually or from the regression equation) between Y and the best X.\n\n\nWhat will be looked at for grading\n\nCompleted summary statistics table with correct formulas, well-formatted plots with trendline information, sufficient write-up.",
    "crumbs": [
      "Excel",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>HW -- Plots for Analyses</span>"
    ]
  },
  {
    "objectID": "hw-excel-plots-for-analyses.html#part-2-plots-of-aggregated-data",
    "href": "hw-excel-plots-for-analyses.html#part-2-plots-of-aggregated-data",
    "title": "9  HW – Plots for Analyses",
    "section": "9.3 Part 2 – Plots of Aggregated Data",
    "text": "9.3 Part 2 – Plots of Aggregated Data\n\n9.3.1 Overview\n\nThis problem extends Part 1 of this Lab, where we continued introducing more types of Charts that can be made in Excel.\nThe second tab of the accompanying workbook contains two tables: a dataset of daily sales and a table for monthly sales from the previous year. Subsets of both are shown below:\n\n\n\n\n\n\n\n\n\n\n9.3.2 Assignment\n\nThe goal is to analyze the sales data from several perspectives using visuals based on different levels of aggregation.\nAfter each analysis, add a text box with a quick write-up answering the directed questions.\n\n\nThe first analysis will compare monthly sales total for 2022 to that of 2021 via a Line Chart.\n\nFirst, the daily data needs to be aggregated by month. Here’s how:\n\nIn the daily sales table, you need to create a new column representing the month for each sale date. Create a new column after Date named ‘Month #’ and determine the correct function to use to extract the month.\nNow in the monthly sales table, add a column for 2022 and use the correct function to calculate the total sales based on the respective month.\nTo have more informative axis labels in the plot, create a new column after ‘Month #’ named ‘Month’. To convert the month # to the abbreviation (e.g. 1 = Jan), use the following formula template: = TEXT(‘Month #’ * 29, “mmm”) This formula just converts the month number to a day number (* 29) that would be in the desired month and changes the format to the month abbreviation.\n\nNow, you can plot two lines, one for 2021 and one for 2022, at the same time by highlighting the Month, 2021 and 2022 -&gt; Insert Line Chart.\n\nBe sure to give the chart an informative title. Try a few different legend spots to find the one that is easiest for the reader to figure out which line is which.\nIn the write-up: Compare monthly sales from the two years.\n\n\nThe second analysis will compare quarterly sales for via Comparative Boxplots.\n\nFirst, the daily data needs to be setup. Here’s how::\n\nBoxplots take raw data and summarize it for you. So all that needs to be done is adding a column for the group, in this case quarter of the sales date.\nAdd a column after ‘Month #’ called ‘Quarter’. There is no direct function to convert a date into quarter. So, write an algebra formula involving the month number and one of the various ROUND() functions to end up with the correct quarter (1, 2, 3 or 4). Ensure your formula works for all months.\n\nNow, you can insert the Comparative Boxplot for Sales by Quarter.\n\nNotice the X-axis labels; they aren’t very informative. This is something that can be fixed directly in data so that better labels are automatically pulled in.\nSearch how to combine text in Excel with a formula and apply this to the Quarter calculation. You want the values to be of the form Q1, Q2,….\nOne additional feature of Comparative Boxplots is connecting the mean markers for each boxplot. To do this: Right click any boxplot -&gt; Format Data Series -&gt; check box for ‘Show mean line’.\nBe sure to give the chart an informative title.\nIn the write up: Discuss what type of information is shown by the final Comparative Boxplot. Is it more or less informative that the Line Chart in the first analysis? Why? Then compare the quarterly.\n\n\n\nWhat will be looked at for grading\n\nCorrect calculation of Quarter, correct Comparative Boxplot, sufficient write-up.",
    "crumbs": [
      "Excel",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>HW -- Plots for Analyses</span>"
    ]
  },
  {
    "objectID": "notes-excel-reports.html#preface",
    "href": "notes-excel-reports.html#preface",
    "title": "11  Notes – Reports",
    "section": "11.1 Preface",
    "text": "11.1 Preface\n\nBelow is all of the content for this section along with the corresponding assignments (in the recommended order).\nBe sure to follow along with all of the videos using the provided Excel files AND complete the additional Exercises.\nPost any questions related to content or assignments in the corresponding discussion board.",
    "crumbs": [
      "Excel",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Notes -- Reports</span>"
    ]
  },
  {
    "objectID": "notes-excel-reports.html#sec-notes-introduction-to-pivot-tables",
    "href": "notes-excel-reports.html#sec-notes-introduction-to-pivot-tables",
    "title": "11  Notes – Reports",
    "section": "11.2 Introduction to Pivot Tables",
    "text": "11.2 Introduction to Pivot Tables\n\nIn the previous section, we calculated summary statistics manually using functions like COUNTIF().\nNow we introduce Pivot Tables, which is are a much more automated and flexible method for summarizing.\nFILES: introduction-to-pivot-tables-STARTER.xlsx and introduction-to-pivot-tables-COMPLETED.xlsx\n\n\n\nHere is the written tutorial for the video.\nNOTE: Insert Pivot Tables into existing worksheet instead of into a new sheet; there are prompts for where to put them.",
    "crumbs": [
      "Excel",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Notes -- Reports</span>"
    ]
  },
  {
    "objectID": "notes-excel-reports.html#sec-notes-combining-data-and-more-on-pivot-tables",
    "href": "notes-excel-reports.html#sec-notes-combining-data-and-more-on-pivot-tables",
    "title": "11  Notes – Reports",
    "section": "11.3 Combining Data and More on Pivot Tables",
    "text": "11.3 Combining Data and More on Pivot Tables\n\nThis video introduces a very common data structure and a function to help combine datasets.\nThen we learn some more useful Pivot Table features.\nFILES: combining-data-and-more-on-pivot-tables-STARTER.xlsx and combining-data-and-more-on-pivot-tables-COMPLETED.xlsx\n\n\n\n\nADDITIONAL RESOURCES\n\nWhen learning / applying new methods, will probably keep running into specific mini problems. So when searching solutions, be sure to use solutions that you can understand as much as possible so you learn more and can reapply it later.\n\nArticle tutorial for how to fix XLOOKUP bringing in zeros instead of blanks.\n\nCombining data via Data models and PowerPivot video and tutorial.\n\nCurrently this can’t be done in Excel on Mac or Excel Online, but pretty much all companies have Windows Excel (so it will likely be available to you). And more importantly, a lot of software and technology is knowing what can be done, then deciding if it is useful for your application. So this is still a GREAT WATCH!",
    "crumbs": [
      "Excel",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Notes -- Reports</span>"
    ]
  },
  {
    "objectID": "notes-excel-reports.html#lab",
    "href": "notes-excel-reports.html#lab",
    "title": "11  Notes – Reports",
    "section": "11.4 Lab",
    "text": "11.4 Lab\nASSIGNMENT LINK: Chapter 11",
    "crumbs": [
      "Excel",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Notes -- Reports</span>"
    ]
  },
  {
    "objectID": "notes-excel-reports.html#sec-notes-more-on-xlookup",
    "href": "notes-excel-reports.html#sec-notes-more-on-xlookup",
    "title": "11  Notes – Reports",
    "section": "11.5 More on XLOOKUP",
    "text": "11.5 More on XLOOKUP\n\nNow we will learn some useful applications / capabilities of the function that was introduced in the last video.\nNOTE: These examples used to be very convoluted with older Excel functions, but with XLOOLUP() there is no need to learn HLOOKUP(), VLOOKUP() or INDEX(MATCH()).\nFILES: more-on-xlookup-STARTER.xlsx and more-on-xlookup-COMPLETED.xlsx\n\n\n\nHere is the written tutorial for the video.",
    "crumbs": [
      "Excel",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Notes -- Reports</span>"
    ]
  },
  {
    "objectID": "notes-excel-reports.html#panel-chart",
    "href": "notes-excel-reports.html#panel-chart",
    "title": "11  Notes – Reports",
    "section": "11.6 Panel Chart",
    "text": "11.6 Panel Chart\n\nThis is a specific application of Pivot Tables that we can tie back into creating Charts.\nWill see later in course that this type of plot is much easier to do in other software and looks much better. In addition to type of plot we should also consider the best tool (in terms of ease of application and quality of final product) to use to make it.\nFILES: panel-chart-STARTER.xlsx and panel-chart-COMPLETED.xlsx",
    "crumbs": [
      "Excel",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Notes -- Reports</span>"
    ]
  },
  {
    "objectID": "notes-excel-reports.html#homework",
    "href": "notes-excel-reports.html#homework",
    "title": "11  Notes – Reports",
    "section": "11.7 Homework",
    "text": "11.7 Homework\nASSIGNMENT LINK: Chapter 12",
    "crumbs": [
      "Excel",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Notes -- Reports</span>"
    ]
  },
  {
    "objectID": "lab-excel-pivot-tables-and-combining-data.html#submission",
    "href": "lab-excel-pivot-tables-and-combining-data.html#submission",
    "title": "11  Lab – Pivot Tables and Combining Data",
    "section": "11.1 Submission",
    "text": "11.1 Submission\nSubmission\n\nPlease upload a completed workbook for this assignment to Canvas.\nPart of the grading will be the organization / cleanliness of the workbook.\n\nMake sure the final product looks professional and presentable, e.g. no extraneous work scattered about and data, plots and reports placed well.\n\n\nFILES\n\nlab-pivot-tables-and-combining-data.docx and lab-pivot-tables-and-combining-data-STARTER.xlsx\nNOTE: Instructors can contact me for solutions :)",
    "crumbs": [
      "Excel",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Lab -- Pivot Tables and Combining Data</span>"
    ]
  },
  {
    "objectID": "lab-excel-pivot-tables-and-combining-data.html#part-1-pivot-table-reports",
    "href": "lab-excel-pivot-tables-and-combining-data.html#part-1-pivot-table-reports",
    "title": "11  Lab – Pivot Tables and Combining Data",
    "section": "11.2 Part 1 – Pivot Table Reports",
    "text": "11.2 Part 1 – Pivot Table Reports\n\n11.2.1 Overview\n\nThis problem is an extension of the notes from Section 10.2, where we learned how to create, organize, and customize Pivot Tables.\nThe first tab of the accompanying workbook contains a dataset of biographical information for the Men’s and Women’s 2018 Olympic Hockey Teams from Canada and the United States; a subset is shown below:\n\n\n\n\n\n\n\n\n\n\n11.2.2 Assignment\n\nThe goal is to recreate the following Report via a Pivot Table, which compares the physical attributes for the Canadian vs USA team, with the option of looking at the Men’s or Women’s team.\n\n\n\n\n\n\n\n\n\nHere are the aspects you will need to consider while doing so:\n\nHow to structure the Pivot Table in terms of rows, columns, values and filters.\nHow to use the desired summary measures and apply formats.\nHow to design the Pivot Table in terms of layout, subtotals, grand totals, blank lines, etc.\nHow to style the Pivot Table in terms of shading, borders, headers in order to create a nice, presentable Report.\nHow to add user input option and customize the style.\n\n\nWhat will be looked at for grading\n\nCorrect layout of Report (rows and columns in final Report), correct summary measures with good formats, design and style of the final Report (shading, borders, headers), correct implementation and style of the user input option.",
    "crumbs": [
      "Excel",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Lab -- Pivot Tables and Combining Data</span>"
    ]
  },
  {
    "objectID": "lab-excel-pivot-tables-and-combining-data.html#part-2-combining-data-and-creating-reports",
    "href": "lab-excel-pivot-tables-and-combining-data.html#part-2-combining-data-and-creating-reports",
    "title": "11  Lab – Pivot Tables and Combining Data",
    "section": "11.3 Part 2 – Combining Data and Creating Reports",
    "text": "11.3 Part 2 – Combining Data and Creating Reports\n\n11.3.1 Overview\n\nThis problem is an application of the notes in Section 10.3, where we used XLOOKUP to combine tables and then create reports.\nThe second tab of the accompanying workbook contains a dataset with two tables: a reference table for the region each state belongs to a dataset of biographical information for all NBA players. Subsets of each are shown below:\n\n\n\n\n\n\n\n\n\n\n11.3.2 Assignment\n\nThe goal is to create a single combined dataset (i.e. attach the Region to the NBA players data) and create two reports and a visual.\n\n\nHere are the aspects you will need to consider for combining the datasets:\n\nHow to add a new column and bring in data from another table.\nHow to take into account non-matches.\nAfter creating the new column, do a data quality check and see if there were any non-matches. If there were some, can they be fixed easily? If so, do it and confirm the data is now properly merged.\n\nNow that the data is combined, you want to create two Reports.\n\nSummarizes the number of players from each Region, sorted from largest to smallest.\nSummarizes the number of players from each State, sorted alphabetically.\n\nThe second Report from above is well setup to create a Map Chart, which is a geographical map shaded based on the value of some measure (in this case the number of players). Here’s how:\n\nCreating a Map Chart will not work on a Pivot Table. So copy the Report and Paste Values next to it.\nHighlight new table and Insert -&gt; Map Chart.\nTry a few designs / layouts to see what looks best. Be sure to give the Map Chart an informative title and legend title.\n\n\nWhat will be looked at for grading\n\nCorrect formula to merge datasets, 100% matches of the merged data, two correct Reports, Map Chart.",
    "crumbs": [
      "Excel",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Lab -- Pivot Tables and Combining Data</span>"
    ]
  },
  {
    "objectID": "hw-excel-creating-more-engaging-reports.html#submission",
    "href": "hw-excel-creating-more-engaging-reports.html#submission",
    "title": "12  HW – Creating More Engaging Reports",
    "section": "12.1 Submission",
    "text": "12.1 Submission\nSubmission\n\nPlease upload a completed workbook for this assignment to Canvas.\nPart of the grading will be the organization / cleanliness of the workbook.\n\nMake sure the final product looks professional and presentable, e.g. no extraneous work scattered about and data, plots and reports placed well.\n\n\nFILES\n\nhw-creating-more-engaging-reports.docx and hw-creating-more-engaging-reports-STARTER.xlsx\nNOTE: Instructors can contact me for solutions :)\n\nIMPORTANT NOTE:\n\nCertain aspects in each part below have not been explicitly covered so far.\nVery often when researching a new method for software, we are trying to learn from a video or tutorial and apply it to our specific problem / dataset. So we need to be able to recognize the similarities, determine what applies, what doesn’t, and be able to follow along with our scenario. This will be your first practice!\nHere are links to a video and the corresponding tutorial that contains many short tips that will be referenced later (some of which we have covered).",
    "crumbs": [
      "Excel",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>HW -- Creating More Engaging Reports</span>"
    ]
  },
  {
    "objectID": "hw-excel-creating-more-engaging-reports.html#part-1-creating-reports-with-customized-features",
    "href": "hw-excel-creating-more-engaging-reports.html#part-1-creating-reports-with-customized-features",
    "title": "12  HW – Creating More Engaging Reports",
    "section": "12.2 Part 1 – Creating Reports with Customized Features",
    "text": "12.2 Part 1 – Creating Reports with Customized Features\n\n12.2.1 Overview\n\nThis problem furthers the ideas from the notes from Section 10.3, where worked with date variables in Pivot Tables and used alternate summary measures.\nThe first tab of the accompanying workbook contains a dataset of sales for a bike company; a subset of which is shown below:\n\n\n\n\n\n\n\n\n\nThe response variable Y is ‘Number of weekly riders’ and the other numeric variables are the explanatory X variables.\n\n\n\n12.2.2 Assignment\n\nThe goal is to create a Report that summarizes quarterly bike sales by Model with both numerical and visual components. A subset of the desired final Report is shown below:\n\n\n\n\n\n\n\n\n\nThis is a great way to incorporate a visual aspect into Reports to further emphasize what the numbers are showing.\n\n\nThe final Report displays measures for Profit. This needs to be calculated in the bike sales table before making the Pivot Table.\n\nAdd columns ‘Revenue’ and ‘Profit’ to the table.\nWrite formulas to calculate them. In simple terms: Revenue relates income from a sale, whereas profit is the money left over after accounting for the cost to make the product.\n\nNow that you have the raw data needed for the Report, you can start creating it. Here are the aspects you will need to consider while doing so (just the numerical parts for now):\n\nHow to structure the Pivot Table in terms of rows, columns, values and filters.\nHow to get the sale Date to appear as Quarters.\nHow to use the desired summary measures and apply formats.\nHow to calculate ‘% Diff’, which represents the percentage difference in total profit relative to the previous Quarter for each Model (refer to the Tip #6 in the source linked at the top for help with this if needed).\n\nNow you can add the custom formatting for the visual component. Here’s how:\n\nAdd a copy of the ‘% Diff’ measure from above to the Report.\nFollow along with Tip #7 in the source linked at the top. If you want to be creative, try a few different symbols.\n\nLastly, format the Pivot Table to be a nice, presentable Report. Here are the aspects you will need to consider while doing so:\n\nHow to have only concise and needed headers.\nHow to not show unnecessary columns and have appropriately sized columns.\nHow to style the Report (i.e. shading and borders).\n\n\nWhat will be looked at for grading\n\nCorrect layout of Report (rows and only needed columns in final Report), correct summary measures with good formats, correct implementation of the visual component, design and style of the final Report (shading, borders, headers, column sizing).",
    "crumbs": [
      "Excel",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>HW -- Creating More Engaging Reports</span>"
    ]
  },
  {
    "objectID": "hw-excel-creating-more-engaging-reports.html#part-2-combining-data-and-creating-reports-with-visuals",
    "href": "hw-excel-creating-more-engaging-reports.html#part-2-combining-data-and-creating-reports-with-visuals",
    "title": "12  HW – Creating More Engaging Reports",
    "section": "12.3 Part 2 – Combining Data and Creating Reports with Visuals",
    "text": "12.3 Part 2 – Combining Data and Creating Reports with Visuals\n\n12.3.1 Overview\n\nThis problem furthers the ideas from the notes from Section 10.5 where we applied the optional arguments of XLOOKUP to bring in data, and also builds on Part 1.\nThe second tab of the accompanying workbook contains a dataset with three tables: an employee dataset which shows information relating to their hire, a table for the current system for assigning raises and a table for the new proposed method. A subset of the employee data and both raise tables are shown below:\n\n\n\n\n\n\n\n\n\nThe setup of the data will be important. Every time an employee is hired, transferred or promoted, a new record is added. This means employees like Eliseo Bittner, who moved from HR to Finance, and Jayna McGraw, who was promoted with a salary increase, all have more than one row.\nThe Standard Raise assigns a flat $ amount based on salary bracket, while the Proposed Raise is based on percentage of salary with different percentages for each salary bracket.\n\n\n\n12.3.2 Assignment\n\nThe goal is to use XLOOKUP to create a Report that demonstrates the effect of a new proposed method for assigning raises, relative to the current standard way.\n\nThis report will be based on regular data (i.e. not aggregated data), which means you won’t be using a Pivot Table.\nAdditionally, it will incorporate a visual component in a different way that also captures magnitude of the numbers they represent rather than just the sign +/-, as shown below:\n\n\n\n\n\n\n\n\n\n\nThe first step is to create a dataset of only the most current information about the employees. Here are the aspects you will need to consider while doing so:\n\nCreate a unique list of employee names by copying the entire list to a new table and then removing duplicates (do to this: Data -&gt; Remove Duplicates). Later we will learn a function to do this!\nHow to use a single XLOOKUP to bring in the corresponding Start Date, Department and Salary.\nWhich optional argument of XLOOKUP is needed to find only the most recent record (in terms of Start Date) for employees who have been transferred or promoted.\n\nNow that you have up-to-date information, the two different raises can be brought into the Report. Here are the aspects you will need to consider while doing so:\n\nBoth methods follow the same rule for assigning raises: Based on Salary, the employee receives the bonus at the next lowest cutoff. For example, if an employee makes $65,000, their bonus will be $1,500 or 1.5%.\nHow to use XLOOKUP to bring in the correct Standard Raise. Then repeat for the Proposed Raise.\n\nNow you can add the data bars for the effect of the Proposed Raise. Here’s how:\n\nCreate a new column that calculates in $ how much more or less the Proposed Raise is relative to the Standard Raise.\nFollow along with Tip #4 in the source linked at the top. Note that It adds data bars to a Pivot Table, but it should be similar for a regular table. If it isn’t clear, find another tutorial (not all are perfect for exactly what you need).\n\nNow with all of the needed information and displays in the Report, it can be styled to be presentable and organized to illuminate any trends. Here are some aspects to consider and questions to answer:\n\nHow to style the Report (i.e. shading and borders).\nHow to organize the Report to answer the following questions. Add a text box to your workbook with a quick write-up for each, referencing your Report when necessary.\n\n\nCompany wide, does the Proposed Raise method result employees getting larger or smaller raises? How do you know or how can it be shown?\nIs there a specific department that benefits most from the Proposed Raises? How can this be shown? 3.In general, who benefits most from the Proposed Raises, employees in lower or higher salary brackets? How can this be shown?\n\n\nWhat will be looked at for grading\n\nCorrectly removed duplicates, correct use of XLOOKUPs to bring in all the needed data, correct implementation of data bars for the calculated Proposed Raise Effect, style of final Report, organization and writeups to support answers to the questions at the end in (d).",
    "crumbs": [
      "Excel",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>HW -- Creating More Engaging Reports</span>"
    ]
  },
  {
    "objectID": "notes-excel-dynamic-charts-and-dashboards.html#preface",
    "href": "notes-excel-dynamic-charts-and-dashboards.html#preface",
    "title": "13  Notes – Dynamic Charts and Dashboards",
    "section": "13.1 Preface",
    "text": "13.1 Preface\n\nBelow is all of the content for this section along with the corresponding assignments (in the recommended order).\nBe sure to follow along with all of the videos using the provided Excel files AND complete the additional Exercises.\nPost any questions related to content or assignments in the corresponding discussion board.",
    "crumbs": [
      "Excel",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Notes -- Dynamic Charts and Dashboards</span>"
    ]
  },
  {
    "objectID": "notes-excel-dynamic-charts-and-dashboards.html#sec-notes-dynamic-charts",
    "href": "notes-excel-dynamic-charts-and-dashboards.html#sec-notes-dynamic-charts",
    "title": "13  Notes – Dynamic Charts and Dashboards",
    "section": "13.2 Dynamic Charts Part 1 and Part 2",
    "text": "13.2 Dynamic Charts Part 1 and Part 2\n\nNow we are going to learn how to make our charts dynamic, meaning that when we change the data our chart updates automatically.\nAdditionally we add some design thinking by bringing focus to certain aspects of the charts.\nFILES: dynamic-charts-part1-STARTER.xlsx and dynamic-charts-part1-COMPLETED.xlsx\n\n\n\nHere is the written tutorial for the video.\nThis video covers another common dynamic feature of charts that be used for increased emphasis and information.\nQuote from video and how it applies to us: “You picked the wrong thing to be good at”.\n\nOur goal is to learn the functionality and capability of the software tools to make processes as dynamic and automated as possible.\n“Work hard to be lazy” will be a common theme, especially when we start programming in R!\n\nFILES: dynamic-charts-part2-STARTER.xlsx and dynamic-charts-part2-COMPLETED.xlsx",
    "crumbs": [
      "Excel",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Notes -- Dynamic Charts and Dashboards</span>"
    ]
  },
  {
    "objectID": "notes-excel-dynamic-charts-and-dashboards.html#sec-notes-dynamic-dashboards-part1",
    "href": "notes-excel-dynamic-charts-and-dashboards.html#sec-notes-dynamic-dashboards-part1",
    "title": "13  Notes – Dynamic Charts and Dashboards",
    "section": "13.3 Dynamic Dashboards Part 1",
    "text": "13.3 Dynamic Dashboards Part 1\n\nThis video introduces us to creating Dashboards, which are very clean, effective ways of displaying results.\nIf we ever need aggregated data for a chart, our strategy is to make a pivot table with a pivot chart; then we can add functionality to make it dynamic based on user input.\nFILES: dynamic-dashboards-part1-STARTER.xlsx and dynamic-dashboards-part1-COMPLETED.xlsx",
    "crumbs": [
      "Excel",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Notes -- Dynamic Charts and Dashboards</span>"
    ]
  },
  {
    "objectID": "notes-excel-dynamic-charts-and-dashboards.html#lab",
    "href": "notes-excel-dynamic-charts-and-dashboards.html#lab",
    "title": "13  Notes – Dynamic Charts and Dashboards",
    "section": "13.4 Lab",
    "text": "13.4 Lab\nASSIGNMENT LINK: Chapter 14",
    "crumbs": [
      "Excel",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Notes -- Dynamic Charts and Dashboards</span>"
    ]
  },
  {
    "objectID": "notes-excel-dynamic-charts-and-dashboards.html#excel-functions",
    "href": "notes-excel-dynamic-charts-and-dashboards.html#excel-functions",
    "title": "13  Notes – Dynamic Charts and Dashboards",
    "section": "13.5 5 Excel Functions",
    "text": "13.5 5 Excel Functions\n\nThis video introduces a suite of functions that will help us create dynamic dashboards in the next video.\nFILES: 5-excel-functions-STARTER.xlsx and 5-excel-functions-COMPLETED.xlsx\n\n\n\nHere is the written tutorial for the video.",
    "crumbs": [
      "Excel",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Notes -- Dynamic Charts and Dashboards</span>"
    ]
  },
  {
    "objectID": "notes-excel-dynamic-charts-and-dashboards.html#sec-notes-dynamic-dashboards-part2",
    "href": "notes-excel-dynamic-charts-and-dashboards.html#sec-notes-dynamic-dashboards-part2",
    "title": "13  Notes – Dynamic Charts and Dashboards",
    "section": "13.6 Dynamic Dashboards Part 2",
    "text": "13.6 Dynamic Dashboards Part 2\n\nThis video puts everything together and uses the functions from the previous video to create dynamic dashboards.\nFILES: dynamic-dashboards-part2-STARTER.xlsx and dynamic-dashboards-part2-COMPLETED.xlsx",
    "crumbs": [
      "Excel",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Notes -- Dynamic Charts and Dashboards</span>"
    ]
  },
  {
    "objectID": "notes-excel-dynamic-charts-and-dashboards.html#homework",
    "href": "notes-excel-dynamic-charts-and-dashboards.html#homework",
    "title": "13  Notes – Dynamic Charts and Dashboards",
    "section": "13.7 Homework",
    "text": "13.7 Homework\nASSIGNMENT LINK: Chapter 15",
    "crumbs": [
      "Excel",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Notes -- Dynamic Charts and Dashboards</span>"
    ]
  },
  {
    "objectID": "lab-excel-dynamic-charts-and-dashboards.html#submission",
    "href": "lab-excel-dynamic-charts-and-dashboards.html#submission",
    "title": "14  Lab – Dynamic Charts and Dashboards",
    "section": "14.1 Submission",
    "text": "14.1 Submission\nSubmission\n\nPlease upload a completed workbook for this assignment to Canvas.\nPart of the grading will be the organization / cleanliness of the workbook.\n\nMake sure the final product looks professional and presentable, e.g. no extraneous work scattered about and data, plots and reports placed well.\n\n\nFILES\n\nlab-dynamic-charts-and-dashboards.docx and lab-dynamic-charts-and-dashboards-STARTER.xlsx\nNOTE: Instructors can contact me for solutions :)",
    "crumbs": [
      "Excel",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Lab -- Dynamic Charts and Dashboards</span>"
    ]
  },
  {
    "objectID": "lab-excel-dynamic-charts-and-dashboards.html#part-1-dynamically-formatted-line-chart",
    "href": "lab-excel-dynamic-charts-and-dashboards.html#part-1-dynamically-formatted-line-chart",
    "title": "14  Lab – Dynamic Charts and Dashboards",
    "section": "14.2 Part 1 – Dynamically Formatted Line Chart",
    "text": "14.2 Part 1 – Dynamically Formatted Line Chart\n\n14.2.1 Overview\n\nThis problem is an extension of the notes from Section 13.2, where we dynamically highlighted the minimum and maximum points on a line chart.\nThe first tab of the accompanying workbook contains a dataset of weekly sales; a subset is shown below:\n\n\n\n\n\n\n\n\n\n\n14.2.2 Assignment\n\nThe goal is to recreate the following plot, which dynamically highlights the smallest 2 and the largest 2 data points of the line chart.\n\n\n\n\n\n\n\n\n-   This is one way that we highlight the important information from a big chart (if there is no way around a big chart).\n\nHere are the aspects you will need to consider while doing so:\n\nMIN() and MAX() check for the single smallest and largest values in an array. To check the k smallest or k largest, use SMALL() and LARGE(), respectively. Try to setup a mini example (such as 1,2,3,4,5) to see how these functions work.\nHow to setup the data to have the correct conditional formatting.\nHow to format the lines and markers to emphasize the extreme points.\nHow to have informative data labels to make it clear what each highlighted point is / represents.\nSuppose this worksheet will be presented, how to remove clutter of any additional work needed for the plot and only show the original data and the plot.\n\nTo confirm your setup works as desired, change the following data points, and see if the plot now highlights the correct points:\n\nWeek 5 = 950, Week 12 = 118, Week 25 = 120 and Week 35 = 940\n\n\nWhat will be looked at for grading\n\nCorrect formula(s) for checking extreme points, dynamic conditional formatting of the extreme points on the plot, informative data labels, color scheme of plot with correct emphasis.",
    "crumbs": [
      "Excel",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Lab -- Dynamic Charts and Dashboards</span>"
    ]
  },
  {
    "objectID": "lab-excel-dynamic-charts-and-dashboards.html#part-2-dynamic-dashboard-using-pivot-tables-and-pivot-charts",
    "href": "lab-excel-dynamic-charts-and-dashboards.html#part-2-dynamic-dashboard-using-pivot-tables-and-pivot-charts",
    "title": "14  Lab – Dynamic Charts and Dashboards",
    "section": "14.3 Part 2 – Dynamic Dashboard using Pivot Tables and Pivot Charts",
    "text": "14.3 Part 2 – Dynamic Dashboard using Pivot Tables and Pivot Charts\n\n14.3.1 Overview\n\nThis problem furthers the ideas from the notes Section 13.3, where we created a dynamic dashboard using Pivot Tables and Pivot Charts.\nThe second tab of the accompanying workbook contains a dataset of students’ test scores for a standardized test, along with some demographic and preparation information; a subset is shown below:\n\n\n\n\n\n\n\n\n\n\n14.3.2 Assignment\n\nThe goal is to create a dynamic dashboard that visualizes student performance based on the level of education of their parents.\nHere are the features that need to be included in your final dashboard:\n\nReport that summarizes the Average Final Score (which equals average of the three individual scores: math, reading and writing) by Parental Level of Education.\nA Line Chart that visualizes the Report.\nHas the option for the user to select whether the Report / Chart show information for Male or Female students and whether Test Prep Course was completed or not.\nAll of the above features organized together as a Dashboard.\n\nHere are some aspects you will need to consider while doing so:\n\nHow to format the Report and Chart logically based on the levels of education.\nHow to incorporate user input for Gender and Test Prep Course.\nWhen different subsets of the data are shown based on the input, pay attention to the Chart and specifically the scale. Is it hard to make easy visual comparisons of the different sets of students based on what happens? Try to solve this.\nHow to style each individual part and the collective to look like a nice, presentable Dashboard.\n\n\nWhat will be looked at for grading\n\nCorrect setup of Report and Chart, implementation of the user input, dynamic Report / Chart (chart should include solution to the visual comparison problem mentioned above), style of final Dashboard.",
    "crumbs": [
      "Excel",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Lab -- Dynamic Charts and Dashboards</span>"
    ]
  },
  {
    "objectID": "hw-excel-dynamic-charts-and-dashboards.html#submission",
    "href": "hw-excel-dynamic-charts-and-dashboards.html#submission",
    "title": "15  HW – Dynamic Charts and Dashboards",
    "section": "15.1 Submission",
    "text": "15.1 Submission\nSubmission\n\nPlease upload a completed workbook for this assignment to Canvas.\nPart of the grading will be the organization / cleanliness of the workbook.\n\nMake sure the final product looks professional and presentable, e.g. no extraneous work scattered about and data, plots and reports placed well.\n\n\nFILES\n\nhw-dynamic-charts-and-dashboards.docx and hw-dynamic-charts-and-dashboards-STARTER.xlsx\nNOTE: Instructors can contact me for solutions :)",
    "crumbs": [
      "Excel",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>HW -- Dynamic Charts and Dashboards</span>"
    ]
  },
  {
    "objectID": "hw-excel-dynamic-charts-and-dashboards.html#part-1-dynamically-formatted-bar-chart",
    "href": "hw-excel-dynamic-charts-and-dashboards.html#part-1-dynamically-formatted-bar-chart",
    "title": "15  HW – Dynamic Charts and Dashboards",
    "section": "15.2 Part 1 – Dynamically Formatted Bar Chart",
    "text": "15.2 Part 1 – Dynamically Formatted Bar Chart\n\n15.2.1 Overview\n\nThis problem is an application using ideas from the notes Section 13.2, where we conditionally formatted charts and implemented a dynamic target line, respectively.\nThe first tab of the accompanying workbook contains a dataset of sales for various companies, which is shown below:\n\n\n\n\n\n\n\n\n\n\n15.2.2 Assignment\n\nThe goal is to create a dynamic Bar Chart that colors the bars based on the relationship to dynamic Target Line, specifically highlighting those that are greater than the target.\n\nThis is one way that we highlight the important information from a big chart (if there is no way around a big chart).\n\nHere are the aspects you will need to consider while doing so:\n\nHow to setup dynamic Target Line.\nHow to setup conditional formatting of bars\nHow to label and style the Target Line, e.g. color, line style, etc. Suppose only the plot is going to be presented; the audience should be able to easily tell what the target is.\nHow to style Bar Chart, e.g. colors scheme and data labels.\n\nTo confirm your setup works as desired, start with Target = 250 and change to Target = 225 and see if the plot highlights the correct bars.\n\nWhat will be looked at for grading\n\nDynamic target line, dynamic conditional formatting of the bars based on the specific target, style of Target Line and Bar Chart (including color scheme data labels) with correct emphasis.",
    "crumbs": [
      "Excel",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>HW -- Dynamic Charts and Dashboards</span>"
    ]
  },
  {
    "objectID": "hw-excel-dynamic-charts-and-dashboards.html#part-2-dynamic-dashboard",
    "href": "hw-excel-dynamic-charts-and-dashboards.html#part-2-dynamic-dashboard",
    "title": "15  HW – Dynamic Charts and Dashboards",
    "section": "15.3 Part 2 – Dynamic Dashboard",
    "text": "15.3 Part 2 – Dynamic Dashboard\n\n15.3.1 Overview\n\nThis problem furthers the ideas from the notes Section 13.6, where we used Excel functions to create dynamic datasets, which out charts where then built off.\nThe second tab of the accompanying workbook contains a dataset with two tables: a master table for the monthly sales targets of each product and the monthly sales of each product; the target sales table and a subset of the monthly sales are shown below:\n\n\n\n\n\n\n\n\n\n\n15.3.2 Assignment\n\nThe goal is to recreate the following dynamic dashboard that includes all the labelled features:\n\n\n\n\n\n\n\n\n\nHere are the features that need to be included in final dashboard (as shown in image above):\n\nDynamic data: Only data for the selected product should display.\nDynamic chart title: Chart title should update automatically based on the selected product; see this tutorial for help.\nDynamic target line: Target line should update automatically based on the selected product; values from the master table of monthly targets.\nDynamic dropdown: If a new product is added, it should appear in the dropdown automatically.\n\nHere are specifications for the Dashboard:\n\nAll of the “prep work” for the plot and its features should be included on the ‘Part 2’ tab.\nCreate a new tab named ‘Dashboard’; this is where the final plot will go. Only the dropdown and plot should be in this tab.\nOn the ‘Dashboard’ tab, hide all other rows and columns so the only the dropdown and plot are showing. This is to increase focus on the plot and so nothing else can even be clicked on.\nStyle the plot and dashboard to be nice, and presentable.\n\nTo confirm your setup works as desired, add the following information to the two data tables and see if the drop down updates for the new product and the plot updates accordingly when it is selected:\n\nProduct = Filing Cabinet; Monthly Target = 160\nSales data (Jan – Dec): 94, 120, 96, 164, 186, 94, 84, 171, 145, 164, 124, 127\n\n\nWhat will be looked at for grading\n\nCorrect formulas in the prep work, correct implementation of the dynamic features in the plot, correct organization and good style of the final plot and dashboard.",
    "crumbs": [
      "Excel",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>HW -- Dynamic Charts and Dashboards</span>"
    ]
  },
  {
    "objectID": "module-tableau.html",
    "href": "module-tableau.html",
    "title": "Tableau",
    "section": "",
    "text": "Here is an overview of the content and corresponding assignments.",
    "crumbs": [
      "Tableau"
    ]
  },
  {
    "objectID": "install-tableau-and-tableau-prep-builder.html#how-to-install-tableau-and-tableau-prep-builder",
    "href": "install-tableau-and-tableau-prep-builder.html#how-to-install-tableau-and-tableau-prep-builder",
    "title": "16  Install Excel",
    "section": "16.1 How to Install Tableau and Tableau Prep Builder",
    "text": "16.1 How to Install Tableau and Tableau Prep Builder\n\nTableau offers free one-year Tableau licenses to students, which includes access to entire eLearning platform.\n\n\n\n\n\n\n\n\n\nNavigate to this link and click “Get Tableau for Free”. Then follow the registration instructions. After which you will receive an email with further information, where you will need to do the following:\n\nDownload and install “Tableau Desktop” AND “Tableau Prep”.\nOpen Tableau Desktop application and enter the product key given in the email to activate the license. Note that this will be valid for one year, but it can be renewed / applied for again.\nCreate an account for eLearning and register with the given access code.",
    "crumbs": [
      "Tableau",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Install Excel</span>"
    ]
  },
  {
    "objectID": "install-tableau-and-tableau-prep-builder.html#next-assignment",
    "href": "install-tableau-and-tableau-prep-builder.html#next-assignment",
    "title": "16  Install Excel",
    "section": "16.2 Next Assignment",
    "text": "16.2 Next Assignment\n\nOur first work with Tableau will be the DataCamp assignment “Introduction to Tableau”.\nEven if it takes a while for Tableau to respond to your application, this assignment can be completed without Tableau installed on your computer.\nAs you will see, within DataCamp there is a version called Tableau Public, which would be sufficient for starting out.",
    "crumbs": [
      "Tableau",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Install Excel</span>"
    ]
  },
  {
    "objectID": "install-tableau-and-tableau-prep-builder.html#tableau-elearning",
    "href": "install-tableau-and-tableau-prep-builder.html#tableau-elearning",
    "title": "16  Install Excel",
    "section": "16.3 Tableau eLearning",
    "text": "16.3 Tableau eLearning\n\nThis is Tableau’s online teaching platform that contains tons of great resources in the form of interactive courses or learning paths (kinda like a plan of courses).\n\n\n\n\n\n\n\n\n\nThese would be great supplementary resources as we are working through Tableau or a great way to continue learning Tableau outside of our class.\nI encourage you to browse around here to see what is available!",
    "crumbs": [
      "Tableau",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Install Excel</span>"
    ]
  },
  {
    "objectID": "install-tableau-and-tableau-prep-builder.html#having-trouble",
    "href": "install-tableau-and-tableau-prep-builder.html#having-trouble",
    "title": "16  Install Excel",
    "section": "16.4 Having Trouble?",
    "text": "16.4 Having Trouble?\n\nPlease reach out to me or the BSU Technology Help Desk as soon as possible.",
    "crumbs": [
      "Tableau",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Install Excel</span>"
    ]
  },
  {
    "objectID": "intro-to-tableau.html#course-introduction-to-tableau",
    "href": "intro-to-tableau.html#course-introduction-to-tableau",
    "title": "17  Introduction to Tableau",
    "section": "17.1 Course: Introduction to Tableau",
    "text": "17.1 Course: Introduction to Tableau\n\n\n\n\n\n\n\n\nThis course covers the basics of Tableau and introduces you to tools we will build on to create effective data visualizations. This is a new software to all of us, so it is especially important to spend the time familiarizing yourself with the platform.\nThis will serve as both content and an assignment to start the module.\nIt has 4 chapters that you will need to complete:\n\nGetting Started with Tableau\nBuilding and Customizing Visualizations\nDigging Deeper\nPresenting Your Data\n\nHOW TO WORK THROUGH THIS COURSE\n\nReminder that this course will be the most effective if you follow along with the videos and do them at the same time and take the time to actually do the exercises. Guessing just to get it done is not an effective learning strategy.\n\nI highly recommend downloading and opening the workbooks in Tableau on your personal computer rather than using Tableau Public within DataCamp. This will be more beneficial in getting you familiar with the platform you will be using.\nHere is a link to DOWNLOAD the workbooks / datasets used in the videos and exercises.",
    "crumbs": [
      "Tableau",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Introduction to Tableau</span>"
    ]
  },
  {
    "objectID": "intro-to-tableau.html#learn-more",
    "href": "intro-to-tableau.html#learn-more",
    "title": "17  Introduction to Tableau",
    "section": "17.2 Learn more!",
    "text": "17.2 Learn more!\n\nRemember that you have unlimited access to ANY DataCamp course until January 6, 2024.\nMake sure to take advantage of this if you are interested.",
    "crumbs": [
      "Tableau",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Introduction to Tableau</span>"
    ]
  },
  {
    "objectID": "intro-to-tableau.html#submission",
    "href": "intro-to-tableau.html#submission",
    "title": "17  Introduction to Tableau",
    "section": "17.3 Submission",
    "text": "17.3 Submission\n\nPlease upload this certificate for this assignment (a picture of it, or a word doc with the certificate in it, etc.). IT MUST INCLUDE YOUR NAME IN THE CERTIFICATE, or no credit will be given.",
    "crumbs": [
      "Tableau",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Introduction to Tableau</span>"
    ]
  },
  {
    "objectID": "notes-tableau-working-with-data.html#preface",
    "href": "notes-tableau-working-with-data.html#preface",
    "title": "18  Notes – Working with Data",
    "section": "18.1 Preface",
    "text": "18.1 Preface\n\nBelow is all of the content for this section along with the corresponding assignments (in the recommended order).\nBe sure to follow along with all of the videos using the provided Tableau workbooks (no additional exercises).\nPost any questions related to content or assignments in the corresponding discussion board.",
    "crumbs": [
      "Tableau",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Notes -- Working with Data</span>"
    ]
  },
  {
    "objectID": "notes-tableau-working-with-data.html#gapminder-visualization",
    "href": "notes-tableau-working-with-data.html#gapminder-visualization",
    "title": "18  Notes – Working with Data",
    "section": "18.2 Gapminder Visualization",
    "text": "18.2 Gapminder Visualization\n\nThe main goal of this lesson is get more familiar with using Tableau. We will do this by recreating the famous visualization shown in the Ted Talk shown below that analyzes how Life Expectancy in years (health) and GDP per capita (wealth) have changed over time in the world for various countries.",
    "crumbs": [
      "Tableau",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Notes -- Working with Data</span>"
    ]
  },
  {
    "objectID": "notes-tableau-working-with-data.html#connecting-to-mulitple-data-sources",
    "href": "notes-tableau-working-with-data.html#connecting-to-mulitple-data-sources",
    "title": "18  Notes – Working with Data",
    "section": "18.3 Connecting to Mulitple Data Sources",
    "text": "18.3 Connecting to Mulitple Data Sources\n\nTo do this we need to connect to multiple data sources and link fields across data sources.\nThis technique is called blending data, which is essentially linking data across common keys (fields).\n\nOPTIONAL watch: Video tutorial on blending data.\n\nFILES: Start with any blank Tableau workbook and recreating-gapminder-data folder, and recreating-gapminder-visualization-COMPLETED.twb\n\n https://youtu.be/1cdRDCjnH2A",
    "crumbs": [
      "Tableau",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Notes -- Working with Data</span>"
    ]
  },
  {
    "objectID": "notes-tableau-working-with-data.html#recreating-the-gapminder-visualization",
    "href": "notes-tableau-working-with-data.html#recreating-the-gapminder-visualization",
    "title": "18  Notes – Working with Data",
    "section": "18.4 Recreating the Gapminder Visualization",
    "text": "18.4 Recreating the Gapminder Visualization\n\nNow that we have the necessary data connected and formatted as needed, let’s recreate the visualization in Tableau.\n\n\n\nFILES: Continuing to work on files from above.",
    "crumbs": [
      "Tableau",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Notes -- Working with Data</span>"
    ]
  },
  {
    "objectID": "notes-tableau-working-with-data.html#tableau-prep-builder",
    "href": "notes-tableau-working-with-data.html#tableau-prep-builder",
    "title": "18  Notes – Working with Data",
    "section": "18.5 Tableau Prep Builder",
    "text": "18.5 Tableau Prep Builder\n\nNow we are going to introduce Tableau Prep Builder (the other Tableau application we downloaded), which allows us to visualize the process of manipulating our data.\nThis is a great video that explains many common data problems in industry and how Tableau Prep Builder can help (nothing to follow along with, just watch and enjoy :)",
    "crumbs": [
      "Tableau",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Notes -- Working with Data</span>"
    ]
  },
  {
    "objectID": "notes-tableau-working-with-data.html#joining-data-and-improving-visualization",
    "href": "notes-tableau-working-with-data.html#joining-data-and-improving-visualization",
    "title": "18  Notes – Working with Data",
    "section": "18.6 Joining Data and Improving Visualization",
    "text": "18.6 Joining Data and Improving Visualization\n\nAnother strategy when working with multiple data sources is to merge (join) them into a single dataset (table). Let’s do this to introduce some of the functionality of Tableau Prep Builder.\n\nOPTIONAL watch: Video tutorial on joining data and data relationships (note that for our purposes with this example, we couldn’t use this method directly in Tableau because we also need to pivot the data).\n\nThen we will recreate the previous visualization from the combined dataset, and add some more features.\nFILES: Start with any blank Tableau Prep Builder flow and join-gapminder-data-COMPLETED.tfl, which outputs joined-gapminder-data.hyper",
    "crumbs": [
      "Tableau",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Notes -- Working with Data</span>"
    ]
  },
  {
    "objectID": "notes-tableau-working-with-data.html#homework",
    "href": "notes-tableau-working-with-data.html#homework",
    "title": "18  Notes – Working with Data",
    "section": "18.7 Homework",
    "text": "18.7 Homework\nASSIGNMENT LINK: Chapter 19",
    "crumbs": [
      "Tableau",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Notes -- Working with Data</span>"
    ]
  },
  {
    "objectID": "hw-tableau-working-with-data.html#submission",
    "href": "hw-tableau-working-with-data.html#submission",
    "title": "19  HW – Working with Data",
    "section": "19.1 Submission",
    "text": "19.1 Submission\nSubmission\n\nPlease upload a completed workbook for this assignment to Canvas.\nPart of the grading will be the organization / cleanliness of the workbook.\n\nMake sure the final product looks professional and presentable, e.g. have your EDA worksheets labelled as such (EDA 1, EDA 2. etc.) and the final sheets / dashboard appropriately labelled so I know where to look.\n\n\nFILES\n\nhw-working-with-data.docx and gapminder.csv\nNOTE: Instructors can contact me for solutions :)\n\nVideo to watch first\n\nThis explains how (and why) to submit your work as a .twbx file instead of a .twb file.\nIf I cannot see your work, I will kindly ask you to resubmit as instructed so that it can be graded accordingly.",
    "crumbs": [
      "Tableau",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>HW -- Working with Data</span>"
    ]
  },
  {
    "objectID": "hw-tableau-working-with-data.html#overview",
    "href": "hw-tableau-working-with-data.html#overview",
    "title": "19  HW – Working with Data",
    "section": "19.2 Overview",
    "text": "19.2 Overview\n\nThis problem is an application of the methods from the notes in Chapter 18, where we learned how to join multiple datasets in Table Prep Builder and create animated visualizations.\nIt is designed to be open-ended, allowing you to explore different relationships and plot types.",
    "crumbs": [
      "Tableau",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>HW -- Working with Data</span>"
    ]
  },
  {
    "objectID": "hw-tableau-working-with-data.html#data-source",
    "href": "hw-tableau-working-with-data.html#data-source",
    "title": "19  HW – Working with Data",
    "section": "19.3 Data Source",
    "text": "19.3 Data Source\n\nThe Gapminder data that Hans Rosling’s visualization is built from a dataset that that combines data from multiple sources into unique coherent time-series about numerous health and socio-economic variables.\n\nThere are lots of other variables with data setup in a similar fashion available for download, which we will explore in this assignment.\nOur goal is to find other factors that could have a potentially significant relationship with life expectancy over time.\n\nNavigate to the Gapminder site and find TWO other variables to join with the already merged regions, population and life expectancy data accompanying this assignment.\nOnce on the website, scroll down to “Select an Indicator”, select a context, then download the csv file. For example:\n\n\n\n\n\n\n\n\n\nDATA QUALITY NOTE: We must choose variables that DO NOT HAVE values formatted like the red box above. These are in the data as text and therefore will not ever get treated as numbers.\nSo think about the scale of the variable and be sure to preview your data to make sure everything is formatted as a number in the .csv download.",
    "crumbs": [
      "Tableau",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>HW -- Working with Data</span>"
    ]
  },
  {
    "objectID": "hw-tableau-working-with-data.html#assignment",
    "href": "hw-tableau-working-with-data.html#assignment",
    "title": "19  HW – Working with Data",
    "section": "19.4 Assignment",
    "text": "19.4 Assignment\n\nThe goal is to work with data from multiple sources in Tableau Prep Builder and practice creating plots to glean trends / relationships in data in an attempt to tell a story.\n\n\nUse Table Prep Builder to join data.\n\nBefore visualizing the data, we need to join the data just as we did in the video notes.\nCreate a flow where you perform the following steps as necessary:\n\nConnect to data sources (csv files).\nRename fields (ensure header are correctly setup).\nPivot and rename resulting pivoted fields.\nAdd a clean step to convert Year to number (whole) so that it joins correctly.\nLEFT join new pivoted data to the existing gapminder.csv data (this way if the variable you chose doesn’t have much historical data we can still keep all the records from the original Gapminder and just have nulls for non-matched country-year combos).\nSetup Applied Join Clauses.\nRemove duplicated columns.\nOutput final data.\n\nA single merged dataset saved as a .hyper file with no duplicated columns is necessary before moving onto the next part.\n\nRecreate Hans Rosling’s visualization using one of your two variables instead of average income per person.\n\nOpen a new Tableau workbook and load the .hyper file created from Tableau Prep Builder. Click on data source and covert to extract. Then save the workbook as a .twbx file so that the data source is included when you submit the workbook on Canvas.\nThis is just recreating the steps from the notes to see if your variable has a significant relationship with life expectancy throughout time.\nAdd reference lines with formatting for the X and Y variables like we did in the notes.\n\nCreate at least TWO more polished plots visualizing the relationships between any of the variables. What will be looked at for grading\n\nYou may not (/ should not) use all of the plots that you create when exploring.\nPolished plots means that there are neat / informative titles and axis labels, well-chosen colors, visuals that make statistical sense (i.e. using the plots correctly based on the data types and context). Can you make a story from the plots and context of the data?\nThe plots you create can be as zoomed in on specific subsets of the data or very macro pictures like visual in part (a).\n\nExamples include: line plot of foreign aid given for countries in North America from 2010-18, boxplots of country population by region over time, etc.\nBe creative, find a trend!\n\n\nCreate a dashboard combining your polished plots with a Big Idea.\n\nOrganize your polished plots into a neat dashboard, where the title and/or subtitle is a nicely formatted sentence containing a “Big Idea” of your plots.\nRecall that the Big Idea from Storytelling with Data is the “so what” of your narrative that is boiled down to a single sentence. It has three components\n\nIt must 1) articulate your unique point of view 2) convey what’s at stake and 3) be a complete sentence.\n\nApply these components to the context of the data and your visuals.\n\n\nWhat will be looked at for grading\n\nSingle joined dataset correctly saved in the .twbx file, correct recreation of the Hans Rosling visualization with a new variable, organization of the final dashboard, attempted narrative via Big Idea statement, quality of the polished plots.",
    "crumbs": [
      "Tableau",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>HW -- Working with Data</span>"
    ]
  },
  {
    "objectID": "notes-tableau-parameters.html#preface",
    "href": "notes-tableau-parameters.html#preface",
    "title": "20  Notes – Parameters",
    "section": "20.1 Preface",
    "text": "20.1 Preface\n\nBelow is all of the content for this section along with the corresponding assignments (in the recommended order).\nBe sure to follow along with all of the videos using the provided Tableau workbooks (no additional exercises).\nPost any questions related to content or assignments in the corresponding discussion board.",
    "crumbs": [
      "Tableau",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Notes -- Parameters</span>"
    ]
  },
  {
    "objectID": "notes-tableau-parameters.html#parameters",
    "href": "notes-tableau-parameters.html#parameters",
    "title": "20  Notes – Parameters",
    "section": "20.2 Parameters",
    "text": "20.2 Parameters\n\nIn addition to getting more familiar with navigating Tableau, these videos introduce parameters, which are ways to make our plots and dashboards more interactive / dynamic.\nFILES: 10+3-use-cases-for-parameters.twbx (the needed data should be part of the packaged Tableau file)\n\n\n\nNOTES\n\nData (the specific values) in video are slightly different than the data in the workbook, but all the column names and important items are the exact same.\nDate Range example: To get the date format like in the video, do the following:\n\nDisplay format = Custom -&gt; Format = MMMM dd, yyyy\n\nWeb Traffic and Date Range Unrelated example: We don’t have the ‘Web Traffic’ data, so instead use the ‘Coffee Sales’ data source and the [Date] column.\n\nREQUIRED WATCH only from minutes 2:22 - 9:54 of the next video (skip the intro and watch only the first two examples).\n\nOPTIONAL (additional) content: Feel free to watch the rest of the video, there are some cool examples (just not as clean of a video).",
    "crumbs": [
      "Tableau",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Notes -- Parameters</span>"
    ]
  },
  {
    "objectID": "notes-tableau-parameters.html#types-of-graphs-in-tableau",
    "href": "notes-tableau-parameters.html#types-of-graphs-in-tableau",
    "title": "20  Notes – Parameters",
    "section": "20.3 Types of Graphs in Tableau",
    "text": "20.3 Types of Graphs in Tableau\n\nThe following image shows what type of relationships can be described by which type of visual objects. It may be helpful for the explanatory data analysis as part of the homework.",
    "crumbs": [
      "Tableau",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Notes -- Parameters</span>"
    ]
  },
  {
    "objectID": "notes-tableau-parameters.html#homework",
    "href": "notes-tableau-parameters.html#homework",
    "title": "20  Notes – Parameters",
    "section": "20.4 Homework",
    "text": "20.4 Homework\nASSIGNMENT LINK: Chapter 21",
    "crumbs": [
      "Tableau",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Notes -- Parameters</span>"
    ]
  },
  {
    "objectID": "hw-tableau-parameters.html#submission",
    "href": "hw-tableau-parameters.html#submission",
    "title": "21  HW – Parameters",
    "section": "21.1 Submission",
    "text": "21.1 Submission\nSubmission\n\nPlease upload a completed workbook for this assignment to Canvas.\nPart of the grading will be the organization / cleanliness of the workbook.\n\nMake sure the final product looks professional and presentable, e.g. have your EDA worksheets labelled as such (EDA 1, EDA 2. etc.) and the final sheets / dashboard appropriately labelled so I know where to look.\n\n\nFILES\n\nparameters-STARTER.twbx (the needed data should be part of the packaged Tableau file, but if not here it is: data-halloween.csv)\nNOTE: Instructors can contact me for solutions :)",
    "crumbs": [
      "Tableau",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>HW -- Parameters</span>"
    ]
  },
  {
    "objectID": "hw-tableau-parameters.html#overview",
    "href": "hw-tableau-parameters.html#overview",
    "title": "21  HW – Parameters",
    "section": "21.2 Overview",
    "text": "21.2 Overview\n\nThis problem is an application of the techniques from the notes in Chapter 22, where we learned many ways to incorporate parameters into our visualizations.\nIt is designed to be open-ended, allowing you to explore many plot types in Tableau while creating a narrative.",
    "crumbs": [
      "Tableau",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>HW -- Parameters</span>"
    ]
  },
  {
    "objectID": "hw-tableau-parameters.html#data-sources",
    "href": "hw-tableau-parameters.html#data-sources",
    "title": "21  HW – Parameters",
    "section": "21.3 Data Sources",
    "text": "21.3 Data Sources\n\nThe connected data source in the accompanying workbook combines information from three different sources about three contexts: Halloween candy data, weather data and economic data. A sample is shown below with some aspects highlighted, followed by detailed descriptions:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n21.3.1 Halloween Data\n\nOverview\n\nContains yearly data on the number of candies given to trick-or-treaters in Cincinnati, OH dating back to 2008.\n\nSpecifics\n\nThe trick-or-treat count (Count) was recorded in 30-minute intervals (Time) (each row above = half hour interval).\nThe night of trick-or-treating has always been on October 31st each year (some neighborhoods change the night of trick-or-treating).\nOfficial trick or treat hours are from 6pm-8pm, but there are often “stragglers” past 8pm that are not turned away. These stragglers are counted in the 8pm-8:15pm time slot. There has never been a trick-or-treater past 8:15pm.\nThe type of candy did not vary year by year. It is always a general mix of candy purchased in bulk variety bags.\nLocation of home: Corner home in a neighborhood in East Walnut Hills/Evanston area, Cincinnati, OH 45207.\n\nSource\n\nhttps://www.dataplusscience.com/HalloweenData.html\n\n\n\n\n21.3.2 Weather Data\n\nOverview\n\nContains the daily minimum and maximum temperatures and precipitation levels on October 31st from 2008-16.\n\nSpecifics\n\nUnits: Minimum (Tmin) and maximum (Tmax) temperatures are recorded in Fahrenheit and precipitation (Prcp) in inches.\nLocation: Measurements taken at a station in Cheviot, OH (about 10 miles away from the East Walnut Hills area).\nMissing values: Data is only for 2008-16; so, there is no data for 2017-22 (this is highlighted in the pink shaded boxes).\nRepeated values: Because each row corresponds to a half hour candy interval on the same day, the temperature and precipitation values are the same for every interval that day (this is highlighted with the yellow and orange shaded boxes).\n\nSource\n\nNCEI database at https://www.ncei.noaa.gov/pub/data/ghcn/daily/\n\n\n\n\n21.3.3 Economic Data\n\nOverview\n\nContains the gross domestic product (Gdp millions) for Cincinnati, OH in millions of dollars for years 2008-21.\n\nSpecifics\n\nGDP definition: Measure of the market value of all final goods and services produced within an area in a particular period of time.\nEach value represents the GDP for that particular year.\nMissing values: Data is only for 2008-21; so, there is no data for 2022 (this is highlighted in the pink shaded boxes).\nRepeated values: Because each row corresponds to a half hour candy interval on the same day, the GDP values are the same for every interval that day (this is highlighted with the yellow and orange shaded boxes).\n\nSource\n\nBureau of Economic Analysis at https://fred.stlouisfed.org/series/NGMP17140\n\n\n\n\n21.3.4 Assignment\n\nThe goal is to visualize the dataset to find trends between the amount of candy given out, the weather during on Halloween and the economy for the year.\n\n\nDetermine a story or goal of the visualization.\n\nSimple examples include:\n\nForecast future trick-or-treaters or estimate future candy need.\nExplore variation of the number of trick-or-treaters year by year.\nVisualize total number of candies as a function of weather or economy.\n\nThis may take some exploratory data analysis and the creation of many plots.\n\nCreate at least two polished plots that support your narrative.\n\nYou may not (/ should not) use all of the plots that you create when exploring.\nPolished plots means that there are neat / informative titles and axis labels, well-chosen colors, visuals that make statistical sense (i.e. using the plots correctly based on the data types and context) and they add to the story you are trying to tell\n\nNote that when using the weather data and economic data, the aggregation function should be AVG() so that the value stays the same (remember that it is repeated in each row = half hour interval).\n\nPlots MUST use parameters, at least one for each plot.\n\nParameters MUST be used in at least two different ways.\nFor example, one for changing the color of points on a scatterplot above or below the line and one for adding in a reference line for a date.\n\nFeel free to make more than two plots or use more parameters, but the minimum requirement is at TWO PLOTS and TWO differently used PARAMETERS.\n\nCreate a dashboard combining your polished plots with a Big Idea.\n\nOrganize your polished plots + shown (or incorporated) parameters into a neat dashboard, where the title and/or subtitle is a nicely formatted sentence containing the “Big Idea” of your narrative.\nRecall that the Big Idea from Storytelling with Data is the “so what” of your narrative that is boiled down to a single sentence. It has three components\n\nIt must 1) articulate your unique point of view 2) convey what’s at stake and 3) be a complete sentence.\n\nApply these components to our Halloween context and your visuals.\n\n\nWhat will be looked at for grading\n\nOrganization of the final dashboard, narrative via Big Idea statement, quality of the polished plots and how they contribute to the narrative, implementation of parameters.",
    "crumbs": [
      "Tableau",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>HW -- Parameters</span>"
    ]
  },
  {
    "objectID": "notes-tableau-dashboards.html#preface",
    "href": "notes-tableau-dashboards.html#preface",
    "title": "23  Notes – Dashboards",
    "section": "23.1 Preface",
    "text": "23.1 Preface\n\nBelow is all of the content for this section along with the corresponding assignments (in the recommended order).\nBe sure to follow along with all of the videos using the provided Tableau workbooks (no additional exercises).\nPost any questions related to content or assignments in the corresponding discussion board.",
    "crumbs": [
      "Tableau",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Notes -- Parameters</span>"
    ]
  },
  {
    "objectID": "notes-tableau-dashboards.html#dashboards-in-tableau",
    "href": "notes-tableau-dashboards.html#dashboards-in-tableau",
    "title": "23  Notes – Dashboards",
    "section": "23.2 Dashboards in Tableau",
    "text": "23.2 Dashboards in Tableau\n\nThe real power of Tableau is in creating dashboards. These videos will take you through designing a complete, effective, well-designed dashboard step-by-step.\nFILES: dashboards-STARTER.twbx (the needed data should be part of the packaged Tableau file, but if not here it is: sample-superstore.csv) and dashboards-COMPLETED.twbx\nNOTES: These are important mini items to make sure you can follow all the steps in the video; if you get stuck somewhere, look here first!\n\nPLAYBACK\n\nI recommend watching the videos on a slower speed in order to keep up with her steps! Some parts are a bit quick, so be prepared to pause and/or rewind often to catch everything.\n\nSHAPES\n\nDownload this items in this folder.\nThen move the ‘Custom Categories’ folder to the following location on your computer: ‘My Tableau Repository’ (This was automatically made when you installed Tableau) -&gt; ‘Shapes’ -&gt; Place in here.\nThen when in the ‘Edit Shape’ dialog (menu), click ‘Reload Shapes’ for our ‘Custom Categories’ to appear.\n\nMAC USERS\n\nSome of the keyboard shortcuts she uses are Windows specific, here are the Mac equivalents:\nWindows ===&gt; Mac\nRight click + drag ===&gt; Option + drag (this opens a Drop Field dialog of aggregation options)\nControl + drag ===&gt; Command + drag (this is to duplicate a pill / field on a shelf)\n\nCONTAINERS on the dashboard\n\nYou may or may not be able to ‘Fix Height’ on some of the containers. They don’t have to be setup exactly like hers, just the general idea is good enough.\nIt may take some time to organize the formatting of the containers and spacing can be finicky, but it is part of the process.\n\nPUBLISH to server\n\nSkip this part, not relevant for us.",
    "crumbs": [
      "Tableau",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Notes -- Parameters</span>"
    ]
  },
  {
    "objectID": "notes-tableau-dashboards.html#dashboard-design",
    "href": "notes-tableau-dashboards.html#dashboard-design",
    "title": "23  Notes – Dashboards",
    "section": "23.3 Dashboard Design",
    "text": "23.3 Dashboard Design\n\nHere are some information about how your audience will look at dashboards as well as some tips in how to structure your dashboard to optimize its’ effectiveness.\nThe emphasis areas shown below agree with the Storytelling With Data idea that we tend to read plots in a “Z” pattern. So this is how we setup our dashboards as well in terms of most emphasis to least.\nFinally there is a checklist for items and aspects to have incorporated in your final dashboards so that users are able to easily glean the information that we want to focus on.",
    "crumbs": [
      "Tableau",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Notes -- Parameters</span>"
    ]
  },
  {
    "objectID": "notes-tableau-dashboards.html#homework",
    "href": "notes-tableau-dashboards.html#homework",
    "title": "23  Notes – Dashboards",
    "section": "23.4 Homework",
    "text": "23.4 Homework\n&lt; link &gt;",
    "crumbs": [
      "Tableau",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Notes -- Parameters</span>"
    ]
  },
  {
    "objectID": "hw-tableau-dashboards.html#submission",
    "href": "hw-tableau-dashboards.html#submission",
    "title": "23  HW – Dashboards",
    "section": "23.1 Submission",
    "text": "23.1 Submission\nSubmission\n\nPlease upload a completed workbook for this assignment to Canvas.\nPart of the grading will be the organization / cleanliness of the workbook.\n\nMake sure the final product looks professional and presentable, e.g. have your EDA worksheets labelled as such (EDA 1, EDA 2. etc.) and the final sheets / dashboard appropriately labelled so I know where to look.\n\n\nFILES\n\nhw-dashboards.docx, start with any blank Tableau workbook, and the following files: bike-sales.csv and folder",
    "crumbs": [
      "Tableau",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>HW -- Dashboards</span>"
    ]
  },
  {
    "objectID": "hw-tableau-dashboards.html#video-description",
    "href": "hw-tableau-dashboards.html#video-description",
    "title": "23  HW – Dashboards",
    "section": "23.2 Video Description",
    "text": "23.2 Video Description",
    "crumbs": [
      "Tableau",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>HW -- Dashboards</span>"
    ]
  },
  {
    "objectID": "hw-tableau-dashboards.html#overview",
    "href": "hw-tableau-dashboards.html#overview",
    "title": "23  HW – Dashboards",
    "section": "23.3 Overview",
    "text": "23.3 Overview\n\nThis problem is an application of the strategies from the notes in ?sec-notes-dashboards, where we learned how to create an effective dashboard, that also utilizes some techniques from the notes in Chapter 22 about the use of parameters.\nThis is a re-creation assignment demonstrating your ability to follow along with a tutorial using a new dataset and applying similar methods to new problems.",
    "crumbs": [
      "Tableau",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>HW -- Dashboards</span>"
    ]
  },
  {
    "objectID": "hw-tableau-dashboards.html#data-source",
    "href": "hw-tableau-dashboards.html#data-source",
    "title": "23  HW – Dashboards",
    "section": "23.4 Data Source",
    "text": "23.4 Data Source\n\nThe file bike-sales.csv contains sales for a bike company; a subset of which is shown below connected in Tableau:",
    "crumbs": [
      "Tableau",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>HW -- Dashboards</span>"
    ]
  },
  {
    "objectID": "hw-tableau-dashboards.html#assignment",
    "href": "hw-tableau-dashboards.html#assignment",
    "title": "23  HW – Dashboards",
    "section": "23.5 Assignment",
    "text": "23.5 Assignment\n\nThe goal is to recreate the dashboard explained in the video accompanying this assignment. A preview of the features is demonstrated below.\n\n\n\n\n\n\n\n\nWhat will be looked at for grading\n\nCorrect implementation of the ALL of dynamic features in the dashboard including the use of parameters, correct organization and good style of the final plots and dashboard.",
    "crumbs": [
      "Tableau",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>HW -- Dashboards</span>"
    ]
  },
  {
    "objectID": "module-r.html",
    "href": "module-r.html",
    "title": "R",
    "section": "",
    "text": "Here is an overview of the content and corresponding assignments.",
    "crumbs": [
      "R"
    ]
  },
  {
    "objectID": "install-r-and-rstudio.html#r-vs-rstudio",
    "href": "install-r-and-rstudio.html#r-vs-rstudio",
    "title": "24  Install R and RStudio",
    "section": "24.1 R vs RStudio",
    "text": "24.1 R vs RStudio\n\nR is the actual software that works behind the scenes on everything that we will do. However, it is not very user friendly; it only has a command line interface.\nSo instead, we will work in RStudio. RStudio is a IDE (integrated development environment) for R. Think of it as an application that we can use to manage and run R code.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Install R and RStudio</span>"
    ]
  },
  {
    "objectID": "install-r-and-rstudio.html#how-to-install-r-and-rstudio",
    "href": "install-r-and-rstudio.html#how-to-install-r-and-rstudio",
    "title": "24  Install R and RStudio",
    "section": "24.2 How to Install R and RStudio",
    "text": "24.2 How to Install R and RStudio\n\nNavigate here and follow Step 1 (Install R) and Step 2 (Install RStudio, can scroll down for versions as well).\n\n\n\n\n\n\n\n\n\nBe sure to download the appropriate version based on what type of computer you have (Windows vs Mac) for both steps.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Install R and RStudio</span>"
    ]
  },
  {
    "objectID": "install-r-and-rstudio.html#learn-about-rstudio",
    "href": "install-r-and-rstudio.html#learn-about-rstudio",
    "title": "24  Install R and RStudio",
    "section": "24.3 Learn about RStudio",
    "text": "24.3 Learn about RStudio\n\nWatch this video as an introduction to RStudio (only 6 min long) and follow along!",
    "crumbs": [
      "R",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Install R and RStudio</span>"
    ]
  },
  {
    "objectID": "install-r-and-rstudio.html#having-trouble",
    "href": "install-r-and-rstudio.html#having-trouble",
    "title": "24  Install R and RStudio",
    "section": "24.4 Having Trouble?",
    "text": "24.4 Having Trouble?\n\nPlease reach out to me or the BSU Technology Help Desk as soon as possible.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Install R and RStudio</span>"
    ]
  },
  {
    "objectID": "intro-to-r.html#course-introduction-to-tableau",
    "href": "intro-to-r.html#course-introduction-to-tableau",
    "title": "25  Introduction to R",
    "section": "25.1 Course: Introduction to Tableau",
    "text": "25.1 Course: Introduction to Tableau\n\n\n\n\n\n\n\n\nThis course covers the basics of R and introduces you to data structures and how we work with data in R. This is our first programming language we are working with, so it is especially important to spend the time understanding the basic syntax, logic and structure for working with objects and commands in R.\nThis will serve as both content and an assignment to start the module.\nIt has 6 chapters that you will need to: complete:\n\nIntro to Basics\nVectors\nMatrices\nFactors\nData frames\nLists\n\nHOW TO WORK THROUGH THIS COURSE\n\nThis course is just exercises that you can complete in DataCamp’s editor. Feel free to copy some exercises into an RStudio script on your computer and try them there as well (this way you can refer to them later).",
    "crumbs": [
      "R",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Introduction to R</span>"
    ]
  },
  {
    "objectID": "intro-to-r.html#learn-more",
    "href": "intro-to-r.html#learn-more",
    "title": "25  Introduction to R",
    "section": "25.2 Learn more!",
    "text": "25.2 Learn more!\n\nRemember that you have unlimited access to ANY DataCamp course until January 6, 2024.\nMake sure to take advantage of this if you are interested.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Introduction to R</span>"
    ]
  },
  {
    "objectID": "intro-to-r.html#submission",
    "href": "intro-to-r.html#submission",
    "title": "25  Introduction to R",
    "section": "25.3 Submission",
    "text": "25.3 Submission\n\nPlease upload this certificate for this assignment (a picture of it, or a word doc with the certificate in it, etc.). IT MUST INCLUDE YOUR NAME IN THE CERTIFICATE, or no credit will be given.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Introduction to R</span>"
    ]
  },
  {
    "objectID": "intro-to-quarto.html",
    "href": "intro-to-quarto.html",
    "title": "26  Introduction to Quarto",
    "section": "",
    "text": "Now that we are familiar with R and RStudio, we will introduce one more concept called Quarto.\nQuarto is a visual editor within RStudio that allows you to combine text and code (and it’s output) in a single document.\nThis is how we will complete all of our notes and assignments, so it will be important to be familiar with how to write .qmd files.\nSLIDES: Click the image below or follow the link to access the slides tutorial that corresponds to this video: https://coltongearhart.quarto.pub/intro-quarto/\n\nHere is the video that goes through the slides:",
    "crumbs": [
      "R",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Introduction to Quarto</span>"
    ]
  },
  {
    "objectID": "notes-r-visualizations.html#overview",
    "href": "notes-r-visualizations.html#overview",
    "title": "\n28  Notes – Visualizations\n",
    "section": "\n28.1 Overview",
    "text": "28.1 Overview\n\n28.1.1 Materials\n\nAttached are all of the supplemental materials to this content! Feel free to check them out :)\n\nClick the image below or follow the link to access the interactive tutorial that corresponds to this content: http://coltongearhart.shinyapps.io/visualizations/\n\n\nHere are the videos that go through the tutorial:\n\n\n\n\nAnd finally here is the starter file mentioned and needed data for one of the exercises: visulaizations-STARTER.qmd and data-bsu-game.RData\n\n\n28.1.2 This section\n\nThis section introduces the world of ggplot2, several different types of plots, and some basic features to enhance your visuals. Then it covers simple data visualization principles when working with multiple variables and how to implement these within ggplot2.\n\n\n\n\n\n\n\n\n28.1.3 Readings\n\n\nThis section covers content from Chapter 2 - Data Visualization of R for Data Science (2e).\n\nAdditional content includes section 10.4 - Facets and 10.5 - Statistical Transformations.\n\n\nggplot2 help documentation contains everything you need to know about ggplot2, including a very helpful cheatsheet.\n\n28.1.4 Prerequisites\n\nBefore we can use the functions, datasets, and help pages within the tidyverse, which includes ggplot2, we need to load the package. We can do this by running:\n\n\nlibrary(tidyverse)\n\n\nNote if any package is not currently installed, it cannot be loaded. We can install packages using the ‘Packages’ tab or by running:\n\n\ninstall.packages(\"tidyverse\")\n\n\n28.1.5 Goal\n\nOur goal by the end of this section is to be able to understand all the aspects of the following plots, how to create them, and how to set up the plot to easily switch between different layouts.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Notes -- Visualizations</span>"
    ]
  },
  {
    "objectID": "notes-r-visualizations.html#example-dataset",
    "href": "notes-r-visualizations.html#example-dataset",
    "title": "\n28  Notes – Visualizations\n",
    "section": "\n28.2 Example dataset",
    "text": "28.2 Example dataset\n\nWe are going to use diamonds dataset from ggplot2 package, aka ggplot2::diamonds (this is the syntax for denoting which package a function or dataset comes from packagename::functionname()). This contains price and other attribute information about a large sample of diamonds.\nYou can search a function or dataset name in the ‘Help’ tab or run ?&lt; function or dataset &gt; to bring up the documentation.\n\n\n?diamonds\n\n\nTo preview the dataset, we can click on it in the ‘Environment’ tab or run glimpse(), which shows a better formatted preview than the standard print() function.\nDisplayed results compactly show the number of observations, the number of variables and their corresponding data types and also some of the raw data.\n\n\nglimpse(diamonds)\n\nRows: 53,940\nColumns: 10\n$ carat   &lt;dbl&gt; 0.23, 0.21, 0.23, 0.29, 0.31, 0.24, 0.24, 0.26, 0.22, 0.23, 0.…\n$ cut     &lt;ord&gt; Ideal, Premium, Good, Premium, Good, Very Good, Very Good, Ver…\n$ color   &lt;ord&gt; E, E, E, I, J, J, I, H, E, H, J, J, F, J, E, E, I, J, J, J, I,…\n$ clarity &lt;ord&gt; SI2, SI1, VS1, VS2, SI2, VVS2, VVS1, SI1, VS2, VS1, SI1, VS1, …\n$ depth   &lt;dbl&gt; 61.5, 59.8, 56.9, 62.4, 63.3, 62.8, 62.3, 61.9, 65.1, 59.4, 64…\n$ table   &lt;dbl&gt; 55, 61, 65, 58, 58, 57, 57, 55, 61, 61, 55, 56, 61, 54, 62, 58…\n$ price   &lt;int&gt; 326, 326, 327, 334, 335, 336, 336, 337, 337, 338, 339, 340, 34…\n$ x       &lt;dbl&gt; 3.95, 3.89, 4.05, 4.20, 4.34, 3.94, 3.95, 4.07, 3.87, 4.00, 4.…\n$ y       &lt;dbl&gt; 3.98, 3.84, 4.07, 4.23, 4.35, 3.96, 3.98, 4.11, 3.78, 4.05, 4.…\n$ z       &lt;dbl&gt; 2.43, 2.31, 2.31, 2.63, 2.75, 2.48, 2.47, 2.53, 2.49, 2.39, 2.…",
    "crumbs": [
      "R",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Notes -- Visualizations</span>"
    ]
  },
  {
    "objectID": "notes-r-visualizations.html#ggplot2-basics-and-scatterplots",
    "href": "notes-r-visualizations.html#ggplot2-basics-and-scatterplots",
    "title": "\n28  Notes – Visualizations\n",
    "section": "\n28.3 ggplot2 basics and scatterplots",
    "text": "28.3 ggplot2 basics and scatterplots\n\n28.3.1 Building from scratch\n\nggplot2 builds plots based on an approach called the grammar of graphics (hence “gg”plot2).\nThe grammar of graphics approach requires explicit aesthetic mapping of data to geometric features.\nAll plots follow a similar structure that builds up from the ggplot() function, which creates a “blank canvas”.\nAnd the first thing we can do is specify the dataset we will be using and rerun the code.\n\n\nggplot(data = diamonds)\n\n\n\n\n\n\n\n\n\n\nNow it is primed with the data, but we haven’t told it to do anything.\n\n28.3.2 Aesthetic mapping\n\nNext, we can add a layer of geometric features with geom_*(). This uses uses aesthetic mapping, which takes values of a variable and translates them into a visual feature.\nChoice of geometry depends on the data types of the variables of interest from the supplied dataset as well as the intent for creating the plot.\nIn the example below, both variables (carat and price) are continuous. So we can use a scatterplot visualize their relationship. This is created by adding a layer of points via geom_point().\nSimply use + between ggplot2 functions to add layers.\n\n\nggplot(data = diamonds,\n       x = carat,\n       y = price) + \n  geom_point()\n\nError in `geom_point()`:\n! Problem while setting up geom.\nℹ Error occurred in the 1st layer.\nCaused by error in `compute_geom_1()`:\n! `geom_point()` requires the following missing aesthetics: x and y\n\n\n\nThe code above throws an error because R can’t find carat and price because it is looking for standalone objects (i.e. vectors named carat and price).\nSo to tell R that the attributes are from the diamonds dataset, use the aes() function. In other words, this function connects the plot features to the dataframe specified in the data argument. Lets correct the above code.\n\n\nggplot(data = diamonds,\n       aes(x = carat,\n           y = price)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\n\n28.3.3 Exercise\n\nCreate a scatterplot for table vs depth.\n\n28.3.4 Other attributes\n\nNow we can adapt the scatterplot from above to learn more about function structure. Lets try to change the color of the points. A reasonable first attempt would be to specify a color argument.\n\n\nggplot(data = diamonds,\n       aes(x = carat,\n           y = price,\n           color = \"purple\")) + \n  geom_point()\n\n\n\n\n\n\n\n\n\n\nThis does not work as hoped. Because we specified within the aes() function, ggplot() looks for the column purple in the dataset.\nSo when it doesn’t find one, a new column purple is made and assigned this same value to every observation. And because this new column is being mapped to the color of the dots, ggplot() colors accordingly (although it’s not what we wanted).\nThe solution to change the color of all data points is to relocate the color argument.\nAnything that is a simple “constant” value (i.e. not part of the data and just an option for visual look) should be specified locally and outside of the aes() function.\nSo lets correct it.\n\n\nggplot(data = diamonds,\n       aes(x = carat,\n           y = price)) + \n  geom_point(color = \"purple\")\n\n\n\n\n\n\n\n\n\n\n28.3.5 Incorporating more variables via aes()\n\n\nOnly data-driven attributes go inside the aes() function.\nTo see how this works, let’s take a look at the iris dataset.\n\n\nglimpse(iris)\n\nRows: 150\nColumns: 5\n$ Sepal.Length &lt;dbl&gt; 5.1, 4.9, 4.7, 4.6, 5.0, 5.4, 4.6, 5.0, 4.4, 4.9, 5.4, 4.…\n$ Sepal.Width  &lt;dbl&gt; 3.5, 3.0, 3.2, 3.1, 3.6, 3.9, 3.4, 3.4, 2.9, 3.1, 3.7, 3.…\n$ Petal.Length &lt;dbl&gt; 1.4, 1.4, 1.3, 1.5, 1.4, 1.7, 1.4, 1.5, 1.4, 1.5, 1.5, 1.…\n$ Petal.Width  &lt;dbl&gt; 0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.3, 0.2, 0.2, 0.1, 0.2, 0.…\n$ Species      &lt;fct&gt; setosa, setosa, setosa, setosa, setosa, setosa, setosa, s…\n\n\n\nFor this example, we want to create a scatterplot for Sepal.Length vs Sepal.Width and color each observation based on Species, while also changing the style of dot for every point.\nNote that color is a data-driven feature, and size / shape are simply constants.\n\n\nggplot(data = iris,\n       aes(x = Sepal.Length,\n           y = Sepal.Width,\n          color = Species)) + \n  geom_point(size = 10,\n             shape = \"*\")\n\n\n\n\n\n\n\n\n\n\n28.3.6 Exercise\n\n\nCreate a scatterplot using a sample of the diamonds dataset that includes the following features (code for the sample is provided, check the help page to see how it works!):\n\nVisualizes table vs depth;\nEach observation is sized based on the weight carat;\nAll observations have the shape of a diamond. HINT: Google “geom_point() shapes”.\n\n\n\n\ndiamonds_sample &lt;- sample_n(diamonds, size = 100)\n\n\nNow lets take a look at some different types of plots and more options to spruce them up.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Notes -- Visualizations</span>"
    ]
  },
  {
    "objectID": "notes-r-visualizations.html#histograms",
    "href": "notes-r-visualizations.html#histograms",
    "title": "\n28  Notes – Visualizations\n",
    "section": "\n28.4 Histograms",
    "text": "28.4 Histograms\n\n28.4.1 geom_histogram()\n\nA basic histogram is a univariate plot that can be used for continuous variables and is created via geom_histogram().\nBelow we will code an example that shows the required mapping (i.e. arguments needed within the aes() function along with some other relevant arguments for geom_histogram().\nSearch the help page for each geom_* to see which aesthetics are required and what else can be modified.\n\n\nggplot(data = diamonds,\n       aes( x = carat)) + \n  geom_histogram(binwidth = 0.1,\n                 fill = \"red\",\n                 color = \"purple\")\n\n\n\n\n\n\n\n\n\n\nNow let’s use the iris data to make another histogram, except we are going to incorporate another variable; specifically we want to visualize on the petal lengths based on which species they are.\nNote that to map species to the color of the bars, the fill argument should be used (using the color attribute only changes the outline color of the bars).\n\n\nggplot(data = iris,\n       aes(x = Petal.Length,\n           fill = Species)) + \n  geom_histogram()\n\n\n\n\n\n\n\n\n\n\n28.4.2 Exercise\n\nCreate a histogram for carat that has 20 bins with white bars and black outlines.\n\n28.4.3 Titles and labels\n\nWe can use of the labs() function which adds main titles, axis titles, etc. These labels can be tacked onto any ggplot2 plot. Let’s try it below.\n\n\nggplot(data = diamonds,\n       aes(x = carat)) + \n  geom_histogram(binwidth = 0.1,\n                 fill = \"red\",\n                 color = \"purple\") + \n  labs(title = \"Histogram of diamond weights\",\n       x = \"Weight in carats\",\n       y = \"Count\")\n\n\n\n\n\n\n\n\n\n\n28.4.4 Exercise\n\n\nModify the code used to make the previous plot to:\n\nVisualize sepal length instead of petal length;\nChange the X-axis label to be more readable;\nGive the plot an informative title.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Notes -- Visualizations</span>"
    ]
  },
  {
    "objectID": "notes-r-visualizations.html#boxplots",
    "href": "notes-r-visualizations.html#boxplots",
    "title": "\n28  Notes – Visualizations\n",
    "section": "\n28.5 Boxplots",
    "text": "28.5 Boxplots\n\n28.5.1 geom_boxplot()\n\nBoxplots are another common plot, which are used to visualize the distribution of a numeric variable. However, they no longer map the raw data.\nInstead, geom_boxplot() maps the five number summary that is computed from the raw data.\n\n\nx &lt;- rnorm(50)\nsummary(x)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n-2.0292 -0.6498  0.1520  0.1249  0.8299  1.8949 \n\nboxplot(x)\n\n\n\n\n\n\n\n\nhist(x)\n\n\n\n\n\n\n\n\n\n\nThis is an example of when an aesthetic has an implicit transformation, which is then used to build the plot rather than straight from the raw data.\ngeom_boxplot() requires a continuous variable to be mapped to either the x or y argument, depending on the desired orientation of the boxplot.\n\n\nggplot(data = diamonds,\n       aes(x = carat)) + \n  geom_boxplot()\n\n\n\n\n\n\n\n\n\n\n28.5.2 Exercise\n\nCreate a vertical boxplot of Sepal.Length using the iris dataset.\n\n28.5.3 Comparitive boxplots\n\nWe can also make comparative (side-by-side) boxplots by mapping a categorical variable to the other axis. Lets see how to this works.\n\n\nggplot(data = diamonds,\naes(x = carat,\n    y = cut)) + \n  geom_boxplot()\n\n\n\n\n\n\n\n\n\n\nThis results in boxplots based on a single continuous variable, but grouped by the levels of the categorical variable. This is one way to plot a numerical response with a categorical explanatory variable.\nAn advantage of this is that they are easier for comparing centers (medians) and spread (IQR), and can also highlights outliers. However with big data, it will often show many outliers that aren’t actually outliers (because the spread gets smaller and smaller as \\(n\\) increases).\n\n28.5.4 Transformations and more customizations\n\nWe can do transformations of the input variables directly within the ggplot() call, without having to modify the data object itself.\nJust like the other geoms, we can modify some visual aspects of the layer.\nThen if we want to swap the axes, we can use coord_flip(); this is one of many functions that can be used for further customization of most ggplots (others include scale_*(), theme_*(), etc.).\n\n\nggplot(data = diamonds,\n       aes(x = cut,\n           y = price/1000)) + \n  geom_boxplot(fill = \"darkblue\",\n               color = \"lightblue\") + \n  coord_flip() + \n  theme_classic()\n\n\n\n\n\n\n\n\n\n\n28.5.5 Exercise\n\n\nCreate a comparative boxplot using the iris dataset that includes the following features:\n\nCompares Sepal.Length for each Species;\nHorizontal boxplots (more than one way to do this);\nSepal.Length is originally measured in millimeters (mm); convert this to meters (m) for this plot;\nMore informative axis label for Sepal.Length based on new scale;\nA cool theme (try a few!).",
    "crumbs": [
      "R",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Notes -- Visualizations</span>"
    ]
  },
  {
    "objectID": "notes-r-visualizations.html#bar-graphs",
    "href": "notes-r-visualizations.html#bar-graphs",
    "title": "\n28  Notes – Visualizations\n",
    "section": "\n28.6 Bar graphs",
    "text": "28.6 Bar graphs\n\n28.6.1 Bar graphs\n\nA bar graph (also known as bar chart or bar plot) is used for categorical data and assigns a height of a bar to the count of a group.\nComparisons are made easier with visuals than just numbers (although keep in mind that sometimes simpler is better and a table suffices).\nJust like a boxplot, a bar graph is not plotting the raw data itself. Rather it uses a summary of the data, specifically the frequency (or relative frequency = frequency / total)\nThere are two ways we can use geom_bar() to make our bar graph, and it depends on the structure of the data.\n\n28.6.2 geom_bar() wtih raw data\n\nOne way to make a bar graph is to just use the raw data and let geom_bar() convert the data into counts behind the scenes, as shown below.\nLets take a look at the data before plotting.\n\n\n\n\n  \n\n\n\n\nBy “raw data”, we mean there is one row for each observation. When this is the case, we don’t have to change any options in geom_bar().\n\n\nggplot(data = diamonds,\n       aes(x = cut)) + \n  geom_bar()\n\n\n\n\n\n\n\n\n\n\n28.6.3 geom_bar() wtih count data\n\nAnother way is to manually create the counts dataframe (aka frequency table) and make the bar graph from this summarized data.\nThere are multiple ways to calculate the frequencies of each group in a dataframe. Two ways are shown below, using Base R table() and the other using a tidyverse function dplyr::count().\n\n\nclass(table(cut = diamonds$cut))\n\n[1] \"table\"\n\ndata.frame(table(cut = diamonds$cut))\n\n\n  \n\n\ncut_table &lt;- count(diamonds, cut)\nglimpse(cut_table)\n\nRows: 5\nColumns: 2\n$ cut &lt;ord&gt; Fair, Good, Very Good, Premium, Ideal\n$ n   &lt;int&gt; 1610, 4906, 12082, 13791, 21551\n\n\n\nNow we have the frequency table, we can go into plotting it. But it will be different than how we used geom_bar() last time because we are giving it already summarized data.\nSpecifically we have the group label (our x) and the now specified count (height, y); so, we need to tell geom_bar() to not do any statistical transformation on these variables (i.e. don’t count again). To do this, we use the option stat = \"identity\".\n\n\nggplot(data = cut_table,\n       aes(x = cut,\n           y = n)) + \n  geom_bar(stat = \"identity\")\n\n\n\n\n\n\n\n\n\n\nJust like with most things, there is still another way to do this: geom_col() treats the y aesthetic as heights directly and we don’t have to specify anything else.\n\n\nggplot(data = cut_table,\n       aes(x = cut,\n           y = n)) + \n  geom_col()\n\n\n\n\n\n\n\n\n\n\n28.6.4 Exercise\n\nCopy the code below that creates a sample of the iris data and then create a bar graph of Species. HINT: Make sure to inspect the data first.\n\n\n\n# create a sample from of data and summarize\n# -&gt; rename so in slightly different format than example and have to work with it\niris_sample &lt;- iris %&gt;% \n  sample_n(size = 50) %&gt;% \n  count(Species) %&gt;% \n  rename(Count = n)\n\n# create bar graph\n\n\n28.6.5 Displays for bivariate categorical data\n\n28.6.6 Stacked bar graph\n\nA common extension of a barplot is to show the breakdown of a second categorical variable within each bar. One way to do this is with a stacked bar graph.\nWe can again use geom_bar() (and let it do the counting). In order to differentiate between the two variables, we can specify fill in the aes(), just like we did with geom_histogram().\n\n\nggplot(data = diamonds,\n       aes(x = cut,\n           fill = clarity)) + \n  geom_bar()\n\n\n\n\n\n\n\n\n\n\nNotice that the y-axis on the plot is count, so all of the bars and segments are based on the frequency.\n\n28.6.7 Proportionally stacked bar graph\n\nIf we want the plot to be more standardized-ish, we can make a proportionally stacked bar graph by specifying position = \"fill\". This makes each bar have the same height and the segments corresponding to the second variable are broken out by percentage within each individual bar.\n\n\nggplot(data = diamonds,\n       aes(x = cut,\n           fill = clarity)) + \n  geom_bar(position = \"fill\")\n\n\n\n\n\n\n\n\n\n\nThis makes across group comparisons valid and easier because segments are no longer based on potentially very different sample sizes (technically, we are plotting the conditional distributions of clarity for each type of cut).\nThe advantage of this display is that we can see if there are differences in the distributions of clarity across each cut (regardless of how many total diamonds belong to each cut).\n\n28.6.8 Side-by-side bar graph\n\nWe can also incorporate the second variable by having side-by-side bars rather than stacked. To do this, we just have to set position = \"dodge\".\n\n\nggplot(data = diamonds,\n       aes(x = cut,\n           fill = clarity)) + \n  geom_bar(position = \"dodge\")\n\n\n\n\n\n\n\n\n\n\nThis display may tell a better story if it is important to keep an idea of sample size for each group combination. We can still tell that there are the most “Ideal” cut diamonds.\n\n28.6.9 Exercise\n\nCreate a few different displays using the diamonds dataset that visualize cut and color together. Can you notice any trends or lack-thereof between the two variables? Explain.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Notes -- Visualizations</span>"
    ]
  },
  {
    "objectID": "notes-r-visualizations.html#line-plots",
    "href": "notes-r-visualizations.html#line-plots",
    "title": "\n28  Notes – Visualizations\n",
    "section": "\n28.7 Line plots",
    "text": "28.7 Line plots\n\n28.7.1 geom_line()\n\nAnother type of plot is a line plot. These are most commonly used when looking at a quantitative variable across time periods (aka time series data).\nBelow is a look at the example data sunspot.year. As usual we should get familiar with the data first.\n\n\nglimpse(sunspot.year)\n\n Time-Series [1:289] from 1700 to 1988: 5 11 16 23 36 58 29 20 10 8 ...\n\n\n\nBefore plotting, we need to turn this into a dataframe and add a column indicating the year.\n\n\ndata_sun &lt;- data.frame(year = c(1700:1988),\n                       sunspots = as.vector(sunspot.year))\nglimpse(data_sun)\n\nRows: 289\nColumns: 2\n$ year     &lt;int&gt; 1700, 1701, 1702, 1703, 1704, 1705, 1706, 1707, 1708, 1709, 1…\n$ sunspots &lt;dbl&gt; 5, 11, 16, 23, 36, 58, 29, 20, 10, 8, 3, 0, 0, 2, 11, 27, 47,…\n\n\n\nThis is an easy plot to make, just use geom_line() and specify the x, which is usually time, and y within the aes().\n\n\nggplot(data = data_sun,\n       aes(x = year,\n           y = sunspots)) + \n  geom_line()",
    "crumbs": [
      "R",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Notes -- Visualizations</span>"
    ]
  },
  {
    "objectID": "notes-r-visualizations.html#facets",
    "href": "notes-r-visualizations.html#facets",
    "title": "\n28  Notes – Visualizations\n",
    "section": "\n28.8 Facets",
    "text": "28.8 Facets\n\n28.8.1 Facets\n\nFacets (think subplots) are a data-driven feature that can be used to compare distributions based on the levels of other variables.\nVisually, this is done by splitting plots into different panels rather than one overall panel. There are multiple ways this can be done within ggplot2.\n\n28.8.2 facet_wrap()\n\nIf we are facetting by one categorical variable, we want to use facet_wrap(~ var).\nNote: the tilde ~ is used to make formula in R.\nLet’s create a scatterplot and add facets for cut to demonstrate this.\n\n\nggplot(data = diamonds,\n       aes(x = table,\n           y = depth)) + \n  geom_point() + \n  facet_wrap(~ cut)\n\n\n\n\n\n\n\n\n\n\nWe see that facet_wrap() “wraps” the panels for a single factor rectangularly, which is ideal when there are many levels for the factor.\n\n28.8.3 Controlling rows and columns\n\nIf we want to control how the panels are wrapped because we are trying to highlight some aspect, we can specify how many rows or columns of panels using the options nrow and ncol.\n\n\nggplot(data = diamonds,\n       aes(x = carat)) + \n  geom_boxplot() + \n  facet_wrap(~ cut,\n             ncol = 1)\n\n\n\n\n\n\n\n\n\n\nJust be careful of overplotting, don’t want too many panels stacked together.\n\n\nggplot(data = diamonds,\n       aes(x = price)) + \n  geom_histogram() + \n  facet_wrap(~ clarity,\n             ncol = 1)\n\n\n\n\n\n\n\n\n\n\n28.8.4 Scales for facets\n\nBy default, all the panels will have the same scale for the numeric variable. This can distort some plots as shown below.\n\n\nggplot(data = diamonds,\n       aes(x = price)) + \n  geom_histogram() + \n  facet_wrap(~ cut)\n\n\n\n\n\n\n\n\n\n\nTo make the plots more readable, we can add an option to allow panels to have scales (min, max, tick marks, etc.) based on only the data in the respective panel, rather than the collective data.\nThis is done via the scales argument; options are \"free_x\", \"free_y\" or \"free\" (both \\(x\\) and \\(y\\) scales are free).\nNow we can correct the above plot.\n\n\nggplot(data = diamonds,\n       aes(x = price)) + \n  geom_histogram() + \n  facet_wrap(~ cut,\n             scales = \"free_y\")\n\n\n\n\n\n\n\n\n\n\nThis is another way to display numerical distributions for multiple groups. The advantage of creating multiple histograms is that they can show prevalence (i.e. frequencies) and modality of the distributions, whereas boxplots cannot.\n\n28.8.5 Exercise\n\n\nCreate a boxplots using the iris dataset that includes the following features:\n\nPlots Sepal.Length faceted by Species;\nStack the facets vertically to emphasize the differences between each Species;\nThink about if we want to adjust the scales of the panel, why or why not?\n\n\nNote that we made this plot previously with comparitive boxplots by specifying aes(y = Species); so this is an alternative.\n\n28.8.6 facet_grid()\n\nIf we want to facet by two categorical variables, we should use facet_grid(var1 ~ var 2) as it can make a matrix of panels.\nNote that var1 (before ~) represents the rows and var2 (after) is the columns.\nLets create boxplots for each combination of cut and color for the diamonds dataset.\n\n\nggplot(data = diamonds,\n       aes(x = table)) + \n  geom_boxplot() + \n  facet_grid(cut ~ color)\n\n\n\n\n\n\n\n\n\n\nNote that when using facet_grid(), we may need to fix the scales in the same way as with facet_wrap(). And just because we can make the plot means that it is good…\n\n28.8.7 Exercise\n\nCopy the code below that creates a sample from the diamonds dataset and create scatterplots of carat vs price that is colored by cut and facetted by color and clarity. Try a few different options for scales to see how they affect the plot.\n\n\n# create a sample from of data with fewer levels (variety from ordinal scale of each)\ndiamonds_sample &lt;- diamonds %&gt;% \n  filter(cut %in% unique(diamonds$cut)[c(1,3,5)],\n         color %in% unique(diamonds$color)[c(1,4,7)],\n         clarity %in% unique(diamonds$clarity)[c(1,4,8)]) %&gt;% \n  sample_n(size = 5000)",
    "crumbs": [
      "R",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Notes -- Visualizations</span>"
    ]
  },
  {
    "objectID": "notes-r-visualizations.html#density-histograms-and-density-curves",
    "href": "notes-r-visualizations.html#density-histograms-and-density-curves",
    "title": "\n28  Notes – Visualizations\n",
    "section": "\n28.9 Density histograms and density curves",
    "text": "28.9 Density histograms and density curves\n\n28.9.1 Density histograms\n\nAs we saw in the previous topic, if comparing a numeric distribution for a categorical explanatory variable, multiple histograms are a good option. But we had to allow varying scales between panels in order to have a readable plot.\nAnother option if we are not concerned with counts (sample size), but rather shape and modality across groups, is to make the heights of bars proportional.\nWe can think of this as each histogram having the same amount of “ink”, whcih is done by adding the condition that total heights must sum to 1. In essence, this standardizes heights.\nTo do this, we map y = after_stat(density) in the aes() statement (we won’t dig into how this works).\n\n\nggplot(data = diamonds,\n       aes(x = carat,\n           y = after_stat(density))) + \n  geom_histogram() + \n  facet_wrap(~ cut)\n\n\n\n\n\n\n\n\n\n\nThis can of course be done for a single histogram too.\n\n28.9.2 Density curves\n\nA density curve is related to the density histograms we just showed.\nAs we have seen, (density) histograms are really choppy binned representations of data whose display can vary widely based on our selection of bin width / number of bins.\n\n\nggplot(data = diamonds,\n       aes(x = carat,\n           y = after_stat(density))) + \n  geom_histogram(bins = 50)\n\n\n\n\n\n\n\n\n\n\nA more objective way to represent the data is called a density curve, which is a smooth curve based off the observed data that has an area under the curve (AUC) of 1.\nWe can think of this smooth curve as a blanket thrown over the top of our density histogram as shown below.\n\n\n\n\n\n\n\n\n\n\n\n\nNotice how the density curve still reflects the overall pattern of histograms, but it is much smoother.\nTo create this by itself, use geom_density().\n\n\nggplot(data = diamonds,\n       aes(x = carat)) + \n  geom_density()\n\n\n\n\n\n\n\n\n\n\n28.9.3 Exercise\n\n\nUse the iris dataset to do the following:\n\nCreate a density histogram of Petal.Length;\nOverlay a density curve of Petal.Length. HINT: You can plot multiple geoms on the same plot simply by adding another layer.\n\n\n\n28.9.4 Multiple density curves\n\nDensity curves provide us with yet another way to visualize a quantitative distribution by group.\nDrawing multiple lines (density curves) on the same plot is often better than many histograms, because the histograms would have to be stacked.\nTo distinguish between different groups when working with lines, we could use the aesthetics linetype or color (color will likely be easier to read, especially for several groups).\nWe can also add some other options to make the lines stand out more.\n\n\nggplot(data = diamonds,\n       aes(x = carat,\n           color = cut)) + \n  geom_density(linewidth = 0.75)\n\n\n\n\n\n\n\n\n\n\nJust be careful to not let the plot to get jumbled / messy with too many lines.\n\n28.9.5 Amount of smoothing\n\nOne way to tweak the resulting curve is to change the amount of smoothing, which is a statistical parameter (not just a visual one like binwidth). To do this, use the adjust parameter.\nIf adjustment is larger (e.g. adjust = 2), then the probability is more spread out and there is less smoothing; if smaller (e.g adjust = 0.2), then the smoothing is more sensitive and picks up on smaller patterns / spikes in the data.\n\n\nggplot(data = diamonds,\n       aes(x = carat)) + \n  geom_density(adjust = 2)\n\n\n\n\n\n\n\n\n\n\n28.9.6 Exercise\n\n\nUse the iris dataset to do the following:\n\nCreate density curves of a Petal.Length colored by each Species;\nAdjust the amount of smoothing to find a level that shows the overall trends well with some detail, but that is not overly exact (it’s a balance);\nAdd fill = Species in the aes() statement to see the result of this;\nNotice how the colors are completely opaque (not “see through”). To make them more transparent, add the following option locally geom_density(alpha = 0.5). Try a few different values (0 \\le alpha \\le 1) to see the result. Note that this option can also be used with lots other geom_*() as well.\nWhat does this plot tell us about the petal lengths of the different species?",
    "crumbs": [
      "R",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Notes -- Visualizations</span>"
    ]
  },
  {
    "objectID": "notes-r-visualizations.html#application",
    "href": "notes-r-visualizations.html#application",
    "title": "\n28  Notes – Visualizations\n",
    "section": "\n28.10 Application",
    "text": "28.10 Application\n\n28.10.1 Recreating\n\nNow we will return to the plots in the beginning of this section and recreate them.\n\n\n# load basketball data\nload(\"tutorials/visualizations/www/data-bsu-game.RData\")\n\n# filter to most recent season and take out the few neutral games\ndata_bsu_plot &lt;- bsu_game %&gt;% \n  filter(Season == max(Season),\n         Location != \"Neutral\")\n\n\n# line plot of points over the season\n# -&gt; specific colors by W/L and also take into account location with either the points (Visual 1)\n# -&gt; add reference line for average points\nggplot(data = data_bsu_plot,\n       aes(x = Date,\n           y = Points)) + \n  geom_point(aes(color = Outcome,\n                 shape = Location),\n             size = 4) + \n  geom_line(color = \"lightgrey\") + \n  geom_hline(aes(yintercept = mean(Points)),\n             color = \"grey20\",\n             linetype = \"dashed\") + \n  scale_color_manual(values = c(\"L\" = \"red\", \"W\" = \"green\")) + \n  scale_shape_manual(values = c(\"Home\" = 19, \"Away\" = 5, \"Neutral\" = 8)) + \n  labs(title = \"Ball State Basketball 2012-13 Visual 1\") + \n  theme_bw()\n\n\n\n\n\n\n\n\n\n\n28.10.2 Exercise\n\nCopy the final code used to create `Visual 1’ from above and modify it to recreate ‘Visual 2’.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Notes -- Visualizations</span>"
    ]
  },
  {
    "objectID": "notes-r-visualizations.html#exercise-solutions",
    "href": "notes-r-visualizations.html#exercise-solutions",
    "title": "\n28  Notes – Visualizations\n",
    "section": "\n28.11 Exercise solutions",
    "text": "28.11 Exercise solutions\nExercise 28.3.3\n\nggplot(data = diamonds,\n       aes(x = table,\n           y = depth)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\nExercise 28.3.6\n\n# create sample\ndiamonds_sample &lt;- sample_n(diamonds, size = 100)\n\n# create scatterplot\nggplot(data = diamonds_sample,\n       aes(x = table,\n           y = depth,\n           size = carat)) +\n  geom_point(shape = 5)\n\n\n\n\n\n\n\n\n\nExercise 28.4.2\n\nggplot(data = diamonds,\n       aes(x = carat)) + \n  geom_histogram(bins = 20,\n                 fill = \"white\",\n                 color = \"black\")\n\n\n\n\n\n\n\n\n\nExercise 28.4.4\n\nggplot(data = iris,\n       aes(x = Sepal.Length,\n           fill = Species)) + \n  geom_histogram() + \n  labs(title = \"Sepal Length by Species\",\n       x = \"Sepal Length (cm)\")\n\n\n\n\n\n\n\n\n\nExercise 28.5.2\n\nggplot(data = iris,\n       aes(y = Sepal.Length)) + \n  geom_boxplot()\n\n\n\n\n\n\n\n\n\nExercise 28.5.5\n\n# NOTE: if have X and Y aesthetics swapped, can use coord_flip() to get horizontal boxplots without changing your aes() statement\nggplot(data = iris,\n       aes(x = Species,\n           y = Sepal.Length / 10)) +  \n  geom_boxplot() + \n  labs(y = \"Sepal Length (m)\") + \n  theme_light()\n\n\n\n\n\n\n\n\n\nExercise 28.6.4\n\n# create a sample from of data and summarize\n# -&gt; rename so in slightly different format than example and have to work with it\niris_sample &lt;- iris %&gt;% \n  sample_n(size = 50) %&gt;% \n  count(Species) %&gt;% \n  rename(Count = n)\n\n# preview dataset to figure out structure\nglimpse(iris_sample) #-&gt; count (summarized) data\n\nRows: 3\nColumns: 2\n$ Species &lt;fct&gt; setosa, versicolor, virginica\n$ Count   &lt;int&gt; 22, 16, 12\n\n# create bar graph\n# -&gt; way 1)\nggplot(data = iris_sample,\n       aes(x = Species,\n           y = Count)) + \n  geom_bar(stat = \"identity\")\n\n\n\n\n\n\n\n\n# -&gt; way 2)\nggplot(data = iris_sample,\n       aes(x = Species,\n           y = Count)) + \n  geom_col()\n\n\n\n\n\n\n\n\n\nExercise 28.6.9\n\n# two of several plots that could be made\n\n# side-by-side bar graphs\nggplot(data = diamonds,\n       aes(x = color,\n           fill = cut)) + \n  geom_bar(position = \"dodge\")\n\n\n\n\n\n\n\n\n# proportionally stacked bar graph\nggplot(data = diamonds,\n       aes(x = cut,\n           fill = color)) + \n  geom_bar(position = \"fill\")\n\n\n\n\n\n\n\n\n# trends\n# -&gt; colors E, F, amd G are the three most common\n# -&gt; distributions of color are relatively the same across cuts (i.e. about same proportion of diamonds for each color regardless of cut)\n\nExercise 28.8.5\n\nggplot(data = iris,\n       aes(x = Sepal.Length)) +  \n  geom_boxplot() + \n  facet_wrap(~ Species,\n             ncol = 1)\n\n\n\n\n\n\n\n\n# we do NOT want to use scales = \"free_x\" because in order to have an equal comparison of the boxplots across species, we need them to be on the same scale\n\nExercise 28.8.7\n\n# create a sample from of data with fewer levels (variety from ordinal scale of each)\ndiamonds_sample &lt;- diamonds %&gt;% \n  filter(cut %in% unique(diamonds$cut)[c(1,3,5)],\n         color %in% unique(diamonds$color)[c(1,4,7)],\n         clarity %in% unique(diamonds$clarity)[c(1,4,8)]) %&gt;% \n  sample_n(size = 5000)\n\n# create facetted scatterplots\nggplot(data = diamonds_sample,\n       aes(x = carat,\n           y = price,\n           color = cut)) + \n  geom_point() + \n  facet_grid(color ~ clarity,\n             scales = \"free\") # both X and Y axes to be free (for the grid, not each individual panel)\n\n\n\n\n\n\n\n\n\nExercise 28.9.3\n\nggplot(data = iris,\n       aes(x = Petal.Length,\n           y = after_stat(density))) + \n  geom_histogram() + \n  geom_density()\n\n\n\n\n\n\n\n\n\nExercise 28.9.6\n\nggplot(data = iris,\n       aes(x = Petal.Length,\n           color = Species,\n           fill = Species)) + \n  geom_density(adjust = 1,\n               alpha = 0.5)\n\n\n\n\n\n\n\n\n# two of the species have similar petal lengths, while one is well below the others\n\nExercise 28.10.2\n\n# line plot of points over the season\n# -&gt; specific colors by W/L and also take into account location with facet (Visual 2)\n# -&gt; add reference line for average points\nggplot(data = data_bsu_plot,\n       aes(x = Date,\n           y = Points)) + \n  geom_point(aes(color = Outcome,\n                 shape = Location),\n             size = 4) + \n  geom_line(color = \"lightgrey\") + \n  geom_hline(aes(yintercept = mean(Points)),\n             color = \"grey20\",\n             linetype = \"dashed\") + \n  scale_color_manual(values = c(\"L\" = \"red\", \"W\" = \"green\")) + \n  scale_shape_manual(values = c(\"Home\" = 19, \"Away\" = 5, \"Neutral\" = 8)) + \n  labs(title = \"Ball State Basketball 2012-13 Visual 1\") + \n  theme_bw()\n\n\n\n\n\n\n\n\nggplot(data = data_bsu_plot,\n       aes(x = Date,\n           y = Points)) +  \n  geom_point(aes(color = Outcome),\n             size = 4) + \n  geom_line(color = \"lightgrey\") + \n  geom_hline(aes(yintercept = mean(Points)),\n             color = \"grey20\",\n             linetype = \"dashed\") + \n  scale_color_manual(values = c(\"L\" = \"red\", \"W\" = \"green\")) + \n  facet_wrap(~ Location) + \n  labs(title = \"Ball State Basketball 2012-13 Visual 2\") + \n  theme_bw()",
    "crumbs": [
      "R",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Notes -- Visualizations</span>"
    ]
  },
  {
    "objectID": "hw-r-visualizations.html#overview",
    "href": "hw-r-visualizations.html#overview",
    "title": "\n28  HW - Visualizations\n",
    "section": "\n28.1 Overview",
    "text": "28.1 Overview\nThese problems apply the idea from the notes ‘3.2 – Visualizations’, where we learned how to create plots using in R using ggplot2.\nWe will be working with the ggplot2::msleep data (documentation), which contains information on mammals sleep patterns as well as some categorical variables about the species. A subset is shown below:",
    "crumbs": [
      "R",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>HW - Visualizations</span>"
    ]
  },
  {
    "objectID": "hw-r-visualizations.html#assignment",
    "href": "hw-r-visualizations.html#assignment",
    "title": "\n28  HW - Visualizations\n",
    "section": "\n28.2 Assignment",
    "text": "28.2 Assignment\nThe goal is to recreate several plots in order to get used to the different types of and the structure of ggplot2 function calls and how to customize plots. The following prompts will take you through a series of plots representing an exploratory data analysis (EDA) where each plot is sequentially updated to new plot types or to incorporate more variables, each time revealing more information.\n\n28.2.1 Part a – Bar graphs\nLets first investigate the sample sizes of different categories within the dataset. Recreate the following bar graph for type of vore.\nNote this used the ggplot2::theme_bw() theme. To run a single command and set the theme for all the subsequent created plots, use ggplot2::theme_set() (check the documentation for more details).\n\n\n\n\n\n\n\n\n\n\nTo make this plot more readable, a first step we could do is sort the bars according to decreasing frequency (when we do this, it is technically called a “Pareto chart”). To do so, replace vore with the following line of code in your aes() statement: fct_infreq(vore). Check the help documentation of forcats::fct_infreq() to see what this function does.\n\n\n\n\n\n\n\n\n\n\nWe can also add the counts atop the bars just like adding data labels in Excel. To do this, add the following lines of code to the previous plot.\n\n&lt; previous bar graph function call &gt; +\n  geom_text(stat = \"count\",\n            aes(x = vore,\n                label = after_stat(count)),\n            vjust = -1)\n\nExplanation of code:\n- geom_text(stat = \"count\", aes(x = vore, label = after_stat(count))) counts the number of observations at each x vore value and uses the count as a label.\n- Then it places the text label by default at the top of each bar, and vjust = -1 moves the label one above the bar.\nBe sure to add nicer labels and title.\n\n28.2.2 Part b – Histograms and density curves\nRecreate the following histogram of sleep_total, paying attention to the changed aesthetics of the histogram.\n\n\n\n\n\n\n\n\n\n\nNotice that this histogram by default is really choppy, lets change the bins argument to a smaller value to see how it looks. Try a few different values.\nPerhaps a smooth curve would be a more accurate representation of this data than a histogram. Recreate the following density curve.\n\n\n\n\n\n\n\n\n\n\nLets add grouping information to the previous histogram to visualize sleep_total for each different type of vore. To do so, use the fill = vore to the aes() statement.\n\n\n\n\n\n\n\n\n\n\nIt is nearly impossible to glean any information from this plot. So let’s switch to a density curve, which is better for displaying several distributions on the same plot. Recreate the following plot, pay attention to which aesthetic vore needs to be mapped to.\n\n\n\n\n\n\n\n\n\n\nNow that we have a readable, accurate plot type for several distributions. Lets investigate more interesting quantities. Suppose we are interested in which animals have the biggest brains (proportionally). To study this we will visualize the ratio of brain weight to body weight based on the classification of animal vore. Recreate the following plot.\nHINTS:\n- Remember we can do “algebra” with our variables within an aes() statement.\n- To remove the NA category, we need to filter then out of the dataset used by ggplot(). We will learn how this function works in more detail next section, but for now replace msleep with the following code: filter(msleep, !is.na(vore)).\n- Essentially, is.na(vore) evaluates to TRUE when there is a missing value of NA and FALSE when not missing, then ! flips the logical so that filter() keeps only the non-missing values.\n\n\n\n\n\n\n\n\n\n\nBe sure to add descriptive title and axis label. Write a sentence in your qmd file summarizing the relationships shown in the resulting plot.\n\n28.2.3 Part c – Comparative boxplots\nAn alternative to multiple density curves is comparative boxplots. Create horizontal comparative boxplots for sleep_total by vore.\nNow convert this to a vertical comparative boxplots. Note that there are two ways this can be done. Be sure to add nice title and axis labels and change the overall color scheme of the boxplots to match the context of sleep. Write a sentence comparing the sleep totals for the different kind of vores.\n\n28.2.4 Part d – Scatterplots\nNow we will visualize two quantitative variables. Recreate the following scatterplot, which investigates the hours of rem sleep compared to the total sleep hours.\n\n# create scatterplot\nggplot(data = msleep) + \n  geom_point(aes(x = sleep_total,\n                 y = sleep_rem))\n\n\n\n\n\n\n\n\n\nThere appears to some kind of relationship between these two variables, which makes sense. The more total sleep an animal gets, the more REM sleep. Lets add model the relationship with a regression line. We can do this via the adding the following code to the previous plot.\n\n&lt; previous scatterplot function call &gt; +\n  geom_smooth(aes(x = sleep_total,\n                  y = sleep_rem),\n              method = \"lm\",\n              se = FALSE)\n\nTry commenting out method = \"lm\" to see the effect. Then change se = TRUE.\nBe sure to add nice titles and axis labels.\nIs it correct to model this relationship? REM sleep in hours per day is obviously a function of the sleep total; so there will implicitly be a relationship between these variables. To account for this, lets convert REM sleep to be relative to the total sleep hours by taking the ratio again like with brain weight and body weight. Create a new scatterplot with straight trend line for total sleep vs the ratio of REM sleep to total sleep.\nWrite a sentence describing the relationship between relative REM sleep and the total amount of sleep based on the this and the previous plot.\n\n28.2.5 Part e – Visualize data\nCreate at least one additional polished plot visualizing relationships among variable(s). Include a sentence write-up detailing any conclusions drawn from the plot. Feel free to create more than one :)",
    "crumbs": [
      "R",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>HW - Visualizations</span>"
    ]
  },
  {
    "objectID": "notes-r-data-transformations.html#overview",
    "href": "notes-r-data-transformations.html#overview",
    "title": "\n29  Notes – Data Transformations\n",
    "section": "\n29.1 Overview",
    "text": "29.1 Overview\n\n29.1.1 Materials\n\nAttached are all of the supplemental materials to this content! Feel free to check them out :)\n\nClick the image below or follow the link to access the interactive tutorial that corresponds to this content: https://coltongearhart.shinyapps.io/data-transformations/\n\n\nHere are the videos that go through the tutorial:\n\n\n\n\n\nAnd finally here is the starter file mentioned: data-transformations-STARTER.qmd\n\n\n29.1.2 This section\n\nIn the previous tutorial, we learned how to create many different visuals to display one or several quantitative and/or qualitative variables.\nHowever, creating visuals is one of the later steps in the process of data visualization.\n\n\n\n\n\n\n\n\nNearly always we have to work with the data at least a little bit to get it into the form we need for the visuals we plan to make.\nNow in this section, we are going to learn the different data transformation methods provided by another core package of the tidyverse called dplyr. Specifically, we will learn how to subset data (both rows and columns), create new columns and summarize data.\n\n29.1.3 Readings\n\nThis section covers content from Chapter 4 - Data Transformation of R for Data Science (2e).\ndplyr help documentation contains everything you need to know about dplyr, including a very helpful cheatsheet.\n\n29.1.4 Prerequisites\n\n\nIn addition to the tidyverse which includes dyplr, we need to load (and install if necessary) the following package:\n\n\nLahman → This is the package our example dataset comes from.\n\n\n\n\nlibrary(tidyverse)\nlibrary(Lahman)",
    "crumbs": [
      "R",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Notes -- Data Transformations</span>"
    ]
  },
  {
    "objectID": "notes-r-data-transformations.html#basics",
    "href": "notes-r-data-transformations.html#basics",
    "title": "\n29  Notes – Data Transformations\n",
    "section": "\n29.2 Basics",
    "text": "29.2 Basics\n\n29.2.1 dplyr\n\nThroughout this section we will demonstrate several dplyr functions that perform the big picture data transformations tasks like filtering, organizing columns, creating new columns, etc.\n\nWhile each of these has their particulars, all of them have the same general setup in terms of their inputs and output:\n\nThe first argument is always a data frame, which is handy when using pipes (see next mini topic).\nThe subsequent arguments typically describe which columns to operate on, using the variable names (without quotes).\nThe output is always a new data frame (or tibble).\n\n\n\n29.2.2 Dataframe vs Tibble\n\nA dataframe is a data type in R that we have been working with (think of it as a table in Excel, rows and columns).\nAll of the functions we will use / have used work perfectly fine with this data type.\nHowever, there is special type of data frame used by the tidyverse known as a tibble. They are essentially equivalent, but tibbles is that they much nicer printing features than regular dataframes.\nTry it out to see for yourself. The iris dataset we have used is a dataframe, while diamonds is a tibble. Run the following lines of code in the console and see the difference in how each prints:\n\n\niris\ndiamonds\n\n\nThe printed tibble gives similar results as glimpse(). So with this new type, we can just call the data object directly.\n\nIn both cases, we are shown a nicely formatted output that includes the dimensions (# of rows x # of cols) and the first few rows / columns with an indication of the column type, which is important for knowing which type of operations we can do on them:\n\n&lt;int&gt; is short for integer;\n&lt;dbl&gt; is short for double (aka real numbers);\n&lt;chr&gt; for character (aka strings);\n&lt;dttm&gt; for date-time.\n\n\n\n29.2.3 Piping\n\nOften, we want to perform multiple functions, i.e. take an object, do something to it, then do something to the output.\nOne way to do this is with nesting functions → f(x).\n\n\nx &lt;- rnorm(n = 10, mean = 10, sd = 2)\nsd(scale(x))\n\n[1] 1\n\n\n\n\nThe pipe is another (equivalent) way to combine functions that is more readable. We can think of this as chaining functions together.\n\nPiping → x %&gt;% f, read as “and then”.\nTakes the object / result on the left and uses (passes) it as the first argument of the function on the right.\n\n\n\n\nx &lt;- rnorm(n = 10, mean = 10, sd = 2)\nx %&gt;% scale %&gt;% sd\n\n[1] 1\n\n\n\nThere is a base R version of the pipe as well |&gt;, but we will continue to use %&gt;% (it has some better functionality that we won’t dive into).",
    "crumbs": [
      "R",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Notes -- Data Transformations</span>"
    ]
  },
  {
    "objectID": "notes-r-data-transformations.html#example",
    "href": "notes-r-data-transformations.html#example",
    "title": "\n29  Notes – Data Transformations\n",
    "section": "\n29.3 Example",
    "text": "29.3 Example\n\n29.3.1 Dataset\n\nWe are going to use Lahman::Batting dataset, which contains Major League Baseball (MLB) batting statistics dating back to 1871.\nHere is a preview of the dataset.\n\n\n\n\n  \n\n\n\n\nBecause we will be checking the results of data transformations often in this section, let’s convert this to a new dataset that is a tibble with as_tibble(). Then we can confirm the data type with class().\n\n\nbatting &lt;- as_tibble(Batting)\nclass(Batting)\n\n[1] \"data.frame\"\n\nclass(batting)\n\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\n\nNext to simplify things later, lets run this line of code. We will learn what this does shortly.\n\n\nbatting &lt;- batting %&gt;% select(-c(CS:GIDP))\n\n\n29.3.2 Goal\n\nSuppose we are interested in the relationship between several of the batting statistics such as home runs (HR), runs batted in (RBI), etc. for the best home run hitters.\nThe specific questions we can answer depend on what data we have and how it is structured (i.e. what each row represents).\nFor example, currently each row represents a player, team and year combination, which means it shows numbers for a single season. So we can’t answer any questions that deal with career statistics based on this setup (season-level vs career-level data).\nOne question we could investigate is how many games were needed for the top 100 home run totals in a single season.\n\n\n\n\n\n\n\n\n\n\n\n\nOur goal for this section is to learn how to use the functions demonstrated in the next sections to perform all of the data transformations needed to construct the following plots.\nThe first one tracks a particular player’s home runs per season throughout the course of his career.\n\n\n\n\n\n\n\n\n\n\n\n\nThe second one plots the number of seasons played and total home runs for the top 500 home run hitters in the history of the MLB and includes information about whether they are still playing.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Notes -- Data Transformations</span>"
    ]
  },
  {
    "objectID": "notes-r-data-transformations.html#selecting-columns",
    "href": "notes-r-data-transformations.html#selecting-columns",
    "title": "\n29  Notes – Data Transformations\n",
    "section": "\n29.4 Selecting columns",
    "text": "29.4 Selecting columns\n\n29.4.1 select() basics\n\nOften there are unneeded columns in dataset. To focus on the columns of interest, we can use select().\nThere are many ways to specify the columns we want to keep or remove, a few are shown below. First we can get a complete list of the available columns with colnames().\n\n\ncolnames(batting)\n\n [1] \"playerID\" \"yearID\"   \"stint\"    \"teamID\"   \"lgID\"     \"G\"       \n [7] \"AB\"       \"R\"        \"H\"        \"X2B\"      \"X3B\"      \"HR\"      \n[13] \"RBI\"      \"SB\"       \"CS\"       \"BB\"       \"SO\"       \"IBB\"     \n[19] \"HBP\"      \"SH\"       \"SF\"       \"GIDP\"    \n\n\n\nExplicitly naming columns (and how to use piping) → Good when just need a few columns.\n\n\nselect(batting, playerID, yearID, HR) %&gt;% head\n\n\n  \n\n\nbatting %&gt;% select(playerID, yearID, HR) %&gt;% head\n\n\n  \n\n\n\n\nSelecting all from a block start_col:end_col → Good shorthand when you know the dataset is organized in blocks of related columns.\n\n\nbatting %&gt;% select(playerID:AB) %&gt;% head\n\n\n  \n\n\n\n\n\nSelect all except certain columns (i.e. remove columns).\n\nCan remove non-adjacent columns by making a vector of column names with c().\nCan also specify column position (#) rather than name.\n\n\n\n\nbatting %&gt;% select(!c(playerID:AB)) %&gt;% head\n\n\n  \n\n\nbatting %&gt;% select(-c(playerID:AB)) %&gt;% head\n\n\n  \n\n\nbatting %&gt;% select(!c(1, 5, 7)) %&gt;% head\n\n\n  \n\n\n\n\n\nCan combine all these different ways.\n\nNote that the columns of the results are ordered based on when they were specified in select().\n\n\n\n\nbatting %&gt;% select(1:4, -yearID, c(HR, AB)) %&gt;% head\n\n\n  \n\n\n\n\nRename columns using select(new_var = old_var). Note that all variables not included will be dropped.\n\n\nbatting %&gt;% select(Games = G) %&gt;% head\n\n\n  \n\n\n\n\n29.4.2 select() advanced\n\nselect() has helper functions to aide in selecting multiple variables at once (it can be cumbersome to have to type out each individual name or organize them so that we can use :). A few of them are explained below.\nwhere(&lt; function &gt;) → Useful for selecting all variables of a certain data type.\nstarts_with(), ends_with(), and contains() → Useful when variable names follow a pattern.\nall_of() and any_of() → Useful when have a character vector of column names (these do the same thing, except we want to use any_of() to allow for the potential of missing variables without getting an error).\n\n\nbatting %&gt;% select(where(is.numeric)) %&gt;% head\n\n\n  \n\n\nbatting %&gt;% select(ends_with(\"ID\")) %&gt;% head\n\n\n  \n\n\nvars &lt;- c(\"playerID\", \"yearID\", \"HR\", \"H\")\nbatting %&gt;% select(all_of(vars)) %&gt;% head\n\n\n  \n\n\nvars &lt;- c(\"playerID\", \"yearID\", \"HR\", \"H\", \"BA\") %&gt;% head\nbatting %&gt;% select(any_of(vars)) %&gt;% head\n\n\n  \n\n\n\n\nNote that these functions have to be used within a select() statement (or in similar verbs).\n\n29.4.3 Exercise\n\nUse the diamonds dataset to create a new dataset that contains only the columns carat, cut, color and price. Try to do this three different ways.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Notes -- Data Transformations</span>"
    ]
  },
  {
    "objectID": "notes-r-data-transformations.html#renaming-columns",
    "href": "notes-r-data-transformations.html#renaming-columns",
    "title": "\n29  Notes – Data Transformations\n",
    "section": "\n29.5 Renaming columns",
    "text": "29.5 Renaming columns\n\n29.5.1 rename() basics\n\nIf want to keep the all of the variables, but just rename a few, we should use rename(new_var = old_var).\n\n\nbatting %&gt;% rename(Doubles = X2B, Triples = X3B) %&gt;% head\n\n\n  \n\n\n\n\n29.5.2 Exercise\n\n\nRename the columns of the iris dataset so they match each of the following scenarios (NOTE: each is a separate problem):\n\nAll columns names are lowercase and the dots . are replaced with underscores _.\nSame rules as (a), except we only want to keep the new columns species and sepal_length (in this order) in the resulting dataframe.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Notes -- Data Transformations</span>"
    ]
  },
  {
    "objectID": "notes-r-data-transformations.html#relocating-columns",
    "href": "notes-r-data-transformations.html#relocating-columns",
    "title": "\n29  Notes – Data Transformations\n",
    "section": "\n29.6 Relocating columns",
    "text": "29.6 Relocating columns\n\n29.6.1 relocate() basics\n\nUse relocate() to move variables around (rather than reordering all of them in a select() statement).\nBy default variables are placed in the front, but we can also specify a different location by using the .before or .after arguments.\nNote that these arguments are available in mutate() as well, and the . before the word signifies that it is an argument and not a column named after.\n\n\nbatting %&gt;% relocate(HR) %&gt;% head\n\n\n  \n\n\nbatting %&gt;% relocate(lgID, G, .after = AB) %&gt;% head\n\n\n  \n\n\n\n\nGenerally it is a good idea to have all of the categorical (identifier) variables first and then the numerical variables, which is how the data was setup originally.\n\n29.6.2 Exercise\n\n\nReorganize the columns of the diamonds dataset so they match each of the following scenarios (NOTE: each is a separate problem):\n\nprice is the first column.\nx, y, and z are located after cut; see if you can do this two different ways.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Notes -- Data Transformations</span>"
    ]
  },
  {
    "objectID": "notes-r-data-transformations.html#filtering-rows",
    "href": "notes-r-data-transformations.html#filtering-rows",
    "title": "\n29  Notes – Data Transformations\n",
    "section": "\n29.7 Filtering rows",
    "text": "29.7 Filtering rows\n\n29.7.1 filter() basics\n\nfilter() is used to subset a dataframe to rows that meet the specified condition(s).\nThese conditions are called logical tests. R has the following comparison operators that we can use to compare values: &gt;, &gt;= (greater than or equal), &lt;, &lt;=, != (not equal), and == (equal).\n\n\nbatting %&gt;% filter(playerID == \"aaronha01\") %&gt;% head\n\n\n  \n\n\nbatting %&gt;% filter(yearID &gt;= 2020) %&gt;% head\n\n\n  \n\n\nbatting %&gt;% filter(yearID == max(yearID)) %&gt;% head\n\n\n  \n\n\n\n\nCan check more than one condition by combining logical tests: & or , to indicate “and” (check for both conditions) or with | to indicate “or” (check for either condition).\nIf checking multiple “or” values for the same variable, use %in% operator.\n\n\nbatting %&gt;% filter(lgID == \"NL\", yearID == max(yearID)) %&gt;% head\n\n\n  \n\n\nbatting %&gt;% filter(lgID == \"NL\" | yearID == max(yearID)) %&gt;% head\n\n\n  \n\n\nbatting %&gt;% filter(teamID %in% c(\"CIN\", \"PHI\", \"MIA\")) %&gt;% head\n\n\n  \n\n\n\n\n29.7.2 Exercise\n\n\nSubset the diamonds dataset so that the result contains only rows that match each of the following scenarios (NOTE: each is a separate problem):\n\nThe most expensive diamond.\nDiamonds that have carat between 1 and 2 (inclusive) and that are not “Premium” diamonds in terms of cut.\nThe least expensive diamond, but it has to have a “Fair” or “Good” cut. HINT: This may require more than filter() statement.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Notes -- Data Transformations</span>"
    ]
  },
  {
    "objectID": "notes-r-data-transformations.html#ordering-rows",
    "href": "notes-r-data-transformations.html#ordering-rows",
    "title": "\n29  Notes – Data Transformations\n",
    "section": "\n29.8 Ordering rows",
    "text": "29.8 Ordering rows\n\n29.8.1 arrange() basics\n\narrange() sorts rows based on the values of the supplied columns. Each additional column gets sorted by within the values of the previous column.\nBy default it orders ascending (smallest to largest); can sort descending by wrapping the column name in desc().\nNote that this can be used on character or factor columns as well where it sorts alphabetically.\n\n\nbatting %&gt;% arrange(yearID) %&gt;% head\n\n\n  \n\n\nbatting %&gt;% arrange(playerID) %&gt;% head\n\n\n  \n\n\nbatting %&gt;% arrange(desc(yearID), desc(H)) %&gt;% head\n\n\n  \n\n\n\n\n29.8.2 Exercise\n\nUse the code below and arrange the sample of the diamonds dataset by price (most expensive to least expensive) within cut.\n\n\ndiamonds_sample &lt;- sample_n(diamonds, size = 1000) %&gt;% select(cut, price, carat)",
    "crumbs": [
      "R",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Notes -- Data Transformations</span>"
    ]
  },
  {
    "objectID": "notes-r-data-transformations.html#finding-unique-rows",
    "href": "notes-r-data-transformations.html#finding-unique-rows",
    "title": "\n29  Notes – Data Transformations\n",
    "section": "\n29.9 Finding unique rows",
    "text": "29.9 Finding unique rows\n\n29.9.1 distinct() basics\n\ndistinct() finds (filters to) all unique rows in a dataset (across all variables); in essence, it removes the duplicate rows.\nMore often, we are trying to see which unique combinations of certain variables exist in the dataset. To do this, just supply the column names of interest to distinct().\nIf we want to the keep other columns when filtering for unique rows, use the .keep_all = TRUE option. Note that distinct() will keep only the first occurrence of the unique combo.\n\n\nbatting_sample &lt;- batting %&gt;% filter(teamID == \"CIN\", yearID &gt;= 2020)\nbatting_sample %&gt;% distinct(playerID) %&gt;% head\n\n\n  \n\n\nbatting_sample %&gt;% distinct(playerID, .keep_all = TRUE) %&gt;% head\n\n\n  \n\n\n\n\n29.9.2 Exercise\n\n\nUse the diamonds dataset to do the following (NOTE: each is a separate problem):\n\nFind the unique combinations cut and color.\nFind the unique combinations cut and color, except keep the rest of the variables.\nFind the unique combinations cut and color, keeping all variables like in (b), but we want the row that is kept to be the most expensive diamonds for each combination. HINT: Can you use a function we learned previously to help?",
    "crumbs": [
      "R",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Notes -- Data Transformations</span>"
    ]
  },
  {
    "objectID": "notes-r-data-transformations.html#creating-editing-columns",
    "href": "notes-r-data-transformations.html#creating-editing-columns",
    "title": "\n29  Notes – Data Transformations\n",
    "section": "\n29.10 Creating / editing columns",
    "text": "29.10 Creating / editing columns\n\n29.10.1 mutate() basics\n\nmutate() is used create new columns based on existing columns (or to overwrite existing columns).\nCan use simple algebra or any function of previous columns when creating new columns.\n\n\nbatting %&gt;% mutate(BA = round(H / AB, 3),\n                   teamID = str_to_lower(teamID)) %&gt;% head\n\n\n  \n\n\n\n\nCan also specify where we want the new columns to be placed in the resulting dataframe with .before and .after, just like with relocate().\n\n\nbatting %&gt;% mutate(BA = round(H / AB, 3),\n                   teamID = str_to_lower(teamID),\n                   .after = playerID) %&gt;% head\n\n\n  \n\n\n\n\n29.10.2 mutate() advanced\n\n\nOften we are only interested in the columns we are mutating or simply just the result, in which case we can optionally specify which variables to keep in the result using the .keep option.\n\n.keep = \"all\" → Keeps all columns; this is the default (so it was used above when nothing was specified).\n.keep = \"used\" → Keeps all columns involved in the mutate() statement and drops the rest.\n.keep = \"unused\" → Drops all columns involved in the mutate() statement, but keeps the rest.\n.keep = \"none\" → Only keeps the new column(s).\n\n\nWe could of course just use the default option and then use a select() statement accordingly, but mutate() has this functionality built in. teamID = str_to_lower(teamID))\n\n\nbatting %&gt;% mutate(BA = round(H / AB, 3),\n                   teamID = str_to_lower(teamID),\n                   .keep = \"none\") %&gt;% head\n\n\n  \n\n\n\n\n\nHere are two very useful / common functions when used in mutate()\n\nifelse(condition, &lt; value if true &gt;, &lt; value if false &gt;) → Assigns a value based on whether a logical test is true or false.\ncase_when(condition 1 ~ &lt; value if true &gt;, ...) → Extends ifelse() to check more than one condition (checks condition by condition).\n\n\n\n\nbatting %&gt;% mutate(thirty_thirty = ifelse(HR &gt;= 30 & SB &gt;= 30, \"Yes\", \"No\"),\n                   .keep = \"used\") %&gt;% head\n\n\n  \n\n\n\n\nfavs &lt;- c(\"CIN\", \"PHI\", \"NYA\")\ndislike &lt;- c(\"BOS\", \"WAS\")\n\nbatting %&gt;% \n  mutate(My_teams = case_when(\n    teamID %in% favs ~ \"Favorite\", # if -&gt; finds all favorite teams\n    teamID %in% dislike ~ \"Dislike\", # ifelse -&gt; fins all disliked teams after checking for favorite\n    TRUE ~ \"Neutral\" # else -&gt; works as an \"else\" statement; all other values get assigned neutral\n  )\n) %&gt;% head\n\n\n  \n\n\n\n\n29.10.3 Exercise\n\n\nUse the sample of the diamonds dataset to create a new dataset matches each of the following scenarios (NOTE: each is a separate problem):\n\nA new column for price_per_carat that is calculated accordingly; place this new column first.\n\nTwo new columns, where only the columns involved are kept:\n\nwithin_budget → An indicator (yes or no) for whether or not price \\(\\le\\) $1000;\nmy_style → An indicator (yes or no) for whether or not table \\(\\ge\\) 50 mm and cut is one of “Very Good” or “Premium”;\nAfterwards, can filter to see how many diamonds are potential purchase for you!\n\n\n\nA new column named that discretizes price, which means taking a numeric variable and turning it into ordinal variable (i.e. categories with implicit levels such as “bad”, “okay”, “good”); here are the specifications:\n\nNew column name = price_level;\nLevels → $0 $ price \\(&lt; 500\\) = “inexpensive”, \\(500 \\le\\) price \\(&lt; 2500\\) = “moderate”, $2500 $ price \\(&lt; 10,000\\) = “expensive”, and price \\(\\ge 10,000\\) = “very expensive”;\nDrop all unused columns.\n\n\nSave the dataset from (c) to a new object and use this to create a bar graph of price_level. Notice the order of the bars in the plot; does it make sense?\n\nModify the plot from (d) to have the correct order, here’s how:\n\nBy default, ggplot2 will order character variables alphabetically. To specify the order we want, we need to convert price_level to a factor data type and explicitly define the order of the levels.\nWe can do the conversion directly in the ggplot aes() statement using factor() and specifying the levels option with the categories we made in (c) in the order we need.\nMake sure to give a more readable axes label.\n\n\n\n\n\n\ndiamonds_sample &lt;- sample_n(diamonds, size = 1000)",
    "crumbs": [
      "R",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Notes -- Data Transformations</span>"
    ]
  },
  {
    "objectID": "notes-r-data-transformations.html#summarize-columns",
    "href": "notes-r-data-transformations.html#summarize-columns",
    "title": "\n29  Notes – Data Transformations\n",
    "section": "\n29.11 Summarize columns",
    "text": "29.11 Summarize columns\n\n29.11.1 summarize() basics\n\nsummarize() is used to calculate summary measures for columns of a dataframe.\n\nCommon functions used to summarize columns are measures of center and spread such as:\n\nCenter → mean(), median();\nSpread → sd(), IQR();\nRange → min(), max();\nCount → n() counts the number of observations and n_distinct() counts the number of unique observations.\n\n\nNote that if the column contains NA values, many of these functions will not work as desired; so we should specify the option na.rm = TRUE to fix this.\nWe can compute multiple summaries (which can be creative as we would like), and summarize() will return a dataframe with a column for each. Note that we can name the resulting columns as well.\n\n\nbatting %&gt;% summarize(most_recent_year = max(yearID),\n                      total_hr = sum(HR),\n                      BA = sum(H) / sum(AB),\n                      n_rows = n(),\n                      n_years = n_distinct(yearID))\n\n\n  \n\n\n\n\n29.11.2 summarize() advanced\n\nAnother pair of useful summaries are the number or proportion of observations that meet a certain condition. We can compute these using sum() and mean(), respectively.\n\n\nbatting %&gt;% summarize(n_first_year = sum(yearID == min(yearID)),\n                      n_30_hr = sum(HR &gt;= 30),\n                      prop_30_hr = mean(HR &gt;= 30))\n\n\n  \n\n\n\n\nIf we are computing the same summary statistic for several variables, we can shorten the command using across(cols, function), which applies the same transformation to a selection of columns.\nWe can also combine this with our select() helper functions such as where(), starts_with(), etc.\n\n\nreds &lt;- batting %&gt;% \n  filter(teamID == \"CIN\") %&gt;% \n  select(playerID, teamID, yearID, AB:X3B)\nreds %&gt;% summarize(across(c(R, H), sum))\n\n\n  \n\n\nreds %&gt;% summarize(across(c(AB:X3B), sum))\n\n\n  \n\n\nreds %&gt;% summarize(across(starts_with(\"X\"), sum))\n\n\n  \n\n\n\n\n29.11.3 Exercise\n\n\nCalculate the following summaries using the diamonds dataset (NOTE: each is a separate problem):\n\nMedian price, minimum table, maximum depth and average price per carat.\nMean of price, table and depth, as well as the total number of observations.\nNumber of and the proportion of diamonds that have an “Ideal” cut.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Notes -- Data Transformations</span>"
    ]
  },
  {
    "objectID": "notes-r-data-transformations.html#groups",
    "href": "notes-r-data-transformations.html#groups",
    "title": "\n29  Notes – Data Transformations\n",
    "section": "\n29.12 Groups",
    "text": "29.12 Groups\n\n29.12.1 group_by() basics\n\nAs we saw above, summarize(), collapses the entire dataframe down into a single row based on some measure.\nOften, however, we are interested in doing a group-wise analysis on our data, where we aggregate / summarize for each group (i.e. level of a variable).\nThe first step in this is to group the data with group_by(), which divides the data into groups (i.e. keeps tracks of rows corresponding to each level). Doing this doesn’t actually change the data, it just changes the attributes of the dataframe (or tibble).\n\n\nbatting %&gt;% group_by(yearID, teamID) %&gt;% head\n\n\n  \n\n\n\n\nNow that the data is grouped, it will affect how the subsequent functions like summarize(), mutate(), etc. work on the data.\nWe can also group by multiple variables simply by specifying additional columns (order matters).\nThese “second-level” groups are within the first grouping levels, and so on for each additional (just like when ordering by multiple variables with arrange()).\n\n29.12.2 Summarize grouped data\n\nPairing group_by() and summarize() is one of the most important capabilities of dplyr.\nsummarize() works the exact same as it did on ungrouped data, except that each summary is computed for each group, rather than for the entire dataset.\nBecause this still returns a dataframe, we can work with the result as well.\n\n\nbatting %&gt;% \n  group_by(yearID) %&gt;% \n  summarize(total_hr = sum(HR),\n            n = n()) %&gt;% \n  arrange(desc(yearID)) %&gt;% head\n\n\n  \n\n\n\n\nIn a long pipeline, every time we apply summarize() there is a different level of aggregation (i.e. collapsing over more and more).\n\n\nbatting %&gt;% \n  group_by(yearID, teamID) %&gt;% \n  summarize(total_hr = sum(HR),\n            n = n()) %&gt;% \n  summarize(sum(total_hr),\n            n = n()) %&gt;% head\n\n\n  \n\n\n\n\n29.12.3 Exercise\n\n\nCalculate the following summaries using the diamonds dataset (NOTE: each is a separate problem):\n\nMedian price for each level of color.\nAverage price and how many diamonds this corresponds to for each cut and clarity combination.\nRecreate the summary for the number of observations in each cut and clarity combination in (b) using the count() function. Search the help page for tips.\n\n\n\n29.12.4 ungroup() basics\n\nNotice above how the result after the first summarize() is still grouped; however once we aggregate again (over the remaining group), the result is back to a normal ungrouped dataframe.\nBy default groups set by group_by() stay active until all are aggregated over. Usually this won’t cause any problems, but if we wanted to remove the groups attribute, just use ungroup().\n\n\nbatting %&gt;% \n  group_by(yearID, teamID) %&gt;% \n  summarize(total_hr = sum(HR),\n            n = n()) %&gt;% \n  ungroup() %&gt;% \n  summarize(sum(total_hr),\n            n = n()) %&gt;% head\n\n\n  \n\n\n\n\n29.12.5 .by argument\n\nIf we know that we only want the groups for one operation instead of the entire chain, we can specify the grouping in the specific function using .by.\n\n\nbatting %&gt;% \n  summarize(.by = c(yearID, teamID),\n            total_hr = sum(HR),\n            n = n()) %&gt;% head\n\n\n  \n\n\n\n\nThis is equivalent to data %&gt;% group_by(col1, col2) %&gt;% summarize(...) %&gt;% ungroup() as we saw before.\n\n29.12.6 group_by() with other functions\n\nWe can also use group_by() and .by on functions like mutate() and filter() as well.\nThey perform the same way as summarize() does for grouped data: the calculation or filtering will take place for each group.\n\n\nbatting %&gt;% \n  select(playerID, yearID, HR) %&gt;% \n  mutate(.by = playerID,\n         avg_hr = round(mean(HR), 1)) %&gt;% head\n\n\n  \n\n\n\n\nbatting %&gt;% \n  filter(.by = playerID,\n         yearID == min(yearID)) %&gt;% head\n\n\n  \n\n\n\n\n29.12.7 slice() and slice_*()\n\n\nslice() is used to select (filter to) certain row numbers of the dataset. In base R, we can use head() and tail() to get the first or last n rows as well.\n\n\nbatting %&gt;% slice(1:5)\n\n\n  \n\n\nhead(batting, n = 5)\n\n\n  \n\n\ntail(batting)\n\n\n  \n\n\n\n\n\nIn the previous filter(.by, ...) example, we filtered to the minimum year for each player; this could also be accomplished with one of the variants of slice(), which are useful when working with grouped data:\n\nslice_head() and slice_tail() select the first or last rows.\nslice_min() and slice_max() select rows with highest or lowest values of a variable.\nslice_sample() randomly selects rows.\n\n\nTo specify how many rows, use the options n or prop.\nNote these can all be used on ungrouped data as well; then the slice is based on the entire dataset.\n\n\nbatting %&gt;% group_by(playerID) %&gt;% slice_min(order_by = yearID) %&gt;% head\n\n\n  \n\n\nbatting %&gt;% slice_max(HR, by = teamID) %&gt;% head\n\n\n  \n\n\n\n\n29.12.8 Exercise\n\n\nPerform the following using the diamonds dataset (NOTE: each is a separate problem):\n\nSummarize the median price for each combination of color and cut using the .by argument.\nCreate a random sample (without replacement) that contains 5 of diamonds from each level of cut. Note that this is a great way to create a representative random sample from a population.\n\nCopy your code from (b) and continue the pipeline to add a new column avg_price_cut that represents the average price for each level of cut. This enables us to compare each individual price to it’s respective average in the same dataset.\n\nKeep only the relevant columns and be sure that the resulting dataframe is no longer grouped.\nSee if you can do this two different ways.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Notes -- Data Transformations</span>"
    ]
  },
  {
    "objectID": "notes-r-data-transformations.html#application",
    "href": "notes-r-data-transformations.html#application",
    "title": "\n29  Notes – Data Transformations\n",
    "section": "\n29.13 Application",
    "text": "29.13 Application\n\n29.13.1 Recreating\n\nNow we will return to the plots that were our goals, and more specifically the data transformations to recreate them.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# summarize over player and year (in case traded / multiple stints)\nseason_stats &lt;- batting %&gt;% \n  summarize(.by = c(playerID, yearID),\n            across(c(G, HR), sum))\n\n# summarize over year to get career data\n# -&gt; calculate total games, home runs, number of seasons and indicator if still playing\ncareer_stats &lt;- season_stats %&gt;% \n  summarize(.by = playerID,\n            across(c(G, HR), sum),\n            Seasons = n(),\n            Status = ifelse(max(yearID) == 2022, \"Active\", \"Retired\"))\n\n\n# plot just for KG jr.\nggplot(data = season_stats %&gt;% filter(playerID == \"griffke02\"),\n       aes(x = yearID,\n           y = HR)) + \n  geom_point(aes(alpha = G),\n             size = 3) +  \n  geom_line() + \n  geom_smooth(se = FALSE) + \n  labs(title = \"Home runs per season by Ken Griffey Jr. - Visual 1\",\n       x = \"Season\",\n       y = \"Home runs\",\n       alpha = \"Games played\") + \n  theme_bw()\n\n\n\n\n\n\n\n\n# plot just top 500 HR hitters, colored by active\n# -&gt; can switch between games or seasons on x axis\ncareer_stats %&gt;% \n  slice_max(order_by = HR,\n            n = 500) %&gt;% \n  ggplot(aes(x = Seasons,\n             y = HR,\n             color = Status)) + \n  geom_point() + \n  scale_color_manual(values = c(\"Active\" = \"forestgreen\",\n                                \"Retired\" = \"grey\")) + \n  labs(title = \"Top 500 home run hitters - Visual 2\",\n       x = \"Seasons\",\n       y = \"Total home runs\") + \n  theme_bw()\n\n\n\n\n\n\n\n\n\n\n29.13.2 Exercise\n\nStudy the plot below and determine how the data must have been structured behind the scenes. Then perform the necessary transformations and recreate the plot.\n\nHINTS:\n- This will require several steps: think about aggregating the data first, then a separate operation to find the top 5 teams, then plot only the correct teams.\n- To get the the \\(x\\) scale to have the labels like shown, use scale_x_continuous() with the option breaks (which are the tick marks). Look into seq() as a shortcut for specifying the numbers.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Notes -- Data Transformations</span>"
    ]
  },
  {
    "objectID": "notes-r-data-transformations.html#exercise-solutions",
    "href": "notes-r-data-transformations.html#exercise-solutions",
    "title": "\n29  Notes – Data Transformations\n",
    "section": "\n29.14 Exercise solutions",
    "text": "29.14 Exercise solutions\nExercise 29.4.3\n\n# three of many ways to do this\ndiamonds %&gt;% select(carat, cut, color, price) %&gt;% head # explicitly naming\n\n\n  \n\n\ndiamonds %&gt;% select(1:3, 7) %&gt;% head # block selecting using column position\n\n\n  \n\n\ndiamonds %&gt;% select(carat:price, -c(clarity, depth, table)) %&gt;% head # block and removing some, less efficient in terms of keystrokes in this case \n\n\n  \n\n\n\nExercise 29.5.2\n\n# a)\niris %&gt;% rename(sepal_length = Sepal.Length, sepal_width = Sepal.Width,\n                petal_length = Petal.Length, petal_width = Petal.Width,\n                species = Species) %&gt;% glimpse # because iris is a dataframe, use glimpse() to nicely see preview \n\nRows: 150\nColumns: 5\n$ sepal_length &lt;dbl&gt; 5.1, 4.9, 4.7, 4.6, 5.0, 5.4, 4.6, 5.0, 4.4, 4.9, 5.4, 4.…\n$ sepal_width  &lt;dbl&gt; 3.5, 3.0, 3.2, 3.1, 3.6, 3.9, 3.4, 3.4, 2.9, 3.1, 3.7, 3.…\n$ petal_length &lt;dbl&gt; 1.4, 1.4, 1.3, 1.5, 1.4, 1.7, 1.4, 1.5, 1.4, 1.5, 1.5, 1.…\n$ petal_width  &lt;dbl&gt; 0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.3, 0.2, 0.2, 0.1, 0.2, 0.…\n$ species      &lt;fct&gt; setosa, setosa, setosa, setosa, setosa, setosa, setosa, s…\n\n# b) \niris %&gt;% select(sepal_length = Sepal.Length, species = Species) %&gt;% glimpse # use select() to rename and drop other columns\n\nRows: 150\nColumns: 2\n$ sepal_length &lt;dbl&gt; 5.1, 4.9, 4.7, 4.6, 5.0, 5.4, 4.6, 5.0, 4.4, 4.9, 5.4, 4.…\n$ species      &lt;fct&gt; setosa, setosa, setosa, setosa, setosa, setosa, setosa, s…\n\n\nExercise 29.6.2\n\n# a)\ndiamonds %&gt;% relocate(price) %&gt;% head\n\n\n  \n\n\n# b) \ndiamonds %&gt;% relocate(x, y, z, .after = cut) %&gt;% head\n\n\n  \n\n\ndiamonds %&gt;% relocate(x, y, z, .before = color) %&gt;% head\n\n\n  \n\n\n\nExercise 29.7.2\n\n# a)\ndiamonds %&gt;% filter(price == min(price))\n\n\n  \n\n\n# b) \ndiamonds %&gt;% filter(carat &gt;= 1, carat &lt;= 2, cut != \"Premium\") %&gt;% head\n\n\n  \n\n\ndiamonds %&gt;% filter(between(carat, 1, 2), cut != \"Premium\") %&gt;% head # equivalent (shorter) way\n\n\n  \n\n\n# c)\ndiamonds %&gt;% filter(cut %in% c(\"Fair\", \"Good\")) %&gt;% filter(price == min(price)) %&gt;% head\n\n\n  \n\n\n\nExercise 29.8.2\n\ndiamonds_sample &lt;- sample_n(diamonds, size = 1000) %&gt;% select(cut, price, carat) %&gt;% head\ndiamonds_sample %&gt;% arrange(cut, desc(price)) %&gt;% head\n\n\n  \n\n\n\nExercise 29.9.2\n\n# a)\ndiamonds %&gt;% \n  distinct(cut, color) %&gt;% \n  arrange(cut, color) %&gt;% head # can arrange to see combos more clearly\n\n\n  \n\n\n# b) \ndiamonds %&gt;% \n  distinct(color, cut, .keep_all = TRUE) %&gt;% # order doesn't matter in distinct()\n  arrange(cut, color) %&gt;% head # but order does matter for arrange()\n\n\n  \n\n\n# c)\ndiamonds %&gt;% \n  arrange(desc(price)) %&gt;% # arrange by highest to lowest price BEFORE, that way the FIRST occurrence of each combo that is kept by distinct() is the highest priced\n  distinct(cut, color, .keep_all = TRUE) %&gt;% \n  arrange(cut, color) %&gt;% head\n\n\n  \n\n\n\nExercise 29.10.3\n\n# create diamonds sample\ndiamonds_sample &lt;- sample_n(diamonds, size = 1000)\n\n# a)\ndiamonds_sample %&gt;% mutate(price_per_carat = price / carat, \n                    .before = carat) %&gt;% head\n\n\n  \n\n\n# b) \ndiamonds_sample %&gt;% \n  mutate(within_budget = ifelse(price &lt;= 1000,\n                                \"yes\",\n                                \"no\"),\n         my_style = ifelse(table &gt;= 50 & cut %in% c(\"Very Good\", \"Ideal\"),\n                           \"yes\",\n                           \"no\"),\n         .keep = \"used\") %&gt;% \n  filter(within_budget == \"yes\",\n         my_style == \"yes\") %&gt;% head\n\n\n  \n\n\n# c)\ndiamonds_prices &lt;- diamonds_sample %&gt;% \n  mutate(price_level = case_when(\n    price &lt; 500 ~ \"inexpensive\", # natural lower bound of zero, so don't need to check &gt;= 0\n    price &lt; 2500 ~ \"moderate\", # case_when() already checked &lt; 500, so everything remaining is &gt;= 500; so don't need to check that again\n    price &lt; 10000 ~ \"expensive\",\n    TRUE ~ \"very expensive\" # everything that is left is &gt;= 10.000\n  ),\n  .keep = \"used\"\n)\n\n# d)\ndiamonds_prices %&gt;% \n  ggplot(aes(x = price_level)) + \n  geom_bar()\n\n\n\n\n\n\n\n\n# order of bars jumble the intuitive order in terms of how expensive\n\n# e)\nprice_levels &lt;- c(\"inexpensive\", \"moderate\", \"expensive\", \"very expensive\") # define levels in order\ndiamonds_prices %&gt;% \n  ggplot(aes(x = factor(price_level, levels = price_levels))) + # convert to factor (with correct order)\n  geom_bar() + \n  labs(x = \"Diamond price level\")\n\n\n\n\n\n\n\n\n\nExercise 29.11.3\n\n# a)\ndiamonds %&gt;% summarize(med_price = median(price),\n                       min_table = min(table),\n                       max_depth = max(depth),\n                       avg_price_carat = mean(price / carat))\n\n\n  \n\n\n# b) \ndiamonds %&gt;% summarize(across(c(price, table, depth), mean),\n                       n = n())\n\n\n  \n\n\n# c)\ndiamonds %&gt;% summarize(n_ideal = sum(cut == \"Ideal\"),\n                       prop_ideal = mean(cut == \"Ideal\"))\n\n\n  \n\n\n\nExercise 29.12.3\n\n# a)\ndiamonds %&gt;% \n  group_by(color) %&gt;% \n  summarize(median(price))\n\n\n  \n\n\n# b) \ndiamonds %&gt;% \n  group_by(cut, clarity) %&gt;% \n  summarize(mean = mean(price),\n            n = n()) %&gt;% head\n\n\n  \n\n\n# c)\ndiamonds %&gt;% count(cut, clarity) %&gt;% head\n\n\n  \n\n\n\nExercise 29.12.8\n\n# a)\ndiamonds %&gt;% \n  summarize(med_price = median(price),\n            .by = c(color, cut)) %&gt;% head\n\n\n  \n\n\n# b) \ndiamonds %&gt;% \n  group_by(cut) %&gt;% \n  slice_sample(n = 5) %&gt;% \n  count(cut)\n\n\n  \n\n\n# c)\n# way 1\ndiamonds %&gt;% \n  group_by(cut) %&gt;% \n  slice_sample(n = 5) %&gt;% \n  mutate(avg_price_cut = mean(price),\n         .keep = \"used\") %&gt;% \n  ungroup %&gt;% head\n\n\n  \n\n\n# way 2\ndiamonds %&gt;% \n  slice_sample(n = 5,\n               by = cut) %&gt;% \n  mutate(avg_price_cut = mean(price),\n         .by = cut,\n         .keep = \"used\") %&gt;% head\n\n\n  \n\n\n\nExercise 31.4.2\n\n# summarize HRs per team and get recent data\nteam_stats &lt;- batting %&gt;%  \n  summarize(total_hr = sum(HR),\n            .by = c(teamID, yearID)) %&gt;% \n  filter(yearID &gt;= 2012)\n\n# find the teams with most HRs over this time period\nmost_hr &lt;- team_stats %&gt;% \n  summarize(total_hr = sum(total_hr),\n            .by = teamID) %&gt;% \n  slice_max(total_hr, n = 5)\n\n# extract team names to use in filter()\nmost_hr_teams &lt;- most_hr$teamID \n\n# get teams of interest and create line plot of HRs over time\nteam_stats %&gt;% \n  filter(teamID %in% most_hr_teams) %&gt;% \n  ggplot(data = .,\n         aes(x = yearID,\n             y = total_hr,\n             color = teamID)) + \n  geom_line() + \n  geom_point() + \n  scale_x_continuous(breaks = seq(from = 2012, to = 2022, by = 2)) + \n  labs(title = \"Top 5 home run hitting teams over past 10 years\",\n       x = \"Season\",\n       y = \"Total HRs\",\n       color = \"Team\") + \n  theme_bw()",
    "crumbs": [
      "R",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Notes -- Data Transformations</span>"
    ]
  },
  {
    "objectID": "hw-r-data-transformations.html#overview",
    "href": "hw-r-data-transformations.html#overview",
    "title": "\n30  HW - Data Transformations\n",
    "section": "\n30.1 Overview",
    "text": "30.1 Overview\nThese problems apply the ideas from the notes ‘3.3 – Data Transformations’, where we learned how to modify datasets plots using in R using dplyr and uses the transformed data to make visualizations learned in notes ‘3.2 – Visualizations’.\nWe will be working with the shuffled-playlist.csv data, which contains information about songs in a Spotify playlist. A subset is shown below:\n\n# load data\ndata_music &lt;- read.csv(file = \"r/data/shuffled-playlist.csv\")\n\n# preview data\nhead(data_music)\n\n\n  \n\n\n\nTo read in the data, first download it from Canvas and then change the path in the read.csv() statement above to where you have saved the data relative to the location of the your homework file.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>HW - Data Transformations</span>"
    ]
  },
  {
    "objectID": "hw-r-data-transformations.html#assignment",
    "href": "hw-r-data-transformations.html#assignment",
    "title": "\n30  HW - Data Transformations\n",
    "section": "\n30.2 Assignment",
    "text": "30.2 Assignment\nThe goal of this assignment is to demonstrate common data manipulation tasks using dplyr and creating more plots from transformed data with ggplot2. You will be asked several questions about the music dataset that can be answered by working with the data and then you will create some simple plots focused on particular aspects of the data.\n\n30.2.1 Part a – Data cleaning\nFirst we will do some data cleaning. Notice in the above preview how the spaces are  are actually plus signs + in the artist names. Use a mutate() statement to overwrite artist with the following line of code: str_replace_all(string = artist, pattern =  \"\\\\+\", replacement = \" \"). Also overwrite data_music so that it is updated with the cleaned artist information.\nExplanation of code:\n- str_replace_all() is part of a package very useful for working with strings. This function in particular finds all occurrences of + and replaces them with a space \" \".\n- Note that the pattern matching is done via what is called “regular expressions”. And + is a special character in regular expressions, so we have to preface it with a double escape character in R \\\\. If you are curious about more regular expression patterns, see this cheatsheet and the documentation for ?str_replace.\n\n\n\n  \n\n\n\n\n30.2.2 Part b – Summarize data\n\nDetermine the number of rows in the dataset. Then use an in-line R statement to write a sentence that is dynamically updated based on your calculation. For example, if I calculate the number of rows and save it as the object n_rows, then my sentence will read “There are &lt; n_rows &gt; in the dataset.”, where &lt; n_rows &gt; pulls from your calculation.\n\nFor each of the following questions, use pipes %&gt;% (or a series of pipes) to display a mini-dataframe that answers the question (there is no need to save the results into an object).\n\nWhat song has the highest valence score? Display only the categorical information about the song (i.e. artist, album, genre, name) and its respective valence score. HINT: use a select() statement in conjunction with where() to display only the character variables.\nWhat is the average energy for hip hop songs?\nWhat percentage of songs in the data are by the artist Dessa?\n\n30.2.3 Part c – Grouped and specific summaries\n\nCalculate the average energy, tempo and loudness for each genre. First do this by having a separate mean(&lt; variable &gt;) statement for each.\nNow repeat the calculation using across(), which allows us to apply the same function to a set of variables. This is much less cumbersome than typing each mean statement out like before.\nUse the same technique as above to calculate the mean of all numeric variable by genre.\nDetermine which pop song is the most danceable (highest danceability). Display only the categorical information about the song and its respective danceability score. HINT: Think about the series of pipes that we need to do.\nUse the same strategy to determine which which Adele song has the lowest energy.\nCHALLENGE: Find the artists with the lowest average acousticness for each genre.\n\n30.2.4 Part d – Visualize data\nNow we will create some plots based on subsets of the data.\n\nCreate a dataset of only hip hop songs and make bar graph for the number of songs by each artist. Add data labels atop the bars and change the color scheme of the bars.\nFind which three artists have the most songs in this playlist. To do this create a dataframe in descending order according to song count. Then create a scatterplot of speechiness vs liveness for only the top three artists. Include a sentence write-up describing the relationship in the scatterplot.\n\nCHALLENGE: Setup the code in such a way to create the scatterplot without ever explicitly naming the top 3 artists, e.g. never coding Fleetwood Mac. This makes your code much more dynamic.\n\nHow do the tempos compare for the artist within the ska genre? Create comparative boxplots to display this and include a sentence write-up summarizing the results.\n\n30.2.5 Part e – Analyze data\n\nAsk and answer another question about this dataset using a combination of “data steps” like in parts b and c.\nCreate an additional plot of your choosing that tells an interesting story about the data. This plot must use data that has been transformed in some way. Describe this plot in a few sentences.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>HW - Data Transformations</span>"
    ]
  },
  {
    "objectID": "notes-r-reshaping-and-combining-data.html#overview",
    "href": "notes-r-reshaping-and-combining-data.html#overview",
    "title": "\n31  Notes – Reshaping and Combining Data\n",
    "section": "\n31.1 Overview",
    "text": "31.1 Overview\n\n31.1.1 Materials\n\nAttached are all of the supplemental materials to this content! Feel free to check them out :)\n\nClick the image below or follow the link to access the interactive tutorial that corresponds to this content: https://coltongearhart.shinyapps.io/reshaping-and-combining-data/\n\n\nHere are the videos that go through the tutorial:\n\n\n\n\nAnd finally here is the starter file mentioned and needed data for the content and exercises: reshaping-and-combining-data-STARTER.qmd and data folder\n\n\n31.1.2 This section\n\nIn the previous tutorial, we learned how to transform our data for either for data cleaning, summarizing, or to get it into a form for different visualizations.\nBefore either of these steps can be done, generally data needs to be worked with after importing.\n\n\n\n\n\n\n\ntidyr is all about cleaning up messy data and turning it into well structured / organized objects. These objects are can be easily used across all packages in the tidyverse (e.g. ggplot2, dpylr, etc.), which makes common data analysis tasks flow much cleaner and smoother.\n\n31.1.3 Readings\n\n\nThis section covers content from Chapter 6 - Data Tidying of R for Data Science (2e).\n\nAdditional topics read_csv() from Chapter 8 - Data Import and basic joins (which are a part of dplyr) from Chapter 20 - Joins.\n\n\ntidyr help documentation contains everything you need to know about tidyr, including a very helpful cheatsheet.\n\n31.1.4 Prerequisites\n\nBefore we can use the functions, datasets, and help pages within the tidyverse (which includes readr, tidyr, and dplyr), we need to load the package. We can do this by running:\n\n\nlibrary(tidyverse)",
    "crumbs": [
      "R",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Notes -- Reshaping and Combining Data</span>"
    ]
  },
  {
    "objectID": "notes-r-reshaping-and-combining-data.html#french-fry-example",
    "href": "notes-r-reshaping-and-combining-data.html#french-fry-example",
    "title": "\n31  Notes – Reshaping and Combining Data\n",
    "section": "\n31.2 French fry example",
    "text": "31.2 French fry example\n\n31.2.1 Importing the example dataset\n\nThe first step when working with data is to read it into R. There are functions to read in all types of data (Excel .csv and .xlsx. text files .txt, SAS files .sas7bdat, etc.).\nFor an Excel .csv file, we will use readr::read_csv(), which has some advantages over the base R function read.csv().\nIt is better at reading in certain data structures. For example, if a column’s data has a format like 12-1-2019, it can recognize that as a date and save you an extra step. It also has good shorthand notation for specifying how R should read in the data.\nIn addition read_csv() actually turns the data into a tibble. Now lets read in and preview the example dataset.\n\n\n# read in dataset in with desired column attributes\n# -&gt; the long string of characters for col_types argument is shorthand notation, see documentation\ndata_ff &lt;- read_csv(file = \"tutorials/reshaping-and-combining-data/www/french-fries.csv\",\n                    col_names = TRUE, col_types = \"fffnnnnnn\")\n\n# preview data\ndata_ff %&gt;% head\n\n\n  \n\n\n\n\nThis contains information from a designed experiment where subjects were asked to taste french fries that were cooked in different oils. Subjects rated the french fries according to certain flavor attributes. Repeated samples were taken.\nAn alternative to reading the data directly is to load a .RData file, which can have the dataset already loaded with pre-specified attributes.\nIn a typical project workflow, after data cleaning it is a good idea to save a cleaned dataset and then start the analysis by loading in the cleaned data rather than starting with the raw data every time.\n\n\n# alternative way to load in data with pre-specified attributes\nload(\"tutorials/reshaping-and-combining-data/www/french_fries.RData\")\n\n\n31.2.2 Goal\n\nThe goal is to understand the data reshaping process to create the following visual.\n\n\n\n\n\n\n\n\n\n\n\n\n31.2.3 Agreggating and plotting\n\nBefore we can create the goal plot, lets create some simpler plots to build up to the goal.\nLets start with a simple plot of the raw data.\n\n\nggplot() + \n  geom_point(aes(x = time,\n                 y = potato),\n             data = data_ff)\n\n\n\n\n\n\n\n\n\n\nNow lets manipulate the data so that we can visually compare the raw individual potato scores to the mean over each time period. Then we can add it to the plot.\n\n\ndata_potato &lt;- data_ff %&gt;% \n  group_by(time) %&gt;% \n  summarize(avg_potato = mean(potato, na.rm = TRUE))\n\ndata_potato %&gt;% head\n\n\n  \n\n\nggplot() + \n  geom_point(aes(x = time, y = potato),\n             data = data_ff) + \n  geom_line(aes(x = time, y = avg_potato),\n            group = 1,\n            size = 2, color = \"blue\",\n            data = data_potato)\n\n\n\n\n\n\n\n\n\n\nNote that line plots typically used for time series plots. But they can also be used if there are related points across the \\(x\\)-axis.\nLets make line plot of potato flavor over time for each subject (so we want one line per subject, across time). In order to do this, we need to format the data so that each time and subject combination are grouped together. And then we can average scores over the two batches (i.e. replications).\nThen once the new data is ready, we can create the line plot of interest.\n\n\ndata_subject &lt;- data_ff %&gt;% \n  group_by(time, subject) %&gt;% \n  summarize(avg_potato = mean(potato, na.rm = TRUE))\n\nggplot() + \n  geom_line(aes(x = time, y = avg_potato, group = subject),\n            data = data_subject)\n\n\n\n\n\n\n\n\n\n\nNow we can do the same thing, but refine our analysis by incorporating the different type of oil (treatment). We do this by also grouping by the treatment applied to each batch of french fries.\nThen we can make new plot with more refined data. We can also add a smoothing line (\\(\\approx\\) mean line) for comparison, which will show the average scores across all subjects as well as the corresponding confidence band.\n\n\ndata_treatment &lt;- data_ff %&gt;% \n  group_by(time, treatment, subject) %&gt;% \n  summarize(avg_potato = mean(potato, na.rm = TRUE))\n\nggplot() + \n  geom_line(aes(x = time,\n                y = avg_potato,\n                group = subject),\n            data = data_treatment) + \n  geom_smooth(aes(x = time,\n                  y = potato,\n                  group = 1),\n              data = data_ff) + \n  facet_grid(. ~ treatment)\n\n\n\n\n\n\n\n\n\n\nWhen doing this, we want to think about the grouping variables and how can we visualize differences (if there are any).\nAggregating to different levels reveals some information, but we also lose information because the data is based is now from a totally different perspective. So it’s important to keep this in mind when drawing conclusions.\n\n31.2.4 Reshape data\n\nCurrently, the dataset is in wide format. So the characteristics about a single observation are represented by many columns.\nHowever, the each of these characteristics are related in what they represent (i.e. different types of flavors). So it makes sense to instead have one column for type of flavor and another for respective flavor score (rather than one column for potato score, another for grassy score, etc.).\nOur goal is to convert to the dataset to long (tall) format, where flavor type and flavor score variables replace the five flavor columns. Then we want to find the average score for each subject within a flavor category each week.\n\nTo do this, we will use tidyr::pivot_longer(). This functions reshapes (transposes) data from wide to long and takes the following main arguments:\n\ncols → Columns to be reshaped\nnames_to → New ID column name\nvalues_to → New value column name\n\n\n\n\ndata_long &lt;- data_ff %&gt;% \n  pivot_longer(cols = potato:painty,\n               names_to = \"flavor_type\",\n               values_to = \"flavor_score\")\nhead(data_long)\n\n\n  \n\n\n\n\nNow that the data is organized in a way that is conducive to the analysis we want to do, we can proceed. So we will average over the replications within each of the desired groups.\nThen create the final visual!\n\n\ndata_flavor &lt;- data_long %&gt;% \n  group_by(time, treatment, subject, flavor_type) %&gt;% \n  summarize(avg_flavor = mean(flavor_score, na.rm = TRUE))\nggplot(aes(x = time,\n           y = avg_flavor),\n       data = data_flavor) + \n  geom_line(aes(group = subject)) + \n  geom_smooth(aes(group = 1)) + \n  facet_grid(flavor_type ~ treatment,\n             scale = \"free_y\")\n\n\n\n\n\n\n\n\n\n\n\nNote that we could revert the tall dataset back to its original wide format using tidyr::pivot_wider(). This takes the following main arguments:\n\nnames_from → Column to get the output column names from\nvalues_from → Column to get the output values from\n\n\n\n\ndata_wide &lt;- data_long %&gt;% \n  pivot_wider(names_from = flavor_type,\n              values_from = flavor_score)\n\ndata_wide %&gt;% head\n\n\n  \n\n\nhead(data_wide == data_ff)\n\n     time treatment subject  rep potato buttery grassy rancid painty\n[1,] TRUE      TRUE    TRUE TRUE   TRUE    TRUE   TRUE   TRUE   TRUE\n[2,] TRUE      TRUE    TRUE TRUE   TRUE    TRUE   TRUE   TRUE   TRUE\n[3,] TRUE      TRUE    TRUE TRUE   TRUE    TRUE   TRUE   TRUE   TRUE\n[4,] TRUE      TRUE    TRUE TRUE   TRUE    TRUE   TRUE   TRUE   TRUE\n[5,] TRUE      TRUE    TRUE TRUE   TRUE    TRUE   TRUE   TRUE   TRUE\n[6,] TRUE      TRUE    TRUE TRUE   TRUE    TRUE   TRUE   TRUE   TRUE",
    "crumbs": [
      "R",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Notes -- Reshaping and Combining Data</span>"
    ]
  },
  {
    "objectID": "notes-r-reshaping-and-combining-data.html#gapminder-example",
    "href": "notes-r-reshaping-and-combining-data.html#gapminder-example",
    "title": "\n31  Notes – Reshaping and Combining Data\n",
    "section": "\n31.3 Gapminder example",
    "text": "31.3 Gapminder example\n\nTo illustrate more examples of reshaping and also merging datasets, we will recreate the Hans Rosling Gapminder visualization.\n\n\n31.3.1 Read in datasets\n\nFirst we need to read in the multiple gapminder datasets (gapminder.org/data) about life expectancy, income, population totals, and countries.\n\n\n# load data, rename / select columns and preview\ndata_life &lt;- read_csv(file = \"tutorials/reshaping-and-combining-data/www/life_expectancy_years.csv\") %&gt;% \n  rename(country = geo)\nhead(data_life)\n\n\n  \n\n\ndata_income &lt;- read_csv(file = \"tutorials/reshaping-and-combining-data/www/income_per_person.csv\") %&gt;% \n  rename(country = geo)\nhead(data_income)\n\n\n  \n\n\ndata_pop &lt;- read_csv(file = \"tutorials/reshaping-and-combining-data/www/population_total.csv\") %&gt;% \n  rename(country = geo)\nhead(data_pop)\n\n\n  \n\n\ndata_countries &lt;- read_csv(file = \"tutorials/reshaping-and-combining-data/www/countries_total.csv\",\n                           col_select = c(country = name, country_id = `alpha-2`,region))\nhead(data_countries)\n\n\n  \n\n\n\n\n31.3.2 Reshape datasets\n\nNow the life expectancy, income and population totals need to be pivot to be long data, just like we did with the french fry data.\n\n\ndata_life_long &lt;- data_life %&gt;% \n  pivot_longer(cols = -1,\n               names_to = \"year\",\n               values_to = \"life_exp\")\nhead(data_life_long)\n\n\n  \n\n\ndata_income_long &lt;- data_income %&gt;% \n  pivot_longer(cols = -1,\n               names_to = \"year\",\n               values_to = \"income\")\nhead(data_income_long)\n\n\n  \n\n\ndata_pop_long &lt;- data_pop %&gt;% \n  pivot_longer(cols = -1,\n               names_to = \"year\",\n               values_to = \"population\")\nhead(data_pop_long)\n\n\n  \n\n\n\n\n31.3.3 Combine datasets\n\nNow that each dataset has been converted to long format, we can begin to combine each of them into a single dataset.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe first step is to inner join the life expectancy, income, and population databy country and year. This will keep all observations with matching (Country, Year) values. This can be done in with a series of pipes.\nThen we can take that result and left join with the countries total data to add in the country abbreviations.\nThe join family of functions *_join() use join_by(lhs == rhs) to specify which columns to join by.\n\n\ndata_gapminder &lt;- data_life_long %&gt;% \n  inner_join(data_income_long, join_by(country, year)) %&gt;% \n  inner_join(data_pop_long, join_by(country, year)) %&gt;% \n  left_join(data_countries, join_by(country))\nhead(data_gapminder)\n\n\n  \n\n\n\n\n31.3.4 Visualize data\n\nNow that the data is merged, we can recreate the visual for a particular year.\n\n\ndata_gapminder %&gt;% \n  filter(year == max(year)) %&gt;% \n  ggplot() + \n  geom_point(aes(x = income,\n                 y = life_exp,\n                 size = population / 1000000,\n                 color = region)) + \n  labs(title = \"Hans Rosling Gapminder Visualization\",\n       x = \"Income per person ($)\",\n       y = \"Life expectancy (years)\",\n       size = \"Population size (millions)\",\n       color = \"Region\") + \n  theme_bw()",
    "crumbs": [
      "R",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Notes -- Reshaping and Combining Data</span>"
    ]
  },
  {
    "objectID": "notes-r-reshaping-and-combining-data.html#application",
    "href": "notes-r-reshaping-and-combining-data.html#application",
    "title": "\n31  Notes – Reshaping and Combining Data\n",
    "section": "\n31.4 Application",
    "text": "31.4 Application\n\n31.4.1 Setup\n\nLoad the halloween candy data (source), which contains yearly data on the number of candies given to trick-or-treaters in Cincinnati, OH dating back to 2008 and the weather data from some of those dates.\n\n\n# load candy and weather data with prespecified attributes\nload(file = \"tutorials/reshaping-and-combining-data/www/data-halloween.RData\")\nhead(data_candy)\n\n\n  \n\n\nhead(data_weather)\n\n\n  \n\n\n\n\nNote that the candy data is already in long format because the information is repeated for each time interval.\n\n31.4.2 Part a)\n\nIf we want to recreate the following scatterplot which visualizes maximum temperatures and total candy count, we need to have the data in wide format so that there is a separate column for the \\(X\\) and \\(Y\\) variable.\n\n\n\n\n\n\n\n\n\n\n\n\nNote that typically wide data is better for this type of plot and for reporting because it is easier to process than long data, but long data is preferred when we are doing any grouping in our plots such as multiple lines or facets.\nUsing the code chunk below, do the following:\n\n\nConvert the data_candy to wide format and name the resulting object data_halloween_wide.\nAdd the following lines of code after the pivot, which will add the candy amounts from each time interval across the rows to get a total count for the entire night:\n\n\ndata_candy_wide &lt;- &lt; code to pivot wide &gt; %&gt;% \n  rowwise %&gt;% \n  mutate(total = sum(c_across(`6:00pm`:`8:15pm`))) \n\nExplanation of code:\n- To sum across rows, data needs to be grouped by rows with dplyr::rowwise().\n- Then we can mutate(c_across()) the columns we want (c_across() pairs with rowwise() to perform row-wise aggregations).\n\nPipe another statement to join the weather data to the updated data_halloween_wide. Be sure to pick the correct type of join so that we keep all of the candy data (there is not weather data for every year).\nCreate the scatterplot of interest and try to add all of the extra features to make it a polished plot.\n\n31.4.3 Part b)\n\nUsing the code chunk below, perform the necessary data steps and recreate the following plot that visualizes the candy count by time interval across years. Try to add all of the extra features to make it a polished plot. HINT: To format the color of the lines, add scale_color_brewer() to your ggplot function call for the color palette used above.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Notes -- Reshaping and Combining Data</span>"
    ]
  },
  {
    "objectID": "notes-r-reshaping-and-combining-data.html#application-solutions",
    "href": "notes-r-reshaping-and-combining-data.html#application-solutions",
    "title": "\n31  Notes – Reshaping and Combining Data\n",
    "section": "\n31.5 Application solutions",
    "text": "31.5 Application solutions\nApplication 31.4.2\n\n# pivot to wide data, then calculate total candy count, and join with weather data\ndata_halloween_wide &lt;- data_candy %&gt;% \n  pivot_wider(names_from = Time,\n              values_from = Count) %&gt;% \n  rowwise %&gt;% \n  mutate(total = sum(c_across(`6:00pm`:`8:15pm`))) %&gt;% \n  left_join(data_weather, by = \"Date\")\n\n# create scatterplot of max temp and total candy count\nggplot(data = data_halloween_wide,\n       aes(x = TMAX,\n           y = total)) + \n  geom_point(color = \"orange\") + \n  geom_text(aes(label = year(Date)),\n            vjust = -1) + \n  labs(title = \"Halloween candy count\",\n       x = \"Max temp on Halloween (F)\",\n       y = \"Total candy count\") + \n  theme_bw()\n\n\n\n\n\n\n\n\n\nApplication 31.4.3\n\n# convert halloween data to long so can group by time interval for lines\ndata_halloween_long &lt;- data_halloween_wide %&gt;% \n  pivot_longer(cols = `6:00pm`:total,\n               names_to = \"Time\",\n               values_to = \"Count\")\n\n# create polished line plot\ndata_halloween_long %&gt;% \n  ggplot() + \n  geom_line(aes(x = Date,\n                y = Count,\n                group = Time,\n                color = Time)) + \n  scale_color_brewer() + \n  labs(title = \"Halloween candy count over the years\",\n       x = \"Year\",\n       y = \"Candy count\",\n       color = \"30-min time interval\") + \n  theme_bw()",
    "crumbs": [
      "R",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Notes -- Reshaping and Combining Data</span>"
    ]
  },
  {
    "objectID": "lab-r-data-cleaning.html#overview",
    "href": "lab-r-data-cleaning.html#overview",
    "title": "\n32  Lab - Data Cleaning\n",
    "section": "\n32.1 Overview",
    "text": "32.1 Overview\nThis problem applies the ideas from the notes ‘3.4 – Reshaping and Combining Data’, where we learned to restructure datasets, and also uses functions from dplyr functions from ‘3.3 – Data Transformations’.\nWe will be working with the midwest-gas-prices.csv data, which contains the average weekly midwestern fuel prices for a gallon of regular unleaded gasoline from November 1994 to May 2012. We want to use this data to create a time series line-plot of the data that looks like the image below:\n\n\n\n\n\n\nThe problem is that the data is very messy and improperly structured to create this visualization. Here is how the data file is structured in Excel and how it would read directly into R.\n\n\n\n\n\n\n\n\n\n\n Year.Month \n    Week.1 \n    X \n    Week.2 \n    X.1 \n    Week.3 \n    X.2 \n    Week.4 \n    X.3 \n    Week.5 \n    X.4 \n  \n\n\n  \n    End Date \n    Value \n    End Date \n    Value \n    End Date \n    Value \n    End Date \n    Value \n    End Date \n    Value \n  \n\n 1994-Nov \n     \n     \n     \n     \n     \n     \n    11/28/16 \n    1.122 \n     \n     \n  \n\n 1994-Dec \n    12/5/16 \n    1.086 \n    12/12/16 \n    1.057 \n    12/19/16 \n    1.039 \n    12/26/16 \n    1.027 \n     \n     \n  \n\n 1995-Jan \n    1/2/16 \n    1.025 \n    1/9/16 \n    1.046 \n    1/16/16 \n    1.031 \n    1/23/16 \n    1.054 \n    1/30/16 \n    1.055 \n  \n\n 1995-Feb \n    2/6/16 \n    1.045 \n    2/13/16 \n    1.04 \n    2/20/16 \n    1.031 \n    2/27/16 \n    1.052 \n     \n     \n  \n\n\n\n\nThis assignment will take you through steps to resolve all of the structural issues with the current data and also clean it.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Lab - Data Cleaning</span>"
    ]
  },
  {
    "objectID": "lab-r-data-cleaning.html#assignment",
    "href": "lab-r-data-cleaning.html#assignment",
    "title": "\n32  Lab - Data Cleaning\n",
    "section": "\n32.2 Assignment",
    "text": "32.2 Assignment\nThe goal of this assignment is to restructure and clean the data in R using the dplyr, tidyr, stringr, and lubridate packages.\nOverview of the current setup of data:\n\nCurrently the data is very messy and improperly structured to create the desired visualization.\nThere is one column for year/mon.\nPrices and more dates are spread across multiple columns, all with bad labels.\nAnd all date columns are character variables.\n\nOur end goal for the data is as follows to have a data frame that has only two columns: date and price. Complete each of the following steps in order to ultimately recreate the visual of interest.\n\n32.2.1 Part a – Import data\nThe header of this data is two rows of poorly formatted labels. When you read in the data you will want to skip over the header using the options in the read_csv() function.\nHere is the result after properly being read in:\n\n\n\n\n ...1 \n    End Date...2 \n    Value...3 \n    End Date...4 \n    Value...5 \n    End Date...6 \n    Value...7 \n    End Date...8 \n    Value...9 \n    End Date...10 \n    Value...11 \n  \n\n\n 1994-Nov \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    11/28/16 \n    1.122 \n    NA \n    NA \n  \n\n 1994-Dec \n    12/5/16 \n    1.086 \n    12/12/16 \n    1.057 \n    12/19/16 \n    1.039 \n    12/26/16 \n    1.027 \n    NA \n    NA \n  \n\n 1995-Jan \n    1/2/16 \n    1.025 \n    1/9/16 \n    1.046 \n    1/16/16 \n    1.031 \n    1/23/16 \n    1.054 \n    1/30/16 \n    1.055 \n  \n\n 1995-Feb \n    2/6/16 \n    1.045 \n    2/13/16 \n    1.040 \n    2/20/16 \n    1.031 \n    2/27/16 \n    1.052 \n    NA \n    NA \n  \n\n 1995-Mar \n    3/6/16 \n    1.053 \n    3/13/16 \n    1.042 \n    3/20/16 \n    1.048 \n    3/27/16 \n    1.065 \n    NA \n    NA \n  \n\n\n\n\n\n32.2.2 Part b – Reshape data\nThe first column has the year/month combined followed by five pairs of columns for the dates and prices associated with weeks 1 through 5 of each month. Each of these five column pairs will need to be moved from wide format to long format using functions in the tidyr package.\nNote that this will be made much easier if you:\n\nFirst create separate data frames with the columns of dates and columns of prices\nThen pivot the columns in each\nThen recombine after they have both been reformatted wide-to-long.\n\nHere is what the price information should look like:\n\n\n\n\n price \n  \n\n\n NA \n  \n\n NA \n  \n\n NA \n  \n\n 1.122 \n  \n\n NA \n  \n\n 1.086 \n  \n\n 1.057 \n  \n\n 1.039 \n  \n\n 1.027 \n  \n\n NA \n  \n\n\n\n\nAnd now the date information:\n\n\n\n\n year_month \n    unneeded_column \n    month_day \n  \n\n\n 1994-Nov \n    End Date...2 \n    NA \n  \n\n 1994-Nov \n    End Date...4 \n    NA \n  \n\n 1994-Nov \n    End Date...6 \n    NA \n  \n\n 1994-Nov \n    End Date...8 \n    11/28/16 \n  \n\n 1994-Nov \n    End Date...10 \n    NA \n  \n\n 1994-Dec \n    End Date...2 \n    12/5/16 \n  \n\n 1994-Dec \n    End Date...4 \n    12/12/16 \n  \n\n 1994-Dec \n    End Date...6 \n    12/19/16 \n  \n\n 1994-Dec \n    End Date...8 \n    12/26/16 \n  \n\n 1994-Dec \n    End Date...10 \n    NA \n  \n\n\n\n\n\n32.2.3 Part c – Clean data\nFor the date information, extra steps are needed after reshaping.\n\nNotice that the years for each date are listed as 2016 in the month/day column, this needs to be replaced with the real year from the year/month column. I suggest using a combination of the stringr::str_sub() and the paste() function to fix the year.\nAfter you get the date column similar to “mm/dd/yyyy” or “mm-dd-yy”, you can use lubridate::mdy() to transform the column to a POSIX date-formatted variable.\n\n\n\n\n\n date \n  \n\n\n NA \n  \n\n NA \n  \n\n NA \n  \n\n 1994-11-28 \n  \n\n NA \n  \n\n 1994-12-05 \n  \n\n 1994-12-12 \n  \n\n 1994-12-19 \n  \n\n 1994-12-26 \n  \n\n NA \n  \n\n\n\n\n\n32.2.4 Part d – Combine data\nNow we can combine the date and price data back together with base R cbind() or dplyr::bind_cols() in order to create the final desired dataset for the visualization.\n\n\n\n\n date \n    price \n  \n\n\n NA \n    NA \n  \n\n NA \n    NA \n  \n\n NA \n    NA \n  \n\n 1994-11-28 \n    1.122 \n  \n\n NA \n    NA \n  \n\n 1994-12-05 \n    1.086 \n  \n\n 1994-12-12 \n    1.057 \n  \n\n 1994-12-19 \n    1.039 \n  \n\n 1994-12-26 \n    1.027 \n  \n\n NA \n    NA \n  \n\n\n\n\n\n32.2.5 Part e – Visualize data\nNow recreate the desired visualization using the final dataset.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Lab - Data Cleaning</span>"
    ]
  },
  {
    "objectID": "hw-r-data-manipulations.html#overview",
    "href": "hw-r-data-manipulations.html#overview",
    "title": "\n33  HW - Data Manipulations\n",
    "section": "\n33.1 Overview",
    "text": "33.1 Overview\nThis problem ties together concepts and functions from all the previous R notes for a comprehensive data analysis problem.\nWe will be working with hypothetical student grade data data-grades.csv, which contains information on two test scores from students of multiple sections for a single professor, and enrollment data data-majors.csv, which has the students major.\n\n\n\n\n ID \n    Student \n    Test_1 \n    Test_2 \n  \n\n\n 1381 \n    LZ-1 \n    20 \n    55 \n  \n\n 2027 \n    KO-1 \n    30 \n    40 \n  \n\n 6077 \n    DD-1 \n    28 \n    68 \n  \n\n 6869 \n    IG-2 \n    14 \n    42 \n  \n\n 4171 \n    VS-1 \n    28 \n    50 \n  \n\n\n\n\n\n\n ID \n    Major \n  \n\n\n 9810 \n    Physics \n  \n\n 9718 \n    Physics \n  \n\n 9685 \n    Chemisty \n  \n\n 9618 \n    Chemisty \n  \n\n 9520 \n    Physics \n  \n\n\n\n\nTo read in the data, first download it from Canvas and then change the path in the read_csv() statement above to where you have saved the data relative to the location of the your homework file.\nThis assignment will take you through steps to clean, organize and analyze these the test scores.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>HW - Data Manipulations</span>"
    ]
  },
  {
    "objectID": "hw-r-data-manipulations.html#assignment",
    "href": "hw-r-data-manipulations.html#assignment",
    "title": "\n33  HW - Data Manipulations\n",
    "section": "\n33.2 Assignment",
    "text": "33.2 Assignment\nThe goal of this assignment is to demonstrate common data manipulation tasks using packages from the tidyverse.\n\n33.2.1 Part a – Data manipulations\nThe goal is to have a single dataset with the following columns:\n\nID\n\nStudent: just two initials\nMajor\n\nClass: 1 or 2\n\nTest_1: % out of 100\n\nTest_2: % out of 100\n\n\nFor the grades data, we need to split the current student column into two variables, one of their initials and one for the class they are in. Use tidyr::separate_wider_delim() to do so.\nConvert the test scores to percentages (Test 1 is out of 30 points and Test 2 is out of 70 points).\nCombine grades data and majors data and then sort alphabetically by student initials within each class.\n\n33.2.2 Part b – Visualize data\nNow that the data is cleaned and organized, lets visualize the Test 1 scores to start with.\nCreate two polished plots to visualize Test 1 scores, at least one of which should include a class comparison or major comparison.\n\n33.2.3 Part c – Summarize data\nNow that we have an idea of the distributions for Test 1, let’s summarize them, specifically we want to create an overall summary and a summary by class.\n\nCreate a test 1 dataset that contains only the Class, Student initials and Test 1 score.\nCreate an object named data_summary_overall that summarizes Test 1 scores with the sample size, average and standard deviation. Then add the following lines of code to add an indicator column and rearrange the columns.\n\n\ndata_summary_overall &lt;- &lt; previous summary function call &gt; %&gt;% \n  mutate(Class = \"Overall\") %&gt;% \n  select(4, 1:3)\n\n\nCreate another object called data_summary_section that performs the same summary functions the previous step, except by Class.\nCombine the overall summary with the class summary rowwise.\n\n33.2.4 Part d – More manipulations and visualizations 1\nIf we want to visualize both tests and class at the same time, some more data restructuring is necessary. Specifically, we need the data to have the following columns:\n\nID\n\nStudent: just two initials\nMajor\n\nClass: 1 or 2\n\nTest: 1 or 2\n\nGrade: % out of 100\n\nThus, there is two rows per student, one for each test grade.\nPerform the necessary data steps and then recreate the following visual. Note that two have the labels for Test 1 and Test 2 nicely formatted, the values need to be cleaned in the data.\n\n\n\n\n\n\n\n\n\n\n\n33.2.5 Part e – More manipulations and visualizations 2\nNow the professor wants to investigate applying a curve by major for Test 1 grades.\n\nUsing the Test 1 data from Part c, create a new dataset that also contains curved grades for Test 1 according to the following scheme:\n\n\nClass 1 receives 3 additional points.\nClass 2 receives a 30% of their missed points back (HINT: On paper work out an algebra function that accomplishes this and spot check a few values to make sure they are correct).\n\nHINT: Use case_when().\n\nUsing the curved data, perform the necessary data steps and then recreate the following visual.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>HW - Data Manipulations</span>"
    ]
  },
  {
    "objectID": "notes-r-interactive-plots.html#overview",
    "href": "notes-r-interactive-plots.html#overview",
    "title": "\n34  Notes – Interactive Plots\n",
    "section": "\n34.1 Overview",
    "text": "34.1 Overview\n\n34.1.1 Materials\n\nAttached are all of the supplemental materials to this content! Feel free to check them out :)\nHere are the videos that go through the tutorial:\n\n\n\n\n\n\n\nAnd finally here is the starter file mentioned: interactive-plots-STARTER.qmd\n\n\n34.1.2 This section\n\nThis tutorial furthers the ideas from the Visualizations tutorial, where we learned how to create many different visuals to display one or several quantitative and/or qualitative variables using ggplot2. Specifically, we will learn how to make our plots interactive using plotly.\nAdding interactivity to plots can make visualizations more effective when communicating, as well as allowing you to explore your data more in depth and ask more questions along the way. Thus, it is can be important part of the exploratory data analysis (EDA) and the final communication.\nWe will also introduce some non-standard plot types.\n\n34.1.3 Readings\n\nThis tutorial covers content from the following chapters of Interactive web-based data visualization with R, plotly, and shiny (link to book): chapters 2, 3, 5, 6, 7, 13, 14, 15, and 16.\nplotly help documentation has lots of examples for different uses of plotly in R as well as demonstrations to get started.\n\n34.1.4 Prerequisites\n\nIn addition to the tidyverse, we need to load other packages (note that a few other packages may be needed for specific functions that are called without loading the libraries). We can do this by running:\n\n\nlibrary(tidyverse)\nlibrary(gapminder)\nlibrary(plotly)\nlibrary(corrplot)\nlibrary(GGally)\nlibrary(crosstalk)\nlibrary(DT)\nlibrary(ggforce)\n\n\n34.1.5 Goal\n\nThe goal of this tutorial is to learn the basic plotly framework for how to build interactive plots, including adding interactivity to ggplot2 code and building interactivity “from scratch”.\nWe will then then extend the basics to add graphical queries to our plots, which can aide in the exploratory data analysis (EDA) phase, combating overplotting and focusing on a particular narrative. Here is a preview of these features.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSelect a city",
    "crumbs": [
      "R",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Notes -- Interactive Plots</span>"
    ]
  },
  {
    "objectID": "notes-r-interactive-plots.html#ggplotly",
    "href": "notes-r-interactive-plots.html#ggplotly",
    "title": "\n34  Notes – Interactive Plots\n",
    "section": "\n34.2 ggplotly()",
    "text": "34.2 ggplotly()\n\n34.2.1 Building simple interactive plots\n\nThe easiest way to add interactivity to plots is via plotly::ggplotly(), which allows us to create our usual ggplot2 workflows and then translate them to plotly.\nTo do this, we simply need to create a ggplot object, say p &lt;- &lt; ggplot call &gt; and pass that to our new function, ggplotly(p).\n\n\np &lt;- ggplot(data = diamonds,\n            aes(x = cut)) + \n  geom_bar()\nggplotly(p)\n\n\n\n\n\n\n34.2.2 Interactivity for other plots\n\nHere is a demonstration of the types of interactivity that ggplotly() gives us for various plot types we already know.\nSide-by-side bar graphs: With multiple aesthetics being mapped to, there are more interactive features available after converting to a plotly object.\n\n\np &lt;- ggplot(data = diamonds,\n            aes(x = cut,\n                fill = clarity)) + \n  geom_bar(position = \"dodge\")\nggplotly(p)\n\n\n\n\n\n\nHistograms\n\n\np &lt;- ggplot(data = diamonds,\n            aes(x = price)) + \n  geom_histogram() + \n  facet_grid(cut ~ .,\n             scales = \"free_y\")\nggplotly(p)\n\n\n\n\n\n\nFor boxplots, the numeric variable needs to be on the y aesthetic for ggplotly() to work as expected.\n\n\np &lt;- ggplot(data = diamonds,\n       aes(x = cut,\n           y = price)) + \n  geom_boxplot()\nggplotly(p)\n\n\n\n\n\n\n34.2.3 Exercise\n\nCreate a proportionally stacked bar chart of price by clarity using the diamonds dataset, then add interactivity. Does all of the interactivity features work well with this plot type?\n\n34.2.4 New plots with interactivity\n\nScatterplots. One problem with scatterplots is the possibility of overplotting, which is when there are multiple observations occupying the same (or similar) x/y locations. When this occurs, it is hard to get an idea of the number of points at a particular spot (frequency).\nOne solution to this is to use alpha blending to make points semi-transparent, then the darker spots indicate more data. This strategy works well when there are up to roughly 10,000 data points.\n\n\np &lt;- ggplot(data = slice_sample(diamonds, n = 10000),\n       aes(x = log(carat),\n           y = log(price))) + \n  geom_point(alpha = 0.1)\nggplotly(p)\n\n\n\n\n\nAnother solution is to change plot types to a hexagonal heat map of 2d bin counts via geom_hex(). This plot essentially divides the plane into regular hexagons and colors the hexagon on a gradient scale based on the count of observations in the hexagon.\n\nThus the problem of overplotting is solved by plotting counts via color scale (fill) rather than raw data points.\n\n\np &lt;- ggplot(data = diamonds,\n            aes(x = log(carat),\n                y = log(price))) + \n  geom_hex(bins = 100)\nggplotly(p)\n\n\n\n\n\n\nFor interactivity, this demonstrates that ggplotly() can be a very useful strategy for adding interactivity to plot types that wouldn’t be straightforward to achieve without it (e.g. using the already well-built ggplot2 suite of functions and features).\nOne common application that is great for ggplotly() is for exploring statistical summaries across groups.\nFor example, if we wanted to look at the distributions of diamond prices for each clarity, then we could create frequency plygons for each level using geom_freqpoly().\n\n\np &lt;- ggplot(data = diamonds,\n            aes(x = price,\n                color = clarity)) + \n  geom_density()\nggplotly(p)\n\n\n\n\n\n\n34.2.5 Application\n\nWe will return to the Gapminder dataset for the motivating example of plotly.\n\n\n?gapminder\nhead(gapminder)\n\n\n  \n\n\n\n\nLet’s create the bubble plot of the most recent year of gdp per capita by life expectancy, then add interactivity.\nBubble plots extend scatterplots to 3 dimensions, but comparisons on third dimension difficult, and overplotting also gets in the way. So we want to make sure adding the third dimension via size is the right decision.\n\n\ngapminder_recent &lt;- gapminder %&gt;% filter(year == max(year))\nyear &lt;- unique(gapminder_recent$year)\n\np &lt;- ggplot(data = gapminder_recent,\n            aes(x = gdpPercap,\n                y = lifeExp,\n                size = pop / 1000000,\n                color = continent,\n                label = country)) + \n  geom_point() + \n  scale_x_continuous(labels = scales::comma) + \n  scale_size_continuous(labels = scales::comma) +  \n  labs(title = \"Gapminder 2007\", # bquote(\"Gapminder \" * .(year))\n       x = \"GDP per capita ($)\",\n       y = \"Life expectancy (years)\",\n       size = \"Population (millions)\",\n       color = \"Continent\") + \n  theme_bw()\nggplotly(p)\n\n\n\n\n\n\nBy default, the only interactive info (mouse over text) that we get is what went into the geom_point(aes()).\nTo get mouse over for country also (and not change the plot at all), we have to trick it. For geom_point, label is an unused attribute (aes), so we can add a label = country to the aes. The plot ignores it, but the mouse over adds country (this is kind of the hacker-ish way).\nBut what if we didn’t want lifeExp and gdpPercap to be shown in mouse over? This customization would be hard to do with ggplotly().\nInstead, we would have to make the plot directly using plotly and the plot_ly() function, which is the general all purpose plot function for plotly (analogous to ggplot() function).",
    "crumbs": [
      "R",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Notes -- Interactive Plots</span>"
    ]
  },
  {
    "objectID": "notes-r-interactive-plots.html#rebuilding-plots-with-plot_ly",
    "href": "notes-r-interactive-plots.html#rebuilding-plots-with-plot_ly",
    "title": "\n34  Notes – Interactive Plots\n",
    "section": "\n34.3 Rebuilding plots with plot_ly()",
    "text": "34.3 Rebuilding plots with plot_ly()\n\n34.3.1 plot_ly() basics\n\nUsing plot_ly() gives us the interactivity automatically and allows us to give more customizations to features. We will start with the basics.\nIf we assign variable names (e.g., cut, clarity, etc.) to visual properties (e.g., x, y, color, etc.) within plot_ly(), it tries to find a sensible geometric representation of that information for us (i.e. it will try and guess what type of plot we want).\nplotly doesn’t use the grammer of graphics the same way ggplot does (so plotly doesn’t work with aes(), although the data argument still works the same).\nInstead, in order to tell plotly the mapping from the dataset to attributes, it uses a ~ (tilde, recall tilde’s in R define formulas, i.e. a data mapping). This is a shorthand function to say which variable are from the data.\n\n\nplot_ly(diamonds, x = ~cut)\n\n\n\n\nplot_ly(diamonds, x = ~cut, y = ~clarity)\n\n\n\n\nplot_ly(diamonds, x = ~cut, color = ~clarity)\n\n\n\n\n\n\nThe plot_ly() function has numerous arguments (think ggplot aesthetics: color = fill, stroke = outline color, span = outline width, symbol, linetype, etc.) that make it easier to encode data variables (e.g. diamond clarity) as visual properties (e.g. color).\nBy default, these arguments map values of a data variable to a visual range defined by the plural form of the argument.\n\n\n\n\n\n\n\n\nFor example, we can use color to map each level of diamond clarity to a different color, then colors is used to specify the range of colors (e.g. the \"Accent\" color palette from the RColorBrewer package, but we can also manually specify colors).\n\n\nplot_ly(diamonds,\n        x = ~cut,\n        color = ~clarity,\n        colors = \"Accent\")\n\n\n\n\nplot_ly(diamonds,\n        x = ~cut,\n        color = ~cut,\n        colors = c(\"red\", \"green\", \"blue\", \"yellow\", \"purple\"))\n\n\n\n\n\n\nSince these arguments map data values to a visual range by default, you will obtain unexpected results if you try to specify the visual range directly.\nIf you want to specify the visual range directly, use the I() function to declare this value to be taken ‘AsIs’.\n\n\nplot_ly(diamonds, x = ~cut,\n        color = \"black\")\n\n\n\n\nplot_ly(diamonds,\n        x = ~cut, \n        color = I(\"red\"), stroke = I(\"black\"), span = I(2))\n\n\n\n\n\n\n34.3.2 Building plotly objects\n\nThe plotly package takes a purely functional approach to a layered grammar of graphics, which means (almost) every function anticipates a plotly object as input to it’s first argument and returns a modified version of that plotly object.\nFor a quick example, the layout() function anticipates a plotly object in it’s first argument and it’s other arguments add and/or modify various layout components of that object (e.g. the title).\nFor more complex plots with multiple “steps”, we can chain them together with pipes %&gt;%.\n\n\nlayout(\n  plot_ly(diamonds, x = ~cut),\n  title = \"My beatiful histogram\"\n)\n\n\n\n\nplot_ly(diamonds, x = ~cut) %&gt;% layout(title = \"My beatiful histogram\")\n\n\n\n\n\n\nIn addition to layout() for adding/modifying part(s) of the graph’s layout, there are also a family of add_*() functions (e.g., add_histogram(), add_lines(), etc.) that define how to render data into geometric objects. In other words, these functions add a graphical layer to a plot. In plotly, layers are called traces.\nWhen using these functions, we are being explicit about what type of plot plot_ly() should create.\n\n\ndiamonds %&gt;%\n  plot_ly() %&gt;% \n  add_histogram(x = ~cut)\n\n\n\n\n\n\n\nIn many scenarios, it can be useful to combine multiple graphical layers into a single plot. In this case, it becomes useful to know a few things about plot_ly():\n\nArguments specified in plot_ly() are global, meaning that any downstream add_*() functions inherit these arguments (unless inherit = FALSE). This is the same way that ggplot() works.\nData manipulation verbs from the dplyr package may be used to transform the data underlying a plotly object.\nCan use plotly_data() function to obtain the data at any point in time, which is primarily useful for debugging purposes (i.e. inspecting the data of a particular graphical layer).\n\n\nFor example, let’s create a bar graph and add data labels atop the bars.\n\n\ndiamonds %&gt;%\n  plot_ly(x = ~cut) %&gt;% \n  add_histogram() %&gt;%\n  #plotly_data() \n  group_by(cut) %&gt;%\n  summarise(n = n()) %&gt;%\n  #plotly_data()\n  add_text(text = ~n, \n           y = ~n,\n           textposition = \"top middle\")",
    "crumbs": [
      "R",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Notes -- Interactive Plots</span>"
    ]
  },
  {
    "objectID": "notes-r-interactive-plots.html#common-plotly-plots",
    "href": "notes-r-interactive-plots.html#common-plotly-plots",
    "title": "\n34  Notes – Interactive Plots\n",
    "section": "\n34.4 Common plotly plots",
    "text": "34.4 Common plotly plots\n\n34.4.1 Bars and histograms\n\nThere is almost a one-to-one with naming conventions from geom_* to add_* because plotly was made to work well with tidyverse.\n\nadd_bars() and add_histogram() work the same way as ggplot geom_bar() and geom_histogram(), respectively.\n\nThe main difference between them is that bars trace requires bar heights (both x and y), whereas histogram traces require just a single variable, and it handles binning automatically (i.e. it performs statistics dynamically in the web browser).\nThis means for add_bars(), we have to do the counting ourselves prior to handing the data to plot_ly(), and for add_histogram() we just give it the raw data.\n\n\nAnd perhaps confusingly, both of these functions can be used to visualize the distribution of either a numeric or a discrete variable.\nTo demonstrate these, lets take a look at the datasets::mtcars dataset, which contains information about 32 cars from 1973-74.\n\n\n# preview data\nmtcars %&gt;% tibble::rownames_to_column(var = \"model\")\n\n\n  \n\n\n\n\nmtcars %&gt;%\n  plot_ly(x = ~mpg) %&gt;% \n  add_histogram(stroke = I(\"black\"))\n\n\n\n\nmtcars %&gt;%\n  # plot_ly(x = ~factor(cyl)) %&gt;% \n  add_histogram(stroke = I(\"black\"))\n\nError: Must supply `x` and/or `y` attributes\n\nmtcars %&gt;% \n  count(cyl = factor(cyl)) %&gt;% \n  mutate(cyl = fct_reorder(cyl, n, .desc = TRUE)) %&gt;% \n  plot_ly(x = ~cyl,\n          y = ~n) %&gt;% \n  add_bars()\n\n\n\n\n\n\n34.4.2 Exercise\n\nUsing the gapminder dataset, create a bar graph of the number of countries per continent in only the first year of data collection. Can you create this bar graph two different ways?\n\nCHALLENGE: Polish this plot by sorting by descending frequency, adding data labels on top of the bars, adding an informative title and hiding the legend.\n\n34.4.3 Boxplots and schema()\n\nBoxplots encode the five number summary of a numeric variable, and provide a decent way to compare many numeric distributions. We saw how to create comparative boxplots with ggplotly(), here’s how to do it directly with plot_ly() and add_boxplot().\nBy default, all outliers are shown. This can be changed via the boxpoints argument of add_boxplot().\nThe help documentation for plotly functions isn’t as useful as for other packages, so instead the best way to check what attributes (arguments) functions can take and their default values, possible values, etc., run schema() in your console and navigate through here.\nOnline help documents, then find the specific trace we need boxplots would be a second option for help.\n\n\ndiamonds %&gt;%\n  plot_ly(x = ~price,\n          y = ~cut) %&gt;% \n  add_boxplot(boxpoints = FALSE)\n\n\n\n\n\n\nWhen making comparative boxplots, it can be useful to sort by something meaningful, such as the median value. To do this, we simply need to mutate() the factor to have a different ordering of the levels via fct_reorder().\n\n\ndiamonds %&gt;% \n  mutate(cut = fct_reorder(.f = cut, .x = price, .fun = median)) %&gt;% \n  plot_ly(x = ~price,\n          y = ~cut) %&gt;% \n  add_boxplot(boxmean = TRUE)\n\n\n\n\n\n\n34.4.4 Exercise\n\nUsing the iris dataset, create comparative boxplots of Sepal.Width for each Species, sorted by descending mean.\n\n34.4.5 Scatterplots\n\nTo make a scatterplot, we can use add_markers(). Here is a simple example.\n\n\nmtcars %&gt;% \n  plot_ly(x = ~wt,\n          y = ~mpg) %&gt;% \n  add_markers()\n\n\n\n\n\n\n34.4.6 Application\n\nNow let’s recreate the bubble plot for the most recent year of the gapminder dataset building from plot_ly().\n\nTo get the mouse over for country, the aesthetic is text, rather than label.\n\nBut the mouse overs (hover) don’t look very nice. So to make the text look better, we can just paste() what text we want (and use some html code to help).\n\n\n\n\ngapminder %&gt;% \n  filter(year == max(year)) %&gt;% \n  plot_ly(x = ~gdpPercap,\n          y = ~lifeExp,\n          size = ~pop,\n          color = ~continent,\n          text = ~paste0(\"Country: \", country, \"&lt;br&gt;Population: \", scales::comma(pop))) %&gt;% \n  add_markers() \n\n\n\n\n\n\nNow to see the real value of plotly, we can add animations through the frame argument (in plot_ly()) / aesthetic (in the ggplot() call before ggplotly()).\nInstead of filtering the data down to one year, we can use the whole gapminder dataset and add frame = ~year (or aes(frame = year)), which will make the visualization into an animation. By default, animated views come with a play/pause button(s) and a slider component for controlling the animation. These can be customized; see Chapter 14.\n\n\ngapminder %&gt;% \n  plot_ly(x = ~gdpPercap,\n          y = ~lifeExp,\n          size = ~pop,\n          color = ~continent,\n          text = ~paste0(\"Country: \", country, \"&lt;br&gt;Population: \", scales::comma(pop)),\n          frame = ~year) %&gt;% \n  add_markers() \n\n\n\n\n\n\n34.4.7 Exercise\n\n\nUsing the iris dataset, create two scatterplots of Sepal.Width by Sepal.Length:\n\nScatterplot 1: The color of every point is green, and the mouse over info also displays the Species.\nScatterplot 2: Color each point by Species, except we want to the colors to be as follows: setosa = darkgreen, versicolor = green, virginica = grey.\n\n\n\n34.4.8 Line plots\n\nTo make a line plot, we can useadd_paths() or add_lines().\n\nThe only difference between these two is that add_paths() connects the dots according to row order, while add_lines() connects the dots according to another variable (x).\n\nSo if your dataset is properly sorted, they should get the same result, but add_lines() is probably better to be more explicit about the connecting.\n\n\n\n\ndata_sun &lt;- data.frame(year = c(1700:1988),\n                       sunspots = as.vector(sunspot.year)) %&gt;% \n  arrange(sunspots)\n\ndata_sun %&gt;% \n  plot_ly(x = ~year,\n          y = ~ sunspots) %&gt;% \n  add_paths()\n\n\n\n\ndata_sun %&gt;% \n  plot_ly(x = ~year,\n          y = ~ sunspots) %&gt;% \n  add_lines()\n\n\n\n\n\n\nSuppose we want to make a time series plot of multiple lines using the ggplot2::economics dataset.\nThere’s a few different ways to do this based on the level of interactivity that we want. In all cases though, we need to group_by() the variable that determines the different lines before passing to plot_ly().\n\nSo for this example, if we want to have a separate line for each year (across the months), then we can do the following.\n\nThis basic way adds only a single trace (one layer).\n\n\n\n\nhead(economics)\n\n\n  \n\n\necon &lt;- economics %&gt;%\n  mutate(year = year(date),\n         month = month(date))\n\necon %&gt;% \n  group_by(year) %&gt;% \n  plot_ly(x = ~month,\n          y = ~unemploy) %&gt;% \n  add_lines(text = ~year)\n\n\n\n\n\n\n\nIf we want to be able to compare values at different lines with the interactivity, we need to add the grouping variable to another aesthetic to differentiate them, for lines this could be color or linetype (which only can do 6 different line types).\n\nThis way adds trace for each year, so each one is a different layer, which allows the extra interactivity.\n\n\n\n\necon %&gt;% \n  group_by(year) %&gt;% \n  plot_ly(x = ~month,\n          y = ~unemploy) %&gt;% \n  add_lines(color = ~ordered(year))\n\n\n\n\n\n\n\nIf we wanted to keep the interactivity, but different colors doesn’t fit into our narrative, we need to use the split argument.\n\nThis guarantees one trace per group level (regardless of the variable type), which is useful if you want a consistent visual property over multiple traces. Then we need be explicit about the constant color using I().\n\n\n\n\necon %&gt;% \n  group_by(year) %&gt;% \n  plot_ly(x = ~month,\n          y = ~unemploy) %&gt;% \n  add_lines(split = ~ordered(year),\n            color = I(\"grey\"))\n\n\n\n\n\n\n34.4.9 Application\n\nReturning to the gapminder data, let’s create time series plots for each country.\n\n\ngapminder %&gt;% \n  group_by(country) %&gt;% \n  plot_ly(x = ~year, y = ~lifeExp, text = ~country) %&gt;% \n  add_lines(color = ~continent)\n\n\n\n\n\n\nWe see that there are some interesting countries that do not follow the general trend. These would be things to focus on when trying to tell a narrative.\nThis first graph, which in practice would probably be made with ggplotly(), would be a good exploration tool (EDA phase) for us to see easily see which countries those were. Then we decide what we want to delve into further and create polished plots to communicate with.\nTo polish this plot and create our narrative (good storytelling strategy), we want to focus on just these three countries and make the rest blend into the background. For plot design this means we want to make all of the non interesting countries lines grey and remove their hover text. Then make the interesting ones red and add mouseover to further highlight those.\nTo do this, we can use the fact that the active dataset (the newest one) is the one that plot_ly() builds that layer from. So we can start at the top and make sub data frames and layers that highlight those specific data points.\n\n\ngapminder %&gt;% \n  group_by(country) %&gt;% \n  plot_ly(x = ~year, y = ~lifeExp) %&gt;% \n  #plotly_data() %&gt;% \n  add_lines(color = I(\"grey\"), hoverinfo = \"skip\") %&gt;% \n  filter(country %in% c(\"Cambodia\", \"China\", \"Rwanda\")) %&gt;% \n  #plotly_data() %&gt;% \n  add_lines(text = ~country,\n            color = I(\"red\")) %&gt;% \n  hide_legend()",
    "crumbs": [
      "R",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Notes -- Interactive Plots</span>"
    ]
  },
  {
    "objectID": "notes-r-interactive-plots.html#other-types-of-plotly-plots",
    "href": "notes-r-interactive-plots.html#other-types-of-plotly-plots",
    "title": "\n34  Notes – Interactive Plots\n",
    "section": "\n34.5 Other types of plotly plots",
    "text": "34.5 Other types of plotly plots\n\n34.5.1 2D histogram and heatmap\n\nTo create a new plot type called a 2D histogram (for numeric data) or a heatmap (for categorical data), we can use add_histogram2d(). This colors rectangular bins based on the count, just like the hexagonal heat map.\n\n\ndiamonds %&gt;% \n  plot_ly(x = ~log(carat), y = ~log(price)) %&gt;% \n  add_histogram2d()\n\n\n\n\n\n\nThis type of plot can be used for a statistical plot called a correlation plot, which plots the correlation between each pair of numeric variables. A static way to do this is with corrplot::corrplot().\nBut we can recreate a version of this to add interactivity. Since we have to create the correlation matrix ahead of time, and we are passing in the data with colored values already computed, we switch our function to add_heatmap() and use some more arguments, then and add a few customizations to make it statistically accurate.\n\n\ncorr &lt;- diamonds %&gt;% \n  select(where(is.numeric)) %&gt;% \n  cor\ncorrplot::corrplot(corr)\n\n\n\n\n\n\n\n\ncorr %&gt;% \n  data.frame %&gt;% \n  plot_ly(x = rownames(corr), y = colnames(corr), z = corr) %&gt;% \n  add_heatmap(colors = \"RdBu\") %&gt;% \n  colorbar(limits = c(-1, 1))\n\n\n\n\n\n\n34.5.2 Exercise\n\n\nCreate the following graphs:\n\nAn interactive 2D histogram for Petal.Width and Petal.Length from the iris dataset. What other type of plot can we make to display two quantitative variables that may be a better choice for this data?\nAn interactive heatmap for color by clarity from the diamonds dataset. Note that the best way to do this is to let plotly guess the plot type when supplying two categorical variables to x and y.\n\n\n\n34.5.3 Slope graphs and dumbell charts\n\nSlope graphs and dumbell charts are useful for comparing numeric values across numerous categories.\n\nSlope graphs are a minimal plot to easily show the change in a value across categories (or time points). That change is easy to see when we connect those values with lines, because the lines will slope up or down, in the direction of the change. The steeper the slope, the bigger the change.\n\nNote however for showing change over time, slopegraphs only show the endpoints and skip all change in the middle; so, we need to think about if this is what we want to show (else a line plot would be better).\n\n\nLet’s recreate the following slopegraph using plotly.\n\n\n# create long data of summarized beginning and end year average life expectancy by continent\ngapminder_avg &lt;- gapminder %&gt;% \n  filter(year %in% c(min(year), max(year))) %&gt;% \n  summarize(.by = c(continent, year),\n            avg_lifeExp = round(mean(lifeExp), 1)) %&gt;% \n  mutate(year = ordered(year))\n\n# use package to make slopegraph\nslopegraph::ggslopegraph2(dataframe = gapminder_avg,\n                          times = year,\n                          measurement = avg_lifeExp,\n                          grouping = continent,\n                          linecolor = \"grey\",\n                          title = \"Gapminder average life expectancy (years)\")\n\n\n\n\n\n\n\n\n\n\nFirst here is a static version using ggplot.\n\n\n# create wide data of summarized beginning and end year average life expectancy by continent\n# then use ggplot2 to manually create slopegraph\n# -&gt; create segments and just add annotations to beginning\n# -&gt; not sure how to customize the x axis, so including description in title\ngapminder %&gt;% \n  filter(year %in% c(min(year), max(year))) %&gt;% \n  summarize(.by = c(continent, year),\n            avg_lifeExp = round(mean(lifeExp), 1)) %&gt;% \n  pivot_wider(names_from = year,\n              values_from = avg_lifeExp,\n              names_prefix = \"year_\") %&gt;% \n  ggplot() +\n  geom_segment(aes(x = 1,\n                   xend = 2,\n                   y = year_1952,\n                   yend = year_2007)) + \n  geom_text(aes(x = 0.95,\n                y = year_1952,\n                label = continent)) + \n  labs(title = \"Gapminder life expectancy 1952 to 2007\",\n       x = \"\",\n       y = \"Average life expectancy (years)\") + \n  theme_bw() + \n  theme(panel.grid = element_blank(),\n        axis.ticks.x = element_blank(),\n        axis.text.x = element_blank())\n\n\n\n\n\n\n\n\n\n\nNow for plotly.\n\n\ngapminder %&gt;% \n  filter(year %in% c(min(year), max(year))) %&gt;% \n  summarize(.by = c(continent, year),\n           avg_lifeExp = round(mean(lifeExp), 1)) %&gt;% \n  pivot_wider(names_from = year,\n              values_from = avg_lifeExp,\n              names_prefix = \"year_\") %&gt;% \n  plot_ly() %&gt;% \n  add_segments(x = 1,\n               xend = 2,\n               y = ~year_1952,\n               yend = ~year_2007) %&gt;% \n  add_annotations(x = 0.95,\n                  y = ~year_1952,\n                  text = ~paste(continent, year_1952),\n                  showarrow = FALSE) %&gt;% \n  add_annotations(x = 2.05,\n                  y = ~year_2007,\n                  text = ~paste(continent, year_2007),\n                  showarrow = FALSE) %&gt;% \n  layout(title = \"Gapminder average life expectancy\",\n         xaxis = list(ticktext = c(\"1952\", \"2007\"),\n                      tickvals = c(1, 2),\n                      zeroline = FALSE),\n         yaxis = list(title = \"\",\n                      showgrid = FALSE,\n                      showticks = FALSE,\n                      showticklabels = FALSE))\n\n\n\n\n\n\nThis would be an example where the interactivity doesn’t really add anything to the plot. So just because it can be made interactive, doesn’t mean that it should be made interactive.\nSo called dumbell charts are similar in concept to slope graphs, but not quite as general. They are typically used to compare two different classes of numeric values across numerous groups, whereas slopegraphs can be built out to three or more x-axis lines.\nWith a dumbell chart, it’s always a good idea to order the categories by a sensible metric.\nLet’s recreate the following dumbell chart made by ggplot, except with plotly so there is interactivity. This plot uses the dumbell approach to show average miles per gallon city and highway for different car models from the ggplot2::mpg dataset.\n\n\nhead(mpg)\n\n\n  \n\n\n# create summary data of mean mpg by model\n# then create dumbell chart with segments and points\n# -&gt; manually specify color legend\nmpg %&gt;% \n  summarize(.by = model,\n            across(c(cty, hwy), mean)) %&gt;% \n  mutate(model = fct_reorder(model, cty)) %&gt;% \n  ggplot() +\n  geom_segment(aes(x = cty,\n                   xend = hwy,\n                   y = model,\n                   yend = model),\n               color = \"grey\") + \n  geom_point(aes(x = cty,\n                 y = model,\n                 color = \"blue\")) + \n  geom_point(aes(x = hwy,\n                 y = model,\n                 color = \"orange\")) + \n  scale_color_manual(name = \"MPG\",\n                     values = c(\"blue\", \"orange\"),\n                     labels = c(\"city\", \"hwy\")) + \n  theme_bw()\n\n\n\n\n\n\n\n\n\n\nmpg %&gt;% \n  summarize(.by = model,\n            across(c(cty, hwy), mean)) %&gt;% \n  mutate(model = fct_reorder(model, cty)) %&gt;% \n  plot_ly() %&gt;% \n  add_segments(x = ~cty,\n              xend = ~hwy,\n              y = ~model,\n              yend = ~model,\n              color = I(\"grey\"),\n              showlegend = FALSE) %&gt;% \n  add_markers(x = ~cty,\n              y = ~model,\n              color = I(\"blue\"),\n              name = \"City\") %&gt;% \n  add_markers(x = ~hwy,\n              y = ~model,\n              color = I(\"orange\"),\n              name = \"Highway\") %&gt;% \n  layout(xaxis = list(title = \"MPG\"))\n\n\n\n\n\n\n34.5.4 Exercise\n\n\nCreate the following graphs:\n\nAn interactive slopegraph using the mpg dataset for cty vs hwy gas mileage by model. Use the same summarizing code as for the dumbell chart (we need wide summary data). What is a problem we have to consider with this type of plot?\nAn interactive dumbell plot using the mean lifeExp by continent from the gapminder dataset. Start with the same summarizing code as for the slopegraph (we need wide summary data again). Be sure to order the levels of continent by increasing mean for the minimum year.\n\n\n\n34.5.5 Parallel coordinates plot\n\n\nGenerally speaking:\n\nFor 2 numeric distributions we can use a scatterplot.\nFor 2 numeric dimensions by group (or time), we can facet, use a slopegraph or a dumbell plot.\nFor 3 numeric dimensions, we can use a bubble plot.\nFor more than 3 numeric dimensions, we can use a parallel coordinates plot.\n\n\nParallel coordinate plots are a multivariate display that organizes many numeric axes in parallel (instead of orthogonal). It’s effectiveness depends how the grouped data behaves (i.e. if data within a group is similar across variables).\nIf want high dimensions, we can look at a “profile” of each observation across many dimensions. Then we can connect the dots to show that corresponding points go togther (i.e. connect observation values with line across all axes).\n\nTo create static parallel coordinates plot, we can use GGally::ggparcoord(). One important argument is scale, which determines how to scale values on each axis, which is an important aspect of the final visual.\n\nSo by default, this function standardizes evey value with a z-score `scale = “std”: \\(z = \\frac{x \\, - \\,\\bar{x}}{S_x}\\). With a strong skew, these could get up to 4 and 5, but generally absolute values are less than 3.\nAnother more common option is to use scale = \"unimimmax\", which puts everything on a [0,1] scale in between the min and max value of that variable: \\(z = \\frac{x \\, - \\,min}{max \\, - \\, min}\\). This which keeps the relative position of all values, just with a new scale.\n\n\n\n\n# create parallel coordinate plot using default options\niris %&gt;% \n  ggparcoord(columns = 1:4, \n             groupColumn = 5,\n             scale = \"uniminmax\",\n             order = \"anyClass\",\n             alphaLines = 0.5) +\n  theme_bw()\n\n\n\n\n\n\n\n\n# confirm trends with correlation matrix\ncor(select(iris, where(is.numeric))) %&gt;% round(3)\n\n             Sepal.Length Sepal.Width Petal.Length Petal.Width\nSepal.Length        1.000      -0.118        0.872       0.818\nSepal.Width        -0.118       1.000       -0.428      -0.366\nPetal.Length        0.872      -0.428        1.000       0.963\nPetal.Width         0.818      -0.366        0.963       1.000\n\n\n\n\nWhen interpreting a parallel coordinates plot, we are looking for three things:\n\nClusters by color: Are there groups that have similar profiles across the axes? Visually, are the lines close together and roughly parallel? Or are there anomilies (lines that don’t follow the general pattern) within or across groups?\nSlopes of lines: If slopes are constant between adjacent axes, this indicates there is a positive correlation between variables (low values of one variable correspond to low values of the other, and high values to high values).\nSpread by color: Are lines for a group spread out on a particular axes or close together (diverging or converging)? We are looking at the variation in a variable within a particular group.\n\n\nLet’s recreate the above parallel coordinates plot with interactivity via plotly and add_lines(). We have to do the scaling ourselves before passing to plot_ly(). To do the uniform min / max transformation, we can use scales::rescale(). In addition, an observation ID needs to be added so that it can be grouped by (and thus we get one line per observation), which can be done with tibble::rowid_to_column().\n\n\niris %&gt;% \n  mutate(across(where(is.numeric), scales::rescale)) %&gt;% \n  rowid_to_column(var = \"obs\") %&gt;% \n  pivot_longer(cols = -c(Species, obs),\n               names_to = \"variable\",\n               values_to = \"value\") %&gt;% \n  group_by(obs) %&gt;% \n  plot_ly(x = ~variable,\n          y = ~value,\n          color = ~Species) %&gt;% \n  add_lines(alpha = 0.5)",
    "crumbs": [
      "R",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Notes -- Interactive Plots</span>"
    ]
  },
  {
    "objectID": "notes-r-interactive-plots.html#graphical-queries",
    "href": "notes-r-interactive-plots.html#graphical-queries",
    "title": "\n34  Notes – Interactive Plots\n",
    "section": "\n34.6 Graphical queries",
    "text": "34.6 Graphical queries\n\n34.6.1 Basic graphical queries\n\nHere we introduce particular approach to linking views (visuals) known as graphical (database) queries. With plotly, we can write R code to pose graphical queries that operate in the web browser (we won’t delve into the back-end of how these work).\nEssentially we want to interactively select aspects of our graph (particular points, lines, etc.) and “filter” to similar data points by highlighting those while pushing the rest to the background.\nEssentially, the strategy that we use is calling plotly::highlight_key(&lt; data &gt;, ~&lt; var &gt;) on our data and a particular variable that we are going to highlight by. Then we pass this to our plot_ly() function and create the graph like normal.\nFor the example below, highlight_key() assigns the number of cylinders to each point so that when a particular point is “queried” all points with the same number of cylinders are highlighted. By default, a mouse click triggers a query, and a double-click clears the query, but both of these events can be customized through the highlight() function with the on and off arguments.\n\n\nmtcars %&gt;% \n  highlight_key(~cyl) %&gt;% \n  plot_ly(x = ~wt,\n          y = ~mpg) %&gt;% \n  add_markers() %&gt;% \n  add_text(text = ~cyl,\n           textposition = \"top\") %&gt;%\n  highlight(on = \"plotly_hover\")\n\n\n\n\n\n\nGenerally speaking, highlight_key() assigns data values to graphical marks so that when graphical mark(s) are directly manipulated through the on event, it uses the corresponding data values (call it $SELECTION_VALUE) to perform an SQL query of the following form:\n\n\nSELECT * FROM mtcars WHERE cyl IN $SELECTION_VALUE\n/* SELECT &lt; all columns &gt; FROM &lt; data &gt; WHERE &lt; var &gt; IN &lt; data marks &gt; */\n\n\nWe don’t need to worry about what is happening behind the scenes, just how to apply the techniques. This is just extra info that may help with the understanding of what’s actually happening if you’re curious.\n\n34.6.2 Linked brushing\n\nWe can take the methods used above one step further using linked brushing, which is a fancy way to say that multiple plots (or tables) are connected via highlighting.\nSuppose we wanted to not just visually highlight matching data points, but rather show the raw data for selected points (so we will have a plot that we can select data points and a corresponding data table displayed at the same time). Doing this requires just a few modifications to the above code.\n\nFirst we have to create a shared data object via highlight_key() (without specifying a variable so the entire data gets queried).\n\nhighlight_key() is a wrapper (meaning it is an easier way to call another function) that creates a SharedData instance built from the crosstalk package. This SharedData is a special data structure that can be accessed by all elements using the data.\nThis is important because it has has some built in reactive / listening features so that plots and tables can talk to each other.\n\n\nThis gets passed to plot_ly() to create our graph like normal with customized highlighting that gives the desirable on event for this application. Continuing the example, we save as an object p &lt;- shared_data %&gt;% &lt; plotly call &gt; %&gt;% highlight(on = \"plotly_selected\").\nFinally, we use crosstalk::bscols(&lt; plot &gt;, &lt; table &gt;) to organize our plot and table on the same pane, where the html table is created from the shared data object using DT::datatable(&lt; shared data &gt;). Continuing the example, we have bscols(p, datatable(shared_data)).\nOnce this is setup correctly, the rows corresponding to the selected points in the graph will be shown in the table!\n\n\nshared_data &lt;- highlight_key(mtcars)\n\np &lt;- shared_data %&gt;% \n  plot_ly(x = ~wt,\n          y = ~mpg) %&gt;% \n  add_markers() %&gt;% \n  add_text(text = ~cyl,\n           textposition = \"top\") %&gt;%\n  highlight(on = \"plotly_selected\") %&gt;% \n  hide_legend()\n\nbscols(p, datatable(shared_data, height = 500))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n34.6.3 Application\n\nAn application of this linked brushing technique is when performing EDA. In a true exploratory setting, you have to make lots of visualizations, and investigate lots of follow-up questions, before stumbling across something truly valuable. Being able to quickly and easily add this interactive filtering to our visuals, as demonstrated above, is a practical augmentation to the exploration process.\nSuppose we are investigating the mpg data, so we setup the linked brushing for a scatterplot and data table and we notice there is a cluster of points that are away from the general trend. Let’s look more into those rows.\n\n\nshared_data &lt;- highlight_key(mpg)\n\np &lt;- shared_data %&gt;% \n  plot_ly(x = ~displ,\n          y = ~hwy) %&gt;% \n  add_markers() %&gt;% \n  highlight(on = \"plotly_selected\")\n\nbscols(p, datatable(shared_data, height = 500))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote that this is much quicker than trying to write code to query those observations, it is much easier and intuitive to draw an outline around the points to query the data behind them.\nWith the gleaned information, suppose this fits into our narrative and we are in the final stages of an analysis, when it is time to publish our work to a general audience. Rather than relying on the audience to interact with the graphics and discover insight for themselves, it’s always a good idea to clearly highlight our findings.\nOne option using strategies from previous tutorials is to use aesthetic mapping to differentiate the points of interest from the rest. Here is how this can be done with ggplot using the color aesthetic.\n\n\n# plot two layers\n# -&gt; one of all points with grey color\n# -&gt; another with just points of interest in a different color\n# -&gt; add legend with informative values\nggplot() + \n  geom_point(aes(x = displ,\n                 y = hwy,\n                 color = \"Other\"),\n             data = mpg) + \n  geom_point(aes(x = displ,\n                 y = hwy,\n                 color = \"Corvette\"),\n             data = filter(mpg, model == \"corvette\")) + \n  scale_color_manual(values = c(\"Other\" = \"grey\", \"Corvette\" = \"red\"),\n                     name = \"Model\") + \n  labs(title = \"Fuel economy from 1999 to 2008 for 38 car models\",\n       caption = \"Source: https://fueleconomy.gov/\",\n       x = \"Engine Displacement\",\n       y = \"Miles Per Gallon\") + \n  theme_bw() \n\n\n\n\n\n\n\n\n\n\nAn alternative is to annotate the points of interest. This can be done via ggforce::geom_mark_hull() (or *_ellipse, *_circle, *_rect).\n\n\nggplot(aes(x = displ,\n           y = hwy),\n       data = mpg) + \n  geom_point() +\n  geom_mark_hull(aes(filter = model == \"corvette\",\n                     label = model)) +\n  labs(title = \"Fuel economy from 1999 to 2008 for 38 car models\",\n       caption = \"Source: https://fueleconomy.gov/\",\n       x = \"Engine Displacement\",\n       y = \"Miles Per Gallon\") + \n  theme_bw()\n\n\n\n\n\n\n\n\n\n\n\nCAUTION: Make sure the points we are highlighting are in a cluster on their own or else additional unwanted points will be included in the annotations as well as demonstrated below.\n\n\n# show hull with colored points to point out caution when using this technique\nggplot() + \n  geom_point(aes(x = displ,\n                 y = hwy),\n             data = mpg) + \n  geom_point(aes(x = displ,\n                 y = hwy,\n                 color = \"a4\"),\n             data = filter(mpg, model == \"a4\")) + \n  geom_mark_hull(aes(x = displ,\n                     y = hwy,\n                     filter = model == \"a4\",\n                     label = model),\n                 data = mpg) + \n  scale_color_manual(values = c(\"a4\" = \"red\"),\n                     name = \"Model\") + \n  theme_bw()\n\n\n\n\n\n\n\n\n\n\n34.6.4 More graphical queries\n\nGraphical queries can also help to combat overplotting on busy plots.\n\n\ngapminder %&gt;% \n  group_by(country) %&gt;% \n  highlight_key(~country) %&gt;% \n  plot_ly(x = ~year,\n          y = ~lifeExp,\n          text = ~country) %&gt;% \n  add_lines(color = ~continent)\n\n\n\n\n\n\nQuerying a country via direct manipulation is somewhat helpful for focusing on a particular time series, but it’s not so helpful for querying a country by name and/or comparing multiple countries at once.\n\nWe can add a few options in highlight() to change the behavior when the on event occurs.\n\nTo select multiple (selections remain), hold shift and click (shift + click) while clicking.\nTo be able to change the color of selections, set dynamic = TRUE.\nTo be able to type in names of selections and have a dropdown, set selectize = TRUE.\n\n\n\n\ngapminder %&gt;% \n  group_by(country) %&gt;% \n  highlight_key(~country, \"Select a country\") %&gt;% \n  plot_ly(x = ~year,\n          y = ~lifeExp,\n          text = ~country) %&gt;% \n  add_lines(color = ~continent) %&gt;% \n  highlight(dynamic = TRUE,\n            selectize = TRUE)\n\n\n\n\n\n\nThis allows us to focus on certain comparisons of interest and notice finer aspects of the data that would be hard with everything plotted.\n\n34.6.5 Exercise\n\n\nExplore the ggplot2::msleep data.\n\nCreate a linked brushing setup for a scatterplot of brainwt by sleep_total and the corresponding data table. Which points stand out? Which species are they?\nCHALLENGE: Recreate the scatterplot as a static image using ggplot2 and add annotations to the interesting species via geom_mark_*() as if it were to be in the final published work. Add nicely formatted, informative labels and titles as well.\n\n\n\n34.6.6 Linking multiple plots and subplot()\n\nWe can also link multiple plots together so that brushing on one highlights data on the other. A very common strategy is to have an aggregated data plot followed by a more detailed plot (this hits the popular data viz advice “Overview first, zoom and filter, then details on demand”).\nTo do this, we need to create a shared data object like before via shared_data &lt;- highlight_key(&lt; data &gt;), then build both plots off shared_data.\nThe plots can then be arranged side-by-side (or any way we desire) using plotly::subplot(), which can be further modified with additional piped statements. The highlight() features can be specified for the subplot() statement rather than the individual plots.\n\n\nshared_data &lt;- highlight_key(mtcars, , \"Select a model\")\n\np1 &lt;- share_data %&gt;% \n  plot_ly(x = ~ordered(cyl)) %&gt;% \n  add_histogram()\n\nError in eval(expr, envir, enclos): object 'share_data' not found\n\np2 &lt;- share_data %&gt;% \n  plot_ly(x = ~wt,\n          y = ~mpg) %&gt;% \n  add_markers()\n\nError in eval(expr, envir, enclos): object 'share_data' not found\n\nsubplot(p1, p2) %&gt;% \n  hide_legend() %&gt;% \n  highlight(dynamic = TRUE, selectize = TRUE)\n\n\n\n\n\n\nNote that subplot() can be used even when we are not linking images and it has a lot of customization to organize our plots well. Below are some example uses of this function.\nCreate comparative boxplots for diamond prices, and add overall boxplot on same axes.\n\n\np &lt;- plot_ly(diamonds,\n             y = ~price,\n             color = I(\"black\"), \n             alpha = 0.1O)\n\np1 &lt;- p %&gt;% add_boxplot(x = \"Overall\")\np2 &lt;- p %&gt;% add_boxplot(x = ~cut)\n\nsubplot(p1, p2,\n        shareY = TRUE,\n        widths = c(0.2, 0.8)) %&gt;% \n  hide_legend()\n\nError: &lt;text&gt;:4:25: unexpected symbol\n3:              color = I(\"black\"), \n4:              alpha = 0.1O\n                           ^\n\n\n\nCreate density plots (for modality) and comparative boxplots (for center and outliers) to get a really good idea of the distributions of diamond prices by cut. We can also use the linked brushing setup with this as well.\n\n\nshared_data &lt;- highlight_key(diamonds)\n\np1 &lt;- ggplot(data = shared_data,\n            aes(x = price,\n                color = cut)) + \n  geom_density() + \n  theme_bw()\n\np2 &lt;- shared_data %&gt;% \n  plot_ly() %&gt;% \n   add_boxplot(x = ~price,\n               y = ~cut,\n               color = ~cut)\n\nsubplot(p1, p2,\n        nrows = 2,\n        shareX = TRUE)\n\n\n\n\n\n\n34.6.7 Exercise\n\n\nUsing the starter code below that filters and summarizes the Lahman::Batting data to team totals for the most current year then creates three density plots, do the following:\n\nCHALLENGE: Create an interactive parallel coordinates. Remember that we need long data for all of the numeric variables and we can group by teamID because that acts as the observation ID. What can we conclude from this plot, if anything?\nCombine these plots into a single view with subplot(); however have the three density plots in the first row and the parallel coordinates plot in the second row.\n\n\n\nHINT: You can nest subplot statements, e.g. subplot(subplot(&lt; plots &gt;) &lt; another plot &gt;)\n\n\n\n\n\n# create team summarized batting data for the most recent year\nbatting &lt;- Lahman::Batting %&gt;% \n  filter(yearID == max(yearID)) %&gt;% \n  select(-c(stint,G)) %&gt;% \n  summarize(.by = c(teamID, yearID, lgID), across(c(where(is.numeric)), sum)) %&gt;% \n  mutate(yearID = as.factor(yearID)) %&gt;% # so year doesn't get rescaled in the parallel coordinates plot\n  select(where(is.factor), HR, RBI, SB) # just look at three important batting stats\n\n# create three different density plots\np1 &lt;- batting %&gt;% \n  ggplot() + \n  geom_density(aes(x = HR,\n                   color = lgID)) + \n  theme_bw()\np2 &lt;- batting %&gt;% \n  ggplot() + \n  geom_density(aes(x = RBI,\n                   color = lgID)) + \n  theme_bw()\np3 &lt;- batting %&gt;% \n  ggplot() + \n  geom_density(aes(x = SB,\n                   color = lgID)) + \n  theme_bw() \n\n# create parallel coordinates plot\n\n# organize plots",
    "crumbs": [
      "R",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Notes -- Interactive Plots</span>"
    ]
  },
  {
    "objectID": "notes-r-interactive-plots.html#filter-events",
    "href": "notes-r-interactive-plots.html#filter-events",
    "title": "\n34  Notes – Interactive Plots\n",
    "section": "\n34.7 Filter events",
    "text": "34.7 Filter events\n\n34.7.1 Highlight vs filter\n\n\nWe just covered plotly’s framework for highlight events, but it also supports filter events. These events trigger slightly different logic:\n\nA highlight event dims the opacity of existing marks, then adds an additional graphical layer representing the selection.\nA filter event completely remove existing marks and rescales axes to the remaining data.\n\n\nHere is a demo of what the difference is:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSelect a city\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n34.7.2 Creating a filtered event plot\n\nNow we can recreate the filtered event plot.\nTo do this, filter events must be fired from filter widgets (think: html element) from the crosstalk package. So create the filter bar, we can use crosstalk::filter_select(), which expects a SharedData instance as an input. As we have seen, we can use shared_data &lt;- highlight_key() to accomplish this.\nThen we create the plot like usual from shared_data using either ggplotly() or plot_ly().\nFinally, we need to arrange the filter bar and the plot with crosstalk::bscols().\n\n\n# crate shared data object\nshared_data &lt;- highlight_key(txhousing)\n\n# create highlight plot from shared data object\np &lt;- ggplot(data = shared_data) +\n  geom_line(aes(x = date,\n                y = median,\n                group = city))\n\n# arrange select box for filtering shared data object and plot from same shared data object\nbscols(filter_select(id = \"id\",\n                     label = \"Select a city\",\n                     sharedData = shared_data,\n                     group = ~city),\n       ggplotly(p, dynamicTicks = TRUE),\n       widths = 12)\n\n\n\n\n\nSelect a city\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n34.7.3 Exercise\n\nModify / add to the code below to transform the static timeseries plot of the gapminder dataset into an interactive filtered event plot.\n\n\nggplot(data = gapminder) + \n  geom_line(aes(x = year,\n                y = lifeExp,\n                group = country,\n                color = continent)) + \n  theme_bw()",
    "crumbs": [
      "R",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Notes -- Interactive Plots</span>"
    ]
  },
  {
    "objectID": "notes-r-interactive-plots.html#exercise-solutions",
    "href": "notes-r-interactive-plots.html#exercise-solutions",
    "title": "\n34  Notes – Interactive Plots\n",
    "section": "\n34.8 Exercise solutions",
    "text": "34.8 Exercise solutions\nExercise 34.2.3\n\np &lt;- ggplot(data = diamonds,\n            aes(x = cut,\n                fill = clarity)) + \n  geom_bar(position = \"fill\") # position = \"stack\" for a regular (count) stacked bar graph\nggplotly(p)\n\n\n\n\n\nExercise 34.4.2\n\n# easiest way: using add_histogram()\ngapminder %&gt;%\n  filter(year == min(year)) %&gt;% \n  plot_ly(x = ~continent) %&gt;% \n  add_histogram\n\n\n\n\n# slightly harder way, but can customize more: using add_bars()\ngapminder %&gt;% \n  filter(year == min(year)) %&gt;% \n  count(continent) %&gt;% \n  mutate(continent = fct_reorder(continent, n, .desc = TRUE)) %&gt;% \n  plot_ly(x = ~continent,\n          y = ~n) %&gt;% \n  add_bars() %&gt;% \n  add_text(x = ~continent,\n           y = ~n,\n           text = ~n,\n           textposition = \"top middle\") %&gt;% \n  layout(title = \"Gapminder 1952\", showlegend = FALSE)\n\n\n\n\n\nExercise 34.4.4\n\niris %&gt;% \n  mutate(Species = fct_reorder(.f = Species, .x = Sepal.Width, .fun = mean, .desc = TRUE)) %&gt;% \n  plot_ly(x = ~Species,\n          y = ~Sepal.Width) %&gt;% \n  add_boxplot(boxmean = TRUE)\n\n\n\n\n\nExercise 34.4.7\n\n# a) Scatterplot 1\niris %&gt;% \n  plot_ly(x = ~Sepal.Width,\n          y = ~Sepal.Length,\n          text = ~Species) %&gt;% \n  add_markers(color = I(\"green\"))\n\n\n\n\n# b) Scatterplot 2\niris %&gt;% \n  plot_ly(x = ~Sepal.Width,\n          y = ~Sepal.Length,\n          color = ~Species,\n          colors = c(\"darkgreen\", \"green\", \"grey\")) %&gt;% \n  add_markers()\n\n\n\n\n\nExercise 34.5.2\n\n# part a)\niris %&gt;% \n  plot_ly(x = ~Petal.Width,\n          y = ~Petal.Length) %&gt;% \n  add_histogram2d()\n\n\n\n\n# -&gt; small data, so scatterplot would be better, try letting plot_ly() guess the plot type and see the result\n\n# part b)\ndiamonds %&gt;% \n  plot_ly(x = ~color,\n          y = ~clarity)\n\n\n\n\n\nExercise 34.5.4\n\n# part a)\n# summarize mean city and highway mpg by model\n# then order by increasing mean for city (the first axis)\n# then create slopegraph\nmpg %&gt;% \n  summarize(.by = model,\n            across(c(cty, hwy), mean)) %&gt;% \n  plot_ly() %&gt;% \n  add_segments(x = 1,\n               xend = 2,\n               y = ~cty,\n               yend = ~hwy) %&gt;% \n  add_annotations(x = 0.95,\n                  y = ~cty,\n                  text = ~model,\n                  name = \"City\") %&gt;% \n  add_annotations(x = 2.05,\n                  y = ~hwy,\n                  text = ~model,\n                  name = \"Highway\")\n\n\n\n\n# -&gt; problem is that the annotations become too cluttered with too many lines, the dumbell chart is better for this data display\n\n# part b)\n# filter to beginning and end years\n# summarize avg life expectancy by year and continent\n# convert to wide data\n# change levels of continent factor\n# create dumbell chart\ngapminder %&gt;% \n  filter(year %in% c(min(year), max(year))) %&gt;% \n  summarize(.by = c(continent, year),\n           avg_lifeExp = round(mean(lifeExp), 1)) %&gt;% \n  pivot_wider(names_from = year,\n              values_from = avg_lifeExp,\n              names_prefix = \"year_\") %&gt;% \n  mutate(continent = fct_reorder(continent, year_1952)) %&gt;% \n  plot_ly() %&gt;% \n  add_segments(x = ~year_1952,\n              xend = ~year_2007,\n              y = ~continent,\n              yend = ~continent,\n              color = I(\"grey\"),\n              showlegend = FALSE) %&gt;% \n  add_markers(x = ~year_1952,\n              y = ~continent,\n              color = I(\"blue\"),\n              name = \"1952\") %&gt;% \n  add_markers(x = ~year_2007,\n              y = ~continent,\n              color = I(\"orange\"),\n              name = \"2007\") %&gt;% \n  layout(xaxis = list(title = \"Average life expectancy (years)\"))\n\n\n\n\n\nExercise 34.6.5\n\n# part a) linked brush setup\nshared_data &lt;- highlight_key(msleep)\n\np &lt;- shared_data %&gt;% \n  plot_ly(x = ~brainwt,\n          y = ~sleep_total) %&gt;% \n  add_markers() %&gt;% \n  highlight(on = \"plotly_selected\")\n\nbscols(p, datatable(shared_data, height = 500))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# part b) final publishable plot example\nggplot(aes(x = brainwt,\n           y = sleep_total),\n       data = msleep) + \n  geom_point() +\n  geom_mark_hull(aes(filter = name %in% c(\"Asian elephant\", \"African elephant\"), label = \"Elephants\")) + \n  geom_mark_hull(aes(filter = name %in% c(\"Big brown bat\", \"Little brown bat\"), label = \"Bats\")) + \n  geom_mark_hull(aes(filter = name == \"Human\", label = name)) + \n  labs(title = \"Mammals sleep patterns\",\n       x = \"Brain weight (kg)\",\n       y = \"Sleep total (hours)\") + \n  theme_bw()\n\n\n\n\n\n\n\n\n\nExercise 34.6.7\n\n# create team summarized batting data for the most recent year\nbatting &lt;- Lahman::Batting %&gt;% \n  filter(yearID == max(yearID)) %&gt;% \n  select(-c(stint,G)) %&gt;% \n  summarize(.by = c(teamID, yearID, lgID), across(c(where(is.numeric)), sum)) %&gt;% \n  mutate(yearID = as.factor(yearID)) %&gt;% # so year doesn't get rescaled in the parallel coordinates plot\n  select(where(is.factor), HR, RBI, SB) # just look at three important batting stats\n\n# create three different density plots\np1 &lt;- batting %&gt;% \n  ggplot() + \n  geom_density(aes(x = HR,\n                   color = lgID)) + \n  theme_bw()\n\np2 &lt;- batting %&gt;% \n  ggplot() + \n  geom_density(aes(x = RBI,\n                   color = lgID)) + \n  theme_bw()\n\np3 &lt;- batting %&gt;% \n  ggplot() + \n  geom_density(aes(x = SB,\n                   color = lgID)) + \n  theme_bw() \n\n# create parallel coordinates plot\np4 &lt;- batting %&gt;% \n  mutate(across(where(is.numeric), scales::rescale)) %&gt;% \n  pivot_longer(cols = -c(teamID, lgID, yearID),\n               names_to = \"variable\",\n               values_to = \"value\") %&gt;% \n  group_by(teamID) %&gt;% \n  plot_ly(x = ~variable,\n          y = ~value,\n          color = ~lgID,\n          text = ~teamID) %&gt;% \n  add_lines(alpha = 0.5)\n\n# AL and NL behave similarly, no trends\n# -&gt; positive correlation between HR and RBIs, less so for RBIs and SBs\n\n# oragnize three plots in first row and one in second row\n# -&gt; note that subplot implicitly converts to plotly like ggplotly()\nsubplot(subplot(p1, p2, p3),\n        p4,\n        nrows = 2)\n\n\n\n\n\nExercise 34.7.3\n\n# crate shared data object\nshared_data &lt;- highlight_key(gapminder)\n\n# create highlight plot from shared data object\np &lt;- ggplot(data = shared_data) + \n  geom_line(aes(x = year,\n                y = lifeExp,\n                group = country,\n                color = continent)) + \n  theme_bw()\n\n# arrange select box for filtering shared data object and plot from same shared data object\nbscols(filter_select(id = \"id\",\n                     label = \"Select a country\",\n                     sharedData = shared_data,\n                     group = ~country),\n       ggplotly(p, dynamicTicks = TRUE),\n       widths = 12)\n\n\n\n\n\nSelect a country",
    "crumbs": [
      "R",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Notes -- Interactive Plots</span>"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "DANA 320 –Data Visualization",
    "section": "",
    "text": "Overview",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "index.html#content",
    "href": "index.html#content",
    "title": "DANA 320 –Data Visualization",
    "section": "Content",
    "text": "Content",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "index.html#concurrent-readings",
    "href": "index.html#concurrent-readings",
    "title": "DANA 320 –Data Visualization",
    "section": "Concurrent Readings",
    "text": "Concurrent Readings",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "index.html#source",
    "href": "index.html#source",
    "title": "DANA 320 –Data Visualization",
    "section": "Source",
    "text": "Source\n\n\n\n\n\n\nQuarto blog publish details\n\n\n\nThis book was created using Quarto and published with Github Pages.\n\n\n\n\n\n\n\n\nGithub repository for code\n\n\n\nYou can find the code to reproduce this project at coltongearhart/dana320.",
    "crumbs": [
      "Overview"
    ]
  }
]